{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text text processing library\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import Vectors\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "from models import *\n",
    "from helpers import *\n",
    "# import main\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import time\n",
    "MAX_LEN = 20\n",
    "MIN_FREQ = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "DE = data.Field(tokenize=tokenize_de)\n",
    "\n",
    "# only target needs BOS/EOS:\n",
    "EN = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, eos_token = EOS_WORD) \n",
    "\n",
    "train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(DE, EN), \n",
    "                                         filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
    "                                         len(vars(x)['trg']) <= MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "EN.build_vocab(train.trg, min_freq=MIN_FREQ)\n",
    "\n",
    "pred_set = []\n",
    "for i, line in enumerate(open(\"source_test.txt\"), 1):\n",
    "    words = line.split()[:-1]\n",
    "    pred_set.append([DE.vocab.stoi[s] for s in words])\n",
    "\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits((train, val, test), batch_size=32, device=-1,\n",
    "                                                  repeat=False, sort_key=lambda x: len(x.src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_iter))\n",
    "# sent_inspect(batch,4)\n",
    "def sent_inspect(batch, idx=0):\n",
    "    print(\"Source\")\n",
    "    print(' '.join([DE.vocab.itos[w] for w in batch.src.data[:,idx]]))\n",
    "    print(\"Target\")\n",
    "    print(' '.join([EN.vocab.itos[w] for w in batch.trg.data[:,idx]]))\n",
    "# print(DE.vocab.stoi['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wo sich der Lauf des <unk> früher befand .\n",
      "<s> We started to be able to see where the <unk> used to flow . </s> <pad> <pad>\n",
      "Das führte mich dazu , Satellitenbilder zu benutzen .\n",
      "<s> This is really what brought me to using satellite imagery . </s> <pad> <pad> <pad> <pad> <pad>\n",
      "Wie unterscheidet sich diese Geschichte von der anderen ?\n",
      "<s> How is this story different ? </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Im Raum war ein junger Mann , <unk> .\n",
      "<s> One of the young men in the room was <unk> . </s> <pad> <pad> <pad> <pad> <pad>\n",
      "Ich brachte rund 90 junge <unk> Führungskräfte zusammen .\n",
      "<s> I brought together about 90 young Somali leaders . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Es vergeht vielleicht ein Jahr , aber nichts .\n",
      "<s> Maybe a year passes , nothing . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Sein Dorf liegt in der Nähe von <unk> .\n",
      "<s> His village is near <unk> . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Ich denke , diese beiden Figuren sind Experten .\n",
      "<s> I think these people are experts . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Vielleicht ist es nicht nur das <unk> Kleid .\n",
      "<s> Maybe it 's not just the <unk> dress . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Wer sind diese Typen ? Was lernen sie ?\n",
      "<s> Who are these guys ? What are they learning ? </s> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(' '.join(DE.vocab.itos[w] for w in debug_set[i]))\n",
    "    print(' '.join(EN.vocab.itos[w] for w in debug_ans[i]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "-0.0243 -0.0115 -0.0354  ...  -0.0116 -0.0199 -0.0004\n",
      " 0.0048 -0.0412  0.0498  ...   0.0488 -0.0136 -0.0468\n",
      "-0.0143 -0.0302 -0.0179  ...  -0.0005 -0.0107 -0.0013\n",
      "          ...             ⋱             ...          \n",
      "-0.0044 -0.0109 -0.0356  ...  -0.0087 -0.0030 -0.0207\n",
      "-0.0081  0.0471  0.0748  ...  -0.0080 -0.0376 -0.0138\n",
      "-0.0063 -0.0028 -0.0020  ...  -0.0136 -0.0283 -0.0010\n",
      "[torch.cuda.FloatTensor of size 11560x500 (GPU 0)]\n",
      "\n",
      "Parameter containing:\n",
      "-0.0243 -0.0115 -0.0354  ...  -0.0116 -0.0199 -0.0004\n",
      " 0.0048 -0.0412  0.0498  ...   0.0488 -0.0136 -0.0468\n",
      "-0.0143 -0.0302 -0.0179  ...  -0.0005 -0.0107 -0.0013\n",
      "          ...             ⋱             ...          \n",
      "-0.0044 -0.0109 -0.0356  ...  -0.0087 -0.0030 -0.0207\n",
      "-0.0081  0.0471  0.0748  ...  -0.0080 -0.0376 -0.0138\n",
      "-0.0063 -0.0028 -0.0020  ...  -0.0136 -0.0283 -0.0010\n",
      "[torch.cuda.FloatTensor of size 11560x500 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "ename": "CuDNNError",
     "evalue": "8: b'CUDNN_STATUS_EXECUTION_FAILED'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCuDNNError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-69ab1ffd786f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs_decoder_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbs_decoder_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatatype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0many_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_descs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0many_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_rnn_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# Allocate buffer to hold the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36minit_rnn_descriptor\u001b[0;34m(fn, handle)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdropout_desc_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdropout_desc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         fn.dropout_state[dropout_desc_name] = Unserializable(\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropoutDescriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         )\n\u001b[1;32m     44\u001b[0m     \u001b[0mdropout_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdropout_desc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, dropout, seed)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/__init__.py\u001b[0m in \u001b[0;36m_set\u001b[0;34m(self, dropout, seed)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_size_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_ulonglong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         ))\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/__init__.py\u001b[0m in \u001b[0;36mcheck_error\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mCuDNNError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCuDNNError\u001b[0m: 8: b'CUDNN_STATUS_EXECUTION_FAILED'"
     ]
    }
   ],
   "source": [
    "bs_decoder_new = AttnDecoder(EN, hidden_size=500, num_layers=4, word_features=500, dropout=0.2)\n",
    "old_params = list(bs_decoder.parameters())\n",
    "for i,p in enumerate(bs_decoder_new.parameters()):\n",
    "    p.data = old_params[i].data\n",
    "print(list(bs_decoder_new.parameters())[0])\n",
    "print(list(bs_decoder.parameters())[0])\n",
    "bs_decoder_new.lstm.flatten_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation time: 1.187801 seconds\n",
      "6.7436073229502185\n",
      "Validation time: 0.914976 seconds\n",
      "5.242139220071256\n",
      "torch.Size([1156000])\n",
      "torch.Size([1156000])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 6, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 6, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 6, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 3, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 3, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 3, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 19, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 19, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 19, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 15, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 15, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 15, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 15, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 15, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 15, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 15, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 15, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 15, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 3, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 3, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 3, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 19, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 19, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 19, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 3, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 3, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 3, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 19, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 19, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 19, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 6, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 6, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 6, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 3, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 3, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 3, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 5, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 5, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 5, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 19, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 19, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 19, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 17, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 6, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 6, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 6, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 19, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 19, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 19, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 5, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 5, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 5, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 6, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 6, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 6, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 4, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 4, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 4, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 18, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 7, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 9, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 10, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 14, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 16, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 8, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 6, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 6, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 6, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 15, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 15, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 15, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 5, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 5, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 5, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 13, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 2, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 11, 500])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9e190be98602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdebug_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdebug_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predictions.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/cs287/hw3/helpers.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_set, fn, num_cands, pred_len, beam_size)\u001b[0m\n\u001b[1;32m    308\u001b[0m                                                        \u001b[0mref_voc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref_voc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                                                        \u001b[0mpred_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                                                        beam_size=beam_size)\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_translations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;31m# if i > 10:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs287/hw3/helpers.py\u001b[0m in \u001b[0;36mrun_model_predict\u001b[0;34m(self, sent, ref_beam, ref_voc, beam_size, pred_len, pred_num)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# For attention, will use enc_output (not otherwise)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs287/hw3/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tsr, hidden)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# output is [batch, sent_len, hidden_size * num_directions]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_tsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# TODO: perhaps add dropout to output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkspace_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mworkspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mreserve_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_long\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "# evaluator = NMTEvaluator([bs_encoder, bs_decoder], DE, EN, reverse_enc_input=False)\n",
    "print(evaluator.evaluate(test_iter))\n",
    "print(evaluator.evaluate(val_iter))\n",
    "test_iter.init_epoch()\n",
    "debug_iter = iter(test_iter)\n",
    "for i in range(10):\n",
    "    batch = next(debug_iter)\n",
    "debug_set = [batch.src.data[:, i] for i in range(batch.src.data.size(1))]\n",
    "debug_ans = [batch.trg.data[:, i] for i in range(batch.trg.data.size(1))]\n",
    "evaluator.predict(pred_set, fn='predictions.txt',beam_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Epoch 0, loss: 75.106003, norm: 5.068851, elapsed: 601.591950, lrn_rate: 0.700000\n",
      "Validation time: 1.177268 seconds\n",
      "Validation set metric: 15.046797\n",
      "Epoch 1, loss: 64.709015, norm: 6.823921, elapsed: 1202.462563, lrn_rate: 0.700000\n",
      "Validation time: 1.123111 seconds\n",
      "Validation set metric: 10.318951\n",
      "Epoch 2, loss: 55.162987, norm: 5.810015, elapsed: 1815.646121, lrn_rate: 0.700000\n",
      "Validation time: 1.158648 seconds\n",
      "Validation set metric: 8.200983\n",
      "Epoch 3, loss: 48.013638, norm: 6.298200, elapsed: 2430.358610, lrn_rate: 0.700000\n",
      "Validation time: 1.222892 seconds\n",
      "Validation set metric: 7.256750\n",
      "Epoch 4, loss: 55.855797, norm: 8.171973, elapsed: 3034.166331, lrn_rate: 0.700000\n",
      "Validation time: 1.161787 seconds\n",
      "Validation set metric: 7.055706\n",
      "Epoch 5, loss: 51.494362, norm: 9.309718, elapsed: 3637.575163, lrn_rate: 0.700000\n",
      "Validation time: 1.184436 seconds\n",
      "Validation set metric: 7.108363\n",
      "Decaying LR to 0.350000\n",
      "Epoch 6, loss: 34.349045, norm: 8.055377, elapsed: 4239.637285, lrn_rate: 0.350000\n",
      "Validation time: 1.196922 seconds\n",
      "Validation set metric: 6.700641\n",
      "Epoch 7, loss: 26.329096, norm: 8.606746, elapsed: 4846.299028, lrn_rate: 0.350000\n",
      "Validation time: 1.140525 seconds\n",
      "Validation set metric: 7.049315\n",
      "Decaying LR to 0.175000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-ffd2c44189bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                      lrn_decay='adaptive', reverse_enc_input=False)\n\u001b[1;32m      7\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNMTEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs_decoder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_enc_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-78-565b039c9b12>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, torch_train_iter, le, val_iter, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m                 \u001b[0mres_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_iter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-565b039c9b12>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, batch, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-565b039c9b12>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(self, batch, mode)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# For attention, will use enc_output (not otherwise)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-cab290137def>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tsr, hidden)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# output is [batch, sent_len, hidden_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_tsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# TODO: perhaps add dropout to output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# init descriptors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_rnn_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_input_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_descs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptor_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36minit_rnn_descriptor\u001b[0;34m(fn, handle)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, hidden_size, num_layers, dropout_desc, input_mode, bidirectional, mode, datatype)\u001b[0m\n\u001b[1;32m    259\u001b[0m             ))\n\u001b[1;32m    260\u001b[0m             if version() >= 7000 and int(cuda[0]) >= 9 and (\n\u001b[0;32m--> 261\u001b[0;31m                     torch.cuda.get_device_capability(torch.cuda.current_device())[0] >= 7):\n\u001b[0m\u001b[1;32m    262\u001b[0m                 \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnnSetRNNMatrixMathType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCUDNN_DEFAULT_MATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdatatype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCUDNN_DATA_HALF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \"\"\"\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDeviceCapability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=32, device=-1,\n",
    "                                                  repeat=False, sort_key=lambda x: len(x.src))\n",
    "bs_encoder = BaseEncoder(DE, hidden_size=500, num_layers=4, word_features=500)\n",
    "bs_decoder = BaseDecoder(EN, hidden_size=500, num_layers=4, word_features=500)\n",
    "trainer = NMTTrainer([bs_encoder, bs_decoder], DE, EN, lrn_rate=0.7, \n",
    "                     lrn_decay='adaptive', reverse_enc_input=False)\n",
    "evaluator = NMTEvaluator([bs_encoder, bs_decoder], DE, EN, reverse_enc_input=False)\n",
    "trainer.train(train_iter, verbose=True, le=evaluator, val_iter=val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Epoch 0, loss: 74.447678, norm: 4.323705, elapsed: 540.722497, lrn_rate: 1.000000\n",
      "Validation time: 1.054063 seconds\n",
      "Validation set metric: 26.014990\n",
      "Epoch 1, loss: 63.033104, norm: 4.913937, elapsed: 1085.895758, lrn_rate: 1.000000\n",
      "Validation time: 0.867175 seconds\n",
      "Validation set metric: 11.078131\n",
      "Epoch 2, loss: 61.974842, norm: 5.519036, elapsed: 1626.097885, lrn_rate: 1.000000\n",
      "Validation time: 0.935742 seconds\n",
      "Validation set metric: 7.667555\n",
      "Epoch 3, loss: 45.707653, norm: 5.045727, elapsed: 2164.118364, lrn_rate: 1.000000\n",
      "Validation time: 0.951134 seconds\n",
      "Validation set metric: 6.637843\n",
      "Epoch 4, loss: 39.838863, norm: 5.510409, elapsed: 2707.005018, lrn_rate: 1.000000\n",
      "Validation time: 0.947607 seconds\n",
      "Validation set metric: 6.117144\n",
      "Epoch 5, loss: 48.402901, norm: 5.603142, elapsed: 3246.396275, lrn_rate: 1.000000\n",
      "Validation time: 0.943356 seconds\n",
      "Validation set metric: 5.751743\n",
      "Epoch 6, loss: 44.464031, norm: 6.889078, elapsed: 3790.113114, lrn_rate: 1.000000\n",
      "Validation time: 0.862508 seconds\n",
      "Validation set metric: 5.527463\n",
      "Epoch 7, loss: 45.894772, norm: 7.042506, elapsed: 4326.867793, lrn_rate: 1.000000\n",
      "Validation time: 0.931661 seconds\n",
      "Validation set metric: 5.405625\n",
      "Epoch 8, loss: 43.811329, norm: 6.324491, elapsed: 4867.575296, lrn_rate: 1.000000\n",
      "Validation time: 0.946792 seconds\n",
      "Validation set metric: 5.395534\n",
      "Epoch 9, loss: 37.985748, norm: 7.297110, elapsed: 5406.630132, lrn_rate: 1.000000\n",
      "Validation time: 0.808646 seconds\n",
      "Validation set metric: 5.312457\n",
      "Epoch 10, loss: 38.659294, norm: 6.352155, elapsed: 5947.663281, lrn_rate: 1.000000\n",
      "Validation time: 1.006784 seconds\n",
      "Validation set metric: 5.275308\n",
      "Epoch 11, loss: 46.025539, norm: 8.441181, elapsed: 6489.309039, lrn_rate: 1.000000\n",
      "Validation time: 1.039704 seconds\n",
      "Validation set metric: 5.236406\n",
      "Epoch 12, loss: 39.458515, norm: 6.940957, elapsed: 7029.367565, lrn_rate: 1.000000\n",
      "Validation time: 1.000365 seconds\n",
      "Validation set metric: 5.292374\n",
      "Decaying LR to 0.500000\n",
      "Epoch 13, loss: 31.296558, norm: 6.371438, elapsed: 7569.893920, lrn_rate: 0.500000\n",
      "Validation time: 0.714151 seconds\n",
      "Validation set metric: 5.113330\n",
      "Epoch 14, loss: 30.013723, norm: 6.594206, elapsed: 8106.723609, lrn_rate: 0.500000\n",
      "Validation time: 0.884465 seconds\n",
      "Validation set metric: 5.085152\n",
      "Epoch 15, loss: 31.031687, norm: 8.124546, elapsed: 8644.692552, lrn_rate: 0.500000\n",
      "Validation time: 0.926231 seconds\n",
      "Validation set metric: 5.166627\n",
      "Decaying LR to 0.250000\n",
      "Epoch 16, loss: 27.022732, norm: 6.915482, elapsed: 9183.632927, lrn_rate: 0.250000\n",
      "Validation time: 0.949923 seconds\n",
      "Validation set metric: 5.184296\n",
      "Decaying LR to 0.125000\n",
      "Epoch 17, loss: 25.021229, norm: 6.698111, elapsed: 9724.979861, lrn_rate: 0.125000\n",
      "Validation time: 0.852118 seconds\n",
      "Validation set metric: 5.165478\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3229212b698d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m evaluator = NMTEvaluator([bs_encoder, at_decoder], DE, EN, attention=True,\n\u001b[1;32m      9\u001b[0m                         record_attention=True)\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/cs287/hw3/helpers.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, torch_train_iter, le, val_iter, **kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m                 \u001b[0mres_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_iter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs287/hw3/helpers.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, batch, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;31m# norms must be clipped after backward but before step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mloss_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs287/hw3/helpers.py\u001b[0m in \u001b[0;36mclip_norms\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# Norm clipping: returns a float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             norm = nn.utils.clip_grad_norm(\n\u001b[0;32m--> 392\u001b[0;31m                 parameters, self.clip_norm)\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mparam_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mtotal_norm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparam_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=32, device=-1,\n",
    "                                                  repeat=False, sort_key=lambda x: len(x.src))\n",
    "bs_encoder = BaseEncoder(DE, hidden_size=500, num_layers=4, word_features=500, dropout=0.2)\n",
    "# TODO: decide whether to add dropout to output states of encoder!\n",
    "at_decoder = AttnDecoder(EN, hidden_size=500, num_layers=4, word_features=500, dropout=0.2)\n",
    "trainer = NMTTrainer([bs_encoder, at_decoder], DE, EN, lrn_rate=1.0, \n",
    "                     lrn_decay='adaptive', attention=True)\n",
    "evaluator = NMTEvaluator([bs_encoder, at_decoder], DE, EN, attention=True,\n",
    "                        record_attention=True)\n",
    "trainer.train(train_iter, verbose=True, le=evaluator, val_iter=val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation time: 0.456792 seconds\n",
      "6.048956472651303\n",
      "3722\n",
      "Variable containing:\n",
      " 0.6505  0.1110  0.0659  0.1725\n",
      " 0.5297  0.1554  0.2806  0.0343\n",
      " 0.0089  0.4239  0.4734  0.0938\n",
      " 0.0180  0.0371  0.9122  0.0327\n",
      " 0.0822  0.0702  0.3141  0.5335\n",
      " 0.4222  0.2591  0.0997  0.2190\n",
      " 0.1612  0.3041  0.4915  0.0432\n",
      " 0.2962  0.4637  0.0781  0.1620\n",
      "[torch.cuda.FloatTensor of size 8x4 (GPU 0)]\n",
      "\n",
      "Source\n",
      "Ich hatte Angst –\n",
      "Target\n",
      "<s> And I was scared . </s> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.evaluate(val_iter))\n",
    "print(len(train_iter))\n",
    "print(evaluator.attns_log[0][4])\n",
    "val_iter.init_epoch()\n",
    "batch = next(iter(val_iter))\n",
    "sent_inspect(batch, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that NMT{Trainer/Evaluator} extends\n",
    "class NMTModelUser(object):\n",
    "    # Models is a list [Encoder, Decoder]\n",
    "    def __init__(self, models, TEXT_SRC, TEXT_TRG, **kwargs):\n",
    "        self._TEXT_SRC = TEXT_SRC\n",
    "        self._TEXT_TRG = TEXT_TRG\n",
    "        self.trg_pad = TEXT_TRG.vocab.stoi['<pad>']\n",
    "        print('Target padding token: %d' % self.trg_pad)\n",
    "        self.models = models\n",
    "        self.use_attention = kwargs.get('attention', False)\n",
    "        self.record_attention = False\n",
    "        self.reverse_enc_input = kwargs.get('reverse_enc_input', False)\n",
    "        self.cuda = kwargs.get('cuda', True) and \\\n",
    "                    torch.cuda.is_available()\n",
    "        if self.cuda:\n",
    "            print('Using CUDA...')\n",
    "        else:\n",
    "            print('CUDA is unavailable...')\n",
    "\n",
    "    def get_src_and_trg(self, batch):\n",
    "        if self.reverse_enc_input:\n",
    "            src_data = torch.t(batch.src.data)\n",
    "            ind_rev = torch.LongTensor(np.arange(src_data.size(1) - 1, -1, -1))\n",
    "            src = torch.index_select(torch.t(batch.src.data), dim=1,\n",
    "                                     index=ind_rev)\n",
    "            src = src.contiguous()\n",
    "        else:\n",
    "            src = torch.t(batch.src.data).contiguous()\n",
    "        trg = torch.t(batch.trg.data)\n",
    "        # Have to shift the target so we don't predict the word \n",
    "        # we see (this is ok since sentences in trg all begin \n",
    "        # with <s>)\n",
    "        trg_feat = trg[:, :-1].contiguous()\n",
    "        trg_lab = trg[:, 1:].contiguous()\n",
    "        return (src, trg_feat, trg_lab)\n",
    "\n",
    "    def zeros_hidden(self, batch_sz, model_num):\n",
    "        return torch.zeros(self.models[model_num].num_layers, batch_sz,\n",
    "                           self.models[model_num].hidden_size)\n",
    "\n",
    "    # Ok to have self.prev_hidden apply to encoder then decoder since\n",
    "    # encoder all ends before decoder starts\n",
    "    def prepare_hidden(self, batch_sz, zero_out=True, model_num=0):\n",
    "        if (not self.prev_hidden is None) and (not zero_out):\n",
    "            pre_hidden = self.prev_hidden\n",
    "        else:\n",
    "            pre_hidden = (self.zeros_hidden(batch_sz, model_num) \\\n",
    "                          for i in range(2))\n",
    "        if self.cuda:\n",
    "            pre_hidden = tuple(t.cuda() for t in pre_hidden)\n",
    "        return tuple(autograd.Variable(t) for t in pre_hidden)\n",
    "\n",
    "    # kwargs can contain zero_out, model_num for prepare_hidden\n",
    "    def prepare_model_inputs(self, batch, **kwargs):\n",
    "        if self.cuda:\n",
    "            src, trg_feat, trg_lab = \\\n",
    "                tuple(t.cuda() for t in self.get_src_and_trg(batch))\n",
    "        else:\n",
    "            src, trg_feat, trg_lab = self.get_src_and_trg(batch)\n",
    "\n",
    "        # TODO: can comment this out (assuming it passes\n",
    "        # -- just is checking batch-sz)\n",
    "        assert batch.src.size(1) == batch.trg.size(1)\n",
    "        var_hidden = self.prepare_hidden(batch.src.size(1), **kwargs)\n",
    "\n",
    "        var_src = autograd.Variable(src)\n",
    "        var_trg_feat = autograd.Variable(trg_feat)\n",
    "        var_trg_lab = autograd.Variable(trg_lab)\n",
    "\n",
    "        return (var_src, var_trg_feat, var_trg_lab, var_hidden)\n",
    "\n",
    "    def init_epoch(self):\n",
    "        self.prev_hidden = None\n",
    "        self.debug_cnt = 0\n",
    "        \n",
    "    def debug_model_output(self, var_src, var_trg, dec_output,\n",
    "                           num_samp=10):\n",
    "        print('DEBUG CNT: %d' % self.debug_cnt)\n",
    "        print(var_src.size(), var_trg.size(), dec_output.size())\n",
    "        self.debug_cnt += 1\n",
    "        if self.debug_cnt > 10:\n",
    "            return\n",
    "        src = var_src.data\n",
    "        trg = var_trg.data\n",
    "        _, pred = torch.topk(dec_output, k=1, dim=2)\n",
    "        pred = pred.squeeze().data\n",
    "        print(pred.size()) # should be [batch_sz, sent_len]\n",
    "        for i in range(num_samp):\n",
    "            print('=== SAMPLE %d ===' % i)\n",
    "            print('-- SRC --')\n",
    "            print(' '.join(self._TEXT_SRC.vocab.itos[src[i,j]] \\\n",
    "                                           for j in range(src.size(1))))\n",
    "            print('-- REAL TRG --')\n",
    "            print(' '.join(self._TEXT_TRG.vocab.itos[trg[i,j]] \\\n",
    "                                           for j in range(trg.size(1))))\n",
    "            print('-- PRED TRG --')\n",
    "            print(' '.join(self._TEXT_TRG.vocab.itos[pred[i,j]] \\\n",
    "                                           for j in range(pred.size(1))))\n",
    "        \n",
    "        \n",
    "    def run_model(self, batch, mode='mean'):\n",
    "        # var_src, var_trg are [batch_sz, sent_len]\n",
    "        var_src, var_trg_feat, var_trg_lab, var_hidden = \\\n",
    "            self.prepare_model_inputs(\n",
    "            batch, zero_out=True, model_num=0)\n",
    "\n",
    "        # For attention, will use enc_output (not otherwise)\n",
    "        enc_output, enc_hidden = self.models[0](var_src, var_hidden)\n",
    "        self.prev_hidden = enc_hidden\n",
    "        if self.use_attention:\n",
    "            dec_output, dec_hidden, dec_attn = self.models[1](\n",
    "                var_trg_feat, self.prev_hidden, enc_output)\n",
    "            if self.record_attention:\n",
    "                self.attns_log.append(dec_attn)\n",
    "        else:\n",
    "            # Using real words as input. Use prev_hidden both to\n",
    "            # initialize hidden state (the first time) and as context\n",
    "            # vector\n",
    "            dec_output, dec_hidden = self.models[1](\n",
    "                var_trg_feat, self.prev_hidden, enc_hidden)\n",
    "            \n",
    "        # TEMPORARY\n",
    "        # self.debug_model_output(var_src, var_trg_lab, dec_output)\n",
    "        self.prev_hidden = dec_hidden\n",
    "        loss = self.nll_loss(dec_output, var_trg_lab, mode=mode)\n",
    "        return loss\n",
    "\n",
    "    # Assume log_probs is [batch_sz, sent_len, V], output is\n",
    "    # [batch_sz, sent_len]\n",
    "    def nll_loss(self, log_probs, output, mode='mean', **kwargs):\n",
    "        sent_len = log_probs.size(1)\n",
    "        log_probs_rshp = log_probs.view(-1, log_probs.size(2))\n",
    "        output_rshp = output.view(-1)\n",
    "        if mode == 'mean':\n",
    "            # Sum over all words in sent, mean over sentences; \n",
    "            # make sure to ignore padding\n",
    "            return F.nll_loss(log_probs_rshp, output_rshp, \n",
    "                              ignore_index=self.trg_pad, \n",
    "                              **kwargs) * sent_len\n",
    "        elif mode == 'sum':\n",
    "            # Sum over all sentences and words in them\n",
    "            return F.nll_loss(log_probs_rshp, output_rshp,\n",
    "                              ignore_index=self.trg_pad,\n",
    "                              size_average=False)\n",
    "        else:\n",
    "            raise ValueError('Invalid mode field: %s' % mode)\n",
    "                \n",
    "\n",
    "class NMTEvaluator(NMTModelUser):\n",
    "    def __init__(self, models, TEXT_SRC, TEXT_TRG, **kwargs):\n",
    "        super(NMTEvaluator, self).__init__(models, TEXT_SRC, TEXT_TRG,\n",
    "                                           **kwargs)\n",
    "        # Perhaps overwrite record_attention\n",
    "        self.record_attention = kwargs.get('record_attention', False)\n",
    "        \n",
    "    def init_epoch(self):\n",
    "        super(NMTEvaluator, self).init_epoch()\n",
    "        self.attns_log = list()\n",
    "\n",
    "    def evaluate(self, test_iter, num_iter=None):\n",
    "        start_time = time.time()\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "        nll_sum = 0\n",
    "        nll_cnt = 0\n",
    "\n",
    "        self.init_epoch()\n",
    "        test_iter.init_epoch()\n",
    "        for i,batch in enumerate(test_iter):\n",
    "            nll_cnt += batch.trg.data.numel()\n",
    "            loss = self.run_model(batch, mode='sum')\n",
    "            # TODO: make sure loss just has 1 element!\n",
    "            nll_sum += loss.data[0]\n",
    "            \n",
    "            if not num_iter is None and i > num_iter:\n",
    "                break\n",
    "                        \n",
    "        # Wrap the model.eval(), just in case\n",
    "        for model in self.models:\n",
    "            model.train()\n",
    "        \n",
    "        print('Validation time: %f seconds' % (time.time() - start_time))\n",
    "        return np.exp(nll_sum / nll_cnt)\n",
    "    \n",
    "    # Performs beam search\n",
    "    def run_model_predict(self, sent, ref_beam, ref_voc,\n",
    "                          beam_size=100, pred_len=3, pred_num=None):\n",
    "        if pred_num is None:\n",
    "            pred_num = beam_size\n",
    "        \n",
    "        # [sent_len]\n",
    "        sent_tsr = torch.LongTensor(sent)\n",
    "        if self.reverse_enc_input:\n",
    "            ind_rev = torch.LongTensor(np.arange(sent_tsr.size(0) - 1, -1, -1))\n",
    "            sent_tsr = torch.index_select(sent_tsr, dim=0,\n",
    "                                          index=ind_rev)\n",
    "        if self.cuda:\n",
    "            sent_tsr = sent_tsr.cuda()\n",
    "        var_src = autograd.Variable(sent_tsr.view(1, -1).expand(beam_size, -1))\n",
    "        var_hidden = self.prepare_hidden(beam_size, zero_out=True)\n",
    "        \n",
    "        # For attention, will use enc_output (not otherwise)\n",
    "        enc_output, enc_hidden = self.models[0](var_src, var_hidden)\n",
    "        self.prev_hidden = enc_hidden\n",
    "        \n",
    "        # Make sure to start with SOS token\n",
    "        sos_token = self._TEXT_TRG.vocab.stoi['<s>']\n",
    "        self.cur_beams = (sos_token * torch.ones(beam_size, 1)).type(torch.LongTensor)\n",
    "        self.cur_beam_vals = torch.zeros(beam_size, 1).type(torch.FloatTensor)\n",
    "        if self.cuda:\n",
    "            self.cur_beams = self.cur_beams.cuda()\n",
    "            self.cur_beam_vals = self.cur_beam_vals.cuda()\n",
    "        self.cur_beams = autograd.Variable(self.cur_beams)\n",
    "        self.cur_beam_vals = autograd.Variable(self.cur_beam_vals)\n",
    "        for i in range(pred_len):\n",
    "            cur_sent = self.cur_beams[:, i:i+1]\n",
    "            if self.use_attention:\n",
    "                dec_output, dec_hidden, dec_attn = self.models[1](\n",
    "                    cur_sent, self.prev_hidden, enc_output)\n",
    "                if self.record_attention:\n",
    "                    self.attns_log.append(dec_attn)\n",
    "            else:\n",
    "                # Using real words as input. Use prev_hidden both to\n",
    "                # initialize hidden state (the first time) and as context\n",
    "                # vector\n",
    "                dec_output, dec_hidden = self.models[1](\n",
    "                    cur_sent, self.prev_hidden, enc_hidden)\n",
    "            self.prev_hidden = dec_hidden\n",
    "            \n",
    "            # dec_output is [batch_sz, sent_len=1, V]\n",
    "            # print(dec_output.size())\n",
    "            # Using broadcasting:\n",
    "            dec_output = dec_output.squeeze() + self.cur_beam_vals\n",
    "            if i == 0:\n",
    "                # All start words were the same, so need to restrict \n",
    "                # to the first row\n",
    "                dec_output = dec_output[0, :]\n",
    "            else:\n",
    "                dec_output = dec_output.view(-1)\n",
    "                \n",
    "            topk_dec, topk_inds = torch.topk(dec_output, k=beam_size)\n",
    "            chosen_prev_inds = torch.index_select(ref_beam, dim=0, index=topk_inds)\n",
    "            chosen_prevs = torch.index_select(self.cur_beams, dim=0,\n",
    "                                              index=chosen_prev_inds)\n",
    "            # Important to update hidden to reflect which prev \n",
    "            # sents we choose\n",
    "            self.prev_hidden = tuple(torch.index_select(\n",
    "                    self.prev_hidden[j], dim=1, index=chosen_prev_inds) \\\n",
    "                                     for j in range(len(self.prev_hidden)))\n",
    "            \n",
    "            # Update self.cur_beam_vals: [beam_sz, 1] \n",
    "            # (we already added on prev cur_beam_vals above)\n",
    "            self.cur_beam_vals = topk_dec.view(-1, 1)\n",
    "            # print('cur_beam_vals', self.cur_beam_vals)\n",
    "\n",
    "            # [batch_sz=beam_sz, 1]\n",
    "            chosen_nexts = torch.index_select(ref_voc, dim=0, index=topk_inds).view(-1, 1)\n",
    "            # print('chosen_nexts', chosen_nexts)\n",
    "            self.cur_beams = torch.cat((chosen_prevs, chosen_nexts), dim=1)\n",
    "            # print('cur_beams', self.cur_beams)\n",
    "            \n",
    "        return self.cur_beams\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def escape(l):\n",
    "        return l.replace(\"\\\"\", \"<quote>\").replace(\",\", \"<comma>\")\n",
    "    \n",
    "    def predict(self, test_set, fn='predictions.txt', num_cands=100, pred_len=3,\n",
    "                beam_size=100):\n",
    "        start_time = time.time()\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "            \n",
    "        # Create reference idx for expanding beams and vocab\n",
    "        trg_vocab_sz = len(self._TEXT_TRG.vocab)\n",
    "        ref_beam = torch.LongTensor(np.arange(beam_size)).view(-1, 1).expand(-1, trg_vocab_sz)\n",
    "        ref_beam = ref_beam.contiguous().view(-1)\n",
    "        ref_beam = ref_beam.cuda() if self.cuda else ref_beam\n",
    "        ref_beam = autograd.Variable(ref_beam)\n",
    "        print(ref_beam.size())\n",
    "        \n",
    "        ref_voc = torch.LongTensor(np.arange(trg_vocab_sz)).view(1, -1).expand(beam_size, -1)\n",
    "        ref_voc = ref_voc.contiguous().view(-1)\n",
    "        ref_voc = ref_voc.cuda() if self.cuda else ref_voc\n",
    "        ref_voc = autograd.Variable(ref_voc)\n",
    "        print(ref_voc.size())\n",
    "            \n",
    "        self.init_epoch()\n",
    "        predictions = list()\n",
    "        for i,sent in enumerate(test_set):\n",
    "            # [pred_num, pred_len] tensor\n",
    "            best_translations = self.run_model_predict(sent, ref_beam=ref_beam,\n",
    "                                                       ref_voc=ref_voc,\n",
    "                                                       pred_len=pred_len,\n",
    "                                                       beam_size=beam_size)\n",
    "            predictions.append(best_translations)\n",
    "            # if i > 10:\n",
    "            #     break\n",
    "            \n",
    "        print('Writing predictions to %s...' % fn)\n",
    "        with open(fn, 'w') as fout:\n",
    "            print('id,word', file=fout)\n",
    "            for i,preds in enumerate(predictions):\n",
    "                # We can traverse the beam in order since topk \n",
    "                # sorts its output\n",
    "                cands = list()\n",
    "                for j in range(num_cands):\n",
    "                    # Ignore SOS\n",
    "                    words = [self._TEXT_TRG.vocab.itos[preds[j,k].data[0]] for k in range(1, pred_len + 1)]\n",
    "                    sent = '|'.join(self.escape(l) for l in words)\n",
    "                    cands.append(sent)\n",
    "                print('%d,%s' % (i+1, ' '.join(cands)), file=fout)\n",
    "        print('Computing predictions took %f seconds' % (time.time() - start_time))\n",
    "        \n",
    "        # Wrap model.eavl\n",
    "        for model in self.models:\n",
    "            model.train()\n",
    "            \n",
    "\n",
    "    \n",
    "class NMTTrainer(NMTModelUser):\n",
    "    def __init__(self, models, TEXT_SRC, TEXT_TRG, **kwargs):\n",
    "        super(NMTTrainer, self).__init__(models, TEXT_SRC, TEXT_TRG, **kwargs)\n",
    "\n",
    "        self.base_lrn_rate = kwargs.get('lrn_rate', 0.1)\n",
    "        self.optimizer_type = kwargs.get('optimizer', optim.SGD)\n",
    "        self.init_optimizers()\n",
    "\n",
    "        # Do learning rate decay:\n",
    "        self.lr_decay_opt = kwargs.get('lrn_decay', 'none')\n",
    "        if self.lr_decay_opt == 'none' or self.lr_decay_opt == 'adaptive':\n",
    "            self.lambda_lr = lambda i : 1\n",
    "        elif self.lr_decay_opt == 'invlin':\n",
    "            decay_rate = kwargs.get('lrn_decay_rate', 0.1)\n",
    "            self.lambda_lr = lambda i : 1 / (1 + (i-6) * decay_rate) if i > 6 else 1\n",
    "        else:\n",
    "            raise ValueError('Invalid learning rate decay option: %s' \\\n",
    "                             % self.lr_decay_opt)\n",
    "        self.schedulers = [optim.lr_scheduler.LambdaLR(optimizer,\n",
    "            self.lambda_lr) for optimizer in self.optimizers]\n",
    "\n",
    "        self.clip_norm = kwargs.get('clip_norm', 10)\n",
    "        self.init_lists()\n",
    "        if self.cuda:\n",
    "            for model in self.models:\n",
    "                model.cuda()\n",
    "                \n",
    "    def init_optimizers(self):\n",
    "        self.optimizers = [self.optimizer_type(filter(lambda p : p.requires_grad,\n",
    "                                                      model.parameters()),\n",
    "                                               lr = self.base_lrn_rate) for \\\n",
    "                           model in self.models]\n",
    "    def init_lists(self):\n",
    "        self.training_losses = list()\n",
    "        self.training_norms = list()\n",
    "        self.val_perfs = list()\n",
    "\n",
    "    def get_loss_data(self, loss):\n",
    "        if self.cuda:\n",
    "            return loss.data.cpu().numpy()[0]\n",
    "        else:\n",
    "            return loss.data.numpy()[0]\n",
    "\n",
    "    def make_recordings(self, loss, norm):\n",
    "        self.training_norms.append(norm)\n",
    "        self.training_losses.append(loss)\n",
    "\n",
    "    def clip_norms(self):\n",
    "        # Clip grad norm after backward but before step\n",
    "        if self.clip_norm > 0:\n",
    "            parameters = tuple()\n",
    "            for model in self.models:\n",
    "                parameters += tuple(model.parameters())\n",
    "                \n",
    "            # Norm clipping: returns a float\n",
    "            norm = nn.utils.clip_grad_norm(\n",
    "                parameters, self.clip_norm)\n",
    "        else:\n",
    "            norm = -1\n",
    "        return norm\n",
    "\n",
    "    def train_batch(self, batch, **kwargs):\n",
    "        for model in self.models:\n",
    "            model.zero_grad()\n",
    "            \n",
    "        loss = self.run_model(batch)\n",
    "        loss.backward()\n",
    "\n",
    "        # norms must be clipped after backward but before step\n",
    "        norm = self.clip_norms()\n",
    "\n",
    "        loss_data = self.get_loss_data(loss)\n",
    "        # print('TEMP: ', loss_data, norm)\n",
    "        if kwargs.get('verbose', False):\n",
    "            self.make_recordings(loss_data, norm)\n",
    "\n",
    "        for optimizer in self.optimizers:\n",
    "            optimizer.step()\n",
    "\n",
    "        # Return loss and norm (before gradient step)\n",
    "        return loss_data, norm\n",
    "\n",
    "    def init_parameters(self):\n",
    "        for model in self.models:\n",
    "            for p in model.parameters():\n",
    "                p.data.uniform_(-0.05, 0.05)\n",
    "\n",
    "    def train(self, torch_train_iter, le=None, val_iter=None, **kwargs):\n",
    "        self.init_lists()\n",
    "        start_time = time.time()\n",
    "        self.init_parameters()\n",
    "        torch_train_iter.init_epoch()\n",
    "        for epoch in range(kwargs.get('num_iter', 100)):\n",
    "            self.init_epoch()\n",
    "            for model in self.models:\n",
    "                model.train()\n",
    "                \n",
    "            # Learning rate decay, if any\n",
    "            if self.lr_decay_opt == 'adaptive':\n",
    "                if epoch > 2 and self.val_perfs[-1] > self.val_perfs[-2]:\n",
    "                    self.base_lrn_rate = self.base_lrn_rate / 2\n",
    "                    self.init_optimizers() # Looks at self.base_lrn_rate\n",
    "                    print('Decaying LR to %f' % self.base_lrn_rate)\n",
    "            else:\n",
    "                for scheduler in self.schedulers:\n",
    "                    scheduler.step()\n",
    "\n",
    "            # TODO: LR decay\n",
    "            train_iter = iter(torch_train_iter)\n",
    "\n",
    "            for batch in train_iter:\n",
    "                res_loss, res_norm = self.train_batch(batch, **kwargs)\n",
    "\n",
    "            if epoch % kwargs.get('skip_iter', 1) == 0:\n",
    "                if not kwargs.get('verbose', False):\n",
    "                    self.make_recordings(res_loss, res_norm)\n",
    "\n",
    "            print('Epoch %d, loss: %f, norm: %f, elapsed: %f, lrn_rate: %f' \\\n",
    "                  % (epoch, np.mean(self.training_losses[-10:]),\n",
    "                     np.mean(self.training_norms[-10:]),\n",
    "                     time.time() - start_time,\n",
    "                     self.base_lrn_rate)) #  * self.lambda_lr(epoch)))\n",
    "                    \n",
    "            \n",
    "            if (not le is None) and (not val_iter is None):\n",
    "                self.val_perfs.append(le.evaluate(val_iter))\n",
    "                print('Validation set metric: %f' % \\\n",
    "                      self.val_perfs[-1])\n",
    "\n",
    "        if len(self.val_perfs) >= 1:\n",
    "            print('FINAL VAL PERF', self.val_perfs[-1])\n",
    "            return self.val_perfs[-1]\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<s>\n"
     ]
    }
   ],
   "source": [
    "print(EN.vocab.stoi['<s>'])\n",
    "print(EN.vocab.itos[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## OLD STUFF BELOW HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
