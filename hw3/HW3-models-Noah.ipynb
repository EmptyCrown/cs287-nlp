{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text text processing library\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import Vectors\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "# from models import *\n",
    "# from helpers import *\n",
    "# import main\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import time\n",
    "MAX_LEN = 20\n",
    "MIN_FREQ = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "DE = data.Field(tokenize=tokenize_de)\n",
    "\n",
    "# only target needs BOS/EOS:\n",
    "EN = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, eos_token = EOS_WORD) \n",
    "\n",
    "train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(DE, EN), \n",
    "                                         filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
    "                                         len(vars(x)['trg']) <= MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "EN.build_vocab(train.trg, min_freq=MIN_FREQ)\n",
    "\n",
    "pred_set = []\n",
    "for i, line in enumerate(open(\"source_test.txt\"), 1):\n",
    "    words = line.split()[:-1]\n",
    "    pred_set.append([DE.vocab.stoi[s] for s in words])\n",
    "\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits((train, val, test), batch_size=32, device=-1,\n",
    "                                                  repeat=False, sort_key=lambda x: len(x.src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_iter))\n",
    "# sent_inspect(batch,4)\n",
    "def sent_inspect(batch, idx=0):\n",
    "    print(\"Source\")\n",
    "    print(' '.join([DE.vocab.itos[w] for w in batch.src.data[:,idx]]))\n",
    "    print(\"Target\")\n",
    "    print(' '.join([EN.vocab.itos[w] for w in batch.trg.data[:,idx]]))\n",
    "# print(DE.vocab.stoi['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wo sich der Lauf des <unk> früher befand .\n",
      "<s> We started to be able to see where the <unk> used to flow . </s> <pad> <pad>\n",
      "Das führte mich dazu , Satellitenbilder zu benutzen .\n",
      "<s> This is really what brought me to using satellite imagery . </s> <pad> <pad> <pad> <pad> <pad>\n",
      "Wie unterscheidet sich diese Geschichte von der anderen ?\n",
      "<s> How is this story different ? </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Im Raum war ein junger Mann , <unk> .\n",
      "<s> One of the young men in the room was <unk> . </s> <pad> <pad> <pad> <pad> <pad>\n",
      "Ich brachte rund 90 junge <unk> Führungskräfte zusammen .\n",
      "<s> I brought together about 90 young Somali leaders . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Es vergeht vielleicht ein Jahr , aber nichts .\n",
      "<s> Maybe a year passes , nothing . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Sein Dorf liegt in der Nähe von <unk> .\n",
      "<s> His village is near <unk> . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Ich denke , diese beiden Figuren sind Experten .\n",
      "<s> I think these people are experts . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Vielleicht ist es nicht nur das <unk> Kleid .\n",
      "<s> Maybe it 's not just the <unk> dress . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Wer sind diese Typen ? Was lernen sie ?\n",
      "<s> Who are these guys ? What are they learning ? </s> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(' '.join(DE.vocab.itos[w] for w in debug_set[i]))\n",
    "    print(' '.join(EN.vocab.itos[w] for w in debug_ans[i]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Validation time: 1.223257 seconds\n",
      "6.50678771148015\n",
      "Validation time: 0.874000 seconds\n",
      "5.119931039703331\n",
      "torch.Size([1156000])\n",
      "torch.Size([1156000])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([4, 100, 500])\n",
      "torch.Size([100, 12, 500])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-53be48ff7758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdebug_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdebug_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predictions.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-112-431ea039050a>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_set, fn, num_cands, pred_len, beam_size)\u001b[0m\n\u001b[1;32m    289\u001b[0m                                                        \u001b[0mref_voc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref_voc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                                                        \u001b[0mpred_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                                                        beam_size=beam_size)\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_translations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;31m# if i > 10:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-431ea039050a>\u001b[0m in \u001b[0;36mrun_model_predict\u001b[0;34m(self, sent, ref_beam, ref_voc, beam_size, pred_len, pred_num)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 dec_output, dec_hidden, dec_attn = self.models[1](\n\u001b[0;32m--> 214\u001b[0;31m                     cur_sent, self.prev_hidden, enc_output)\n\u001b[0m\u001b[1;32m    215\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattns_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_attn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-9351a5d8997f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tsr, hidden, enc_output)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# [batch_sz, sent_len_trg, hidden_sz * 2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "# evaluator = NMTEvaluator([bs_encoder, bs_decoder], DE, EN, reverse_enc_input=False)\n",
    "evaluator = NMTEvaluator([bs_encoder, bs_decoder], DE, EN, attention=True,\n",
    "                        record_attention=True)\n",
    "print(evaluator.evaluate(test_iter))\n",
    "print(evaluator.evaluate(val_iter))\n",
    "test_iter.init_epoch()\n",
    "debug_iter = iter(test_iter)\n",
    "for i in range(10):\n",
    "    batch = next(debug_iter)\n",
    "debug_set = [batch.src.data[:, i] for i in range(batch.src.data.size(1))]\n",
    "debug_ans = [batch.trg.data[:, i] for i in range(batch.trg.data.size(1))]\n",
    "evaluator.predict(pred_set, fn='predictions.txt',beam_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Epoch 0, loss: 75.106003, norm: 5.068851, elapsed: 601.591950, lrn_rate: 0.700000\n",
      "Validation time: 1.177268 seconds\n",
      "Validation set metric: 15.046797\n",
      "Epoch 1, loss: 64.709015, norm: 6.823921, elapsed: 1202.462563, lrn_rate: 0.700000\n",
      "Validation time: 1.123111 seconds\n",
      "Validation set metric: 10.318951\n",
      "Epoch 2, loss: 55.162987, norm: 5.810015, elapsed: 1815.646121, lrn_rate: 0.700000\n",
      "Validation time: 1.158648 seconds\n",
      "Validation set metric: 8.200983\n",
      "Epoch 3, loss: 48.013638, norm: 6.298200, elapsed: 2430.358610, lrn_rate: 0.700000\n",
      "Validation time: 1.222892 seconds\n",
      "Validation set metric: 7.256750\n",
      "Epoch 4, loss: 55.855797, norm: 8.171973, elapsed: 3034.166331, lrn_rate: 0.700000\n",
      "Validation time: 1.161787 seconds\n",
      "Validation set metric: 7.055706\n",
      "Epoch 5, loss: 51.494362, norm: 9.309718, elapsed: 3637.575163, lrn_rate: 0.700000\n",
      "Validation time: 1.184436 seconds\n",
      "Validation set metric: 7.108363\n",
      "Decaying LR to 0.350000\n",
      "Epoch 6, loss: 34.349045, norm: 8.055377, elapsed: 4239.637285, lrn_rate: 0.350000\n",
      "Validation time: 1.196922 seconds\n",
      "Validation set metric: 6.700641\n",
      "Epoch 7, loss: 26.329096, norm: 8.606746, elapsed: 4846.299028, lrn_rate: 0.350000\n",
      "Validation time: 1.140525 seconds\n",
      "Validation set metric: 7.049315\n",
      "Decaying LR to 0.175000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-ffd2c44189bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                      lrn_decay='adaptive', reverse_enc_input=False)\n\u001b[1;32m      7\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNMTEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs_decoder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_enc_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-78-565b039c9b12>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, torch_train_iter, le, val_iter, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m                 \u001b[0mres_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_iter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-565b039c9b12>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, batch, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-565b039c9b12>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(self, batch, mode)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# For attention, will use enc_output (not otherwise)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-cab290137def>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tsr, hidden)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# output is [batch, sent_len, hidden_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_tsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# TODO: perhaps add dropout to output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# init descriptors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_rnn_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_input_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_descs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptor_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36minit_rnn_descriptor\u001b[0;34m(fn, handle)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, hidden_size, num_layers, dropout_desc, input_mode, bidirectional, mode, datatype)\u001b[0m\n\u001b[1;32m    259\u001b[0m             ))\n\u001b[1;32m    260\u001b[0m             if version() >= 7000 and int(cuda[0]) >= 9 and (\n\u001b[0;32m--> 261\u001b[0;31m                     torch.cuda.get_device_capability(torch.cuda.current_device())[0] >= 7):\n\u001b[0m\u001b[1;32m    262\u001b[0m                 \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnnSetRNNMatrixMathType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCUDNN_DEFAULT_MATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdatatype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCUDNN_DATA_HALF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \"\"\"\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDeviceCapability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=32, device=-1,\n",
    "                                                  repeat=False, sort_key=lambda x: len(x.src))\n",
    "bs_encoder = BaseEncoder(DE, hidden_size=500, num_layers=4, word_features=500)\n",
    "bs_decoder = BaseDecoder(EN, hidden_size=500, num_layers=4, word_features=500)\n",
    "trainer = NMTTrainer([bs_encoder, bs_decoder], DE, EN, lrn_rate=0.7, \n",
    "                     lrn_decay='adaptive', reverse_enc_input=False)\n",
    "evaluator = NMTEvaluator([bs_encoder, bs_decoder], DE, EN, reverse_enc_input=False)\n",
    "trainer.train(train_iter, verbose=True, le=evaluator, val_iter=val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Epoch 0, loss: 83.176491, norm: 3.746789, elapsed: 515.477625, lrn_rate: 1.000000\n",
      "Validation time: 0.759316 seconds\n",
      "Validation set metric: 19.221707\n",
      "Epoch 1, loss: 72.469406, norm: 5.242597, elapsed: 1034.874019, lrn_rate: 1.000000\n",
      "Validation time: 0.888308 seconds\n",
      "Validation set metric: 13.506300\n",
      "Epoch 2, loss: 58.292755, norm: 5.588605, elapsed: 1554.866436, lrn_rate: 1.000000\n",
      "Validation time: 0.862921 seconds\n",
      "Validation set metric: 8.196184\n",
      "Epoch 3, loss: 51.758568, norm: 5.508223, elapsed: 2074.353652, lrn_rate: 1.000000\n",
      "Validation time: 0.833768 seconds\n",
      "Validation set metric: 6.917161\n",
      "Epoch 4, loss: 56.023895, norm: 7.027678, elapsed: 2593.641258, lrn_rate: 1.000000\n",
      "Validation time: 0.888862 seconds\n",
      "Validation set metric: 6.134933\n",
      "Epoch 5, loss: 55.090607, norm: 7.383235, elapsed: 3114.329509, lrn_rate: 1.000000\n",
      "Validation time: 1.042574 seconds\n",
      "Validation set metric: 5.983735\n",
      "Epoch 6, loss: 44.098995, norm: 5.809587, elapsed: 3634.523306, lrn_rate: 1.000000\n",
      "Validation time: 0.858635 seconds\n",
      "Validation set metric: 5.463597\n",
      "Epoch 7, loss: 37.983429, norm: 5.829877, elapsed: 4154.521350, lrn_rate: 1.000000\n",
      "Validation time: 0.898083 seconds\n",
      "Validation set metric: 5.374710\n",
      "Epoch 8, loss: 44.963371, norm: 7.506575, elapsed: 4674.869794, lrn_rate: 1.000000\n",
      "Validation time: 0.919314 seconds\n",
      "Validation set metric: 5.333633\n",
      "Epoch 9, loss: 37.157150, norm: 6.094870, elapsed: 5194.792014, lrn_rate: 1.000000\n",
      "Validation time: 0.802078 seconds\n",
      "Validation set metric: 5.223052\n",
      "Epoch 10, loss: 38.162254, norm: 6.529943, elapsed: 5714.575189, lrn_rate: 1.000000\n",
      "Validation time: 0.835940 seconds\n",
      "Validation set metric: 5.254713\n",
      "Decaying LR to 0.500000\n",
      "Epoch 11, loss: 36.005363, norm: 7.582915, elapsed: 6232.610036, lrn_rate: 0.500000\n",
      "Validation time: 0.947821 seconds\n",
      "Validation set metric: 4.950667\n",
      "Epoch 12, loss: 31.702383, norm: 7.502112, elapsed: 6751.638925, lrn_rate: 0.500000\n",
      "Validation time: 0.898122 seconds\n",
      "Validation set metric: 5.044491\n",
      "Decaying LR to 0.250000\n",
      "Epoch 13, loss: 32.586933, norm: 8.140395, elapsed: 7269.620758, lrn_rate: 0.250000\n",
      "Validation time: 0.920062 seconds\n",
      "Validation set metric: 4.956082\n",
      "Epoch 14, loss: 29.804617, norm: 9.098230, elapsed: 7790.068539, lrn_rate: 0.250000\n",
      "Validation time: 0.784312 seconds\n",
      "Validation set metric: 5.009990\n",
      "Decaying LR to 0.125000\n",
      "Epoch 15, loss: 30.206015, norm: 7.111377, elapsed: 8308.423026, lrn_rate: 0.125000\n",
      "Validation time: 0.950300 seconds\n",
      "Validation set metric: 5.037210\n",
      "Decaying LR to 0.062500\n",
      "Epoch 16, loss: 21.619503, norm: 6.205873, elapsed: 8827.253728, lrn_rate: 0.062500\n",
      "Validation time: 0.969957 seconds\n",
      "Validation set metric: 5.066791\n",
      "Decaying LR to 0.031250\n",
      "Epoch 17, loss: 28.178364, norm: 6.829421, elapsed: 9348.215830, lrn_rate: 0.031250\n",
      "Validation time: 0.885076 seconds\n",
      "Validation set metric: 5.089316\n",
      "Decaying LR to 0.015625\n",
      "Epoch 18, loss: 24.815063, norm: 6.600173, elapsed: 9868.576959, lrn_rate: 0.015625\n",
      "Validation time: 0.941633 seconds\n",
      "Validation set metric: 5.108117\n",
      "Decaying LR to 0.007812\n",
      "Epoch 19, loss: 24.905247, norm: 6.679171, elapsed: 10387.413462, lrn_rate: 0.007812\n",
      "Validation time: 0.840421 seconds\n",
      "Validation set metric: 5.117567\n",
      "Decaying LR to 0.003906\n",
      "Epoch 20, loss: 25.450674, norm: 6.822869, elapsed: 10905.752376, lrn_rate: 0.003906\n",
      "Validation time: 0.827390 seconds\n",
      "Validation set metric: 5.117723\n",
      "Decaying LR to 0.001953\n",
      "Epoch 21, loss: 27.964306, norm: 7.105347, elapsed: 11426.610017, lrn_rate: 0.001953\n",
      "Validation time: 0.781154 seconds\n",
      "Validation set metric: 5.118726\n",
      "Decaying LR to 0.000977\n",
      "Epoch 22, loss: 25.319170, norm: 6.779187, elapsed: 11946.168790, lrn_rate: 0.000977\n",
      "Validation time: 0.839791 seconds\n",
      "Validation set metric: 5.119132\n",
      "Decaying LR to 0.000488\n",
      "Epoch 23, loss: 25.685074, norm: 7.967643, elapsed: 12465.322422, lrn_rate: 0.000488\n",
      "Validation time: 0.939803 seconds\n",
      "Validation set metric: 5.119069\n",
      "Epoch 24, loss: 24.749802, norm: 8.242546, elapsed: 12983.777748, lrn_rate: 0.000488\n",
      "Validation time: 0.919218 seconds\n",
      "Validation set metric: 5.119702\n",
      "Decaying LR to 0.000244\n",
      "Epoch 25, loss: 25.666189, norm: 6.990434, elapsed: 13505.451954, lrn_rate: 0.000244\n",
      "Validation time: 0.831452 seconds\n",
      "Validation set metric: 5.119858\n",
      "Decaying LR to 0.000122\n",
      "Epoch 26, loss: 22.252066, norm: 6.408266, elapsed: 14024.532576, lrn_rate: 0.000122\n",
      "Validation time: 0.955368 seconds\n",
      "Validation set metric: 5.119885\n",
      "Decaying LR to 0.000061\n",
      "Epoch 27, loss: 20.617489, norm: 6.223866, elapsed: 14548.008499, lrn_rate: 0.000061\n",
      "Validation time: 0.905301 seconds\n",
      "Validation set metric: 5.119902\n",
      "Decaying LR to 0.000031\n",
      "Epoch 28, loss: 22.118996, norm: 7.349809, elapsed: 15067.157704, lrn_rate: 0.000031\n",
      "Validation time: 0.866088 seconds\n",
      "Validation set metric: 5.119910\n",
      "Decaying LR to 0.000015\n",
      "Epoch 29, loss: 22.410397, norm: 7.793635, elapsed: 15584.904989, lrn_rate: 0.000015\n",
      "Validation time: 0.870584 seconds\n",
      "Validation set metric: 5.119918\n",
      "Decaying LR to 0.000008\n",
      "Epoch 30, loss: 25.644001, norm: 6.857036, elapsed: 16102.810249, lrn_rate: 0.000008\n",
      "Validation time: 0.816334 seconds\n",
      "Validation set metric: 5.119924\n",
      "Decaying LR to 0.000004\n",
      "Epoch 31, loss: 22.231678, norm: 8.080176, elapsed: 16622.405443, lrn_rate: 0.000004\n",
      "Validation time: 0.851670 seconds\n",
      "Validation set metric: 5.119930\n",
      "Decaying LR to 0.000002\n",
      "Epoch 32, loss: 21.761997, norm: 7.287412, elapsed: 17141.945284, lrn_rate: 0.000002\n",
      "Validation time: 0.906827 seconds\n",
      "Validation set metric: 5.119931\n",
      "Decaying LR to 0.000001\n",
      "Epoch 33, loss: 21.998257, norm: 7.612686, elapsed: 17660.897064, lrn_rate: 0.000001\n",
      "Validation time: 0.921872 seconds\n",
      "Validation set metric: 5.119931\n",
      "Decaying LR to 0.000000\n",
      "Epoch 34, loss: 28.442316, norm: 8.448991, elapsed: 18181.485749, lrn_rate: 0.000000\n",
      "Validation time: 0.911381 seconds\n",
      "Validation set metric: 5.119931\n",
      "Epoch 35, loss: 22.906559, norm: 6.685839, elapsed: 18701.278195, lrn_rate: 0.000000\n",
      "Validation time: 0.978718 seconds\n",
      "Validation set metric: 5.119930\n",
      "Epoch 36, loss: 29.210825, norm: 8.679964, elapsed: 19221.051364, lrn_rate: 0.000000\n",
      "Validation time: 0.794243 seconds\n",
      "Validation set metric: 5.119931\n",
      "Decaying LR to 0.000000\n",
      "Epoch 37, loss: 26.786243, norm: 8.219278, elapsed: 19739.964454, lrn_rate: 0.000000\n",
      "Validation time: 0.951206 seconds\n",
      "Validation set metric: 5.119931\n",
      "Decaying LR to 0.000000\n",
      "Epoch 38, loss: 25.951084, norm: 6.925014, elapsed: 20260.160848, lrn_rate: 0.000000\n",
      "Validation time: 1.029469 seconds\n",
      "Validation set metric: 5.119931\n",
      "Decaying LR to 0.000000\n",
      "Epoch 39, loss: 23.543003, norm: 6.565401, elapsed: 20778.442291, lrn_rate: 0.000000\n",
      "Validation time: 0.831677 seconds\n",
      "Validation set metric: 5.119931\n",
      "Decaying LR to 0.000000\n",
      "Epoch 40, loss: 22.966290, norm: 6.585102, elapsed: 21297.046720, lrn_rate: 0.000000\n",
      "Validation time: 0.780371 seconds\n",
      "Validation set metric: 5.119931\n",
      "Epoch 41, loss: 28.401987, norm: 7.768453, elapsed: 21814.660664, lrn_rate: 0.000000\n",
      "Validation time: 0.880733 seconds\n",
      "Validation set metric: 5.119931\n",
      "Decaying LR to 0.000000\n",
      "Epoch 42, loss: 21.668522, norm: 7.392604, elapsed: 22333.160199, lrn_rate: 0.000000\n",
      "Validation time: 0.923808 seconds\n",
      "Validation set metric: 5.119931\n",
      "Epoch 43, loss: 24.953512, norm: 6.644859, elapsed: 22853.408767, lrn_rate: 0.000000\n",
      "Validation time: 0.994757 seconds\n",
      "Validation set metric: 5.119931\n",
      "Decaying LR to 0.000000\n",
      "Epoch 44, loss: 26.988134, norm: 7.168770, elapsed: 23372.000985, lrn_rate: 0.000000\n",
      "Validation time: 0.894938 seconds\n",
      "Validation set metric: 5.119931\n",
      "Decaying LR to 0.000000\n",
      "Epoch 45, loss: 23.698666, norm: 7.522518, elapsed: 23892.273753, lrn_rate: 0.000000\n",
      "Validation time: 0.853760 seconds\n",
      "Validation set metric: 5.119931\n",
      "Epoch 46, loss: 25.464840, norm: 8.102078, elapsed: 24411.285478, lrn_rate: 0.000000\n",
      "Validation time: 0.904450 seconds\n",
      "Validation set metric: 5.119931\n",
      "Epoch 47, loss: 24.421209, norm: 8.297881, elapsed: 24930.582967, lrn_rate: 0.000000\n",
      "Validation time: 1.044139 seconds\n",
      "Validation set metric: 5.119931\n",
      "Epoch 48, loss: 22.473215, norm: 6.263699, elapsed: 25449.598230, lrn_rate: 0.000000\n",
      "Validation time: 1.076120 seconds\n",
      "Validation set metric: 5.119931\n",
      "Decaying LR to 0.000000\n",
      "Epoch 49, loss: 23.943804, norm: 8.272730, elapsed: 25967.766212, lrn_rate: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation time: 0.868033 seconds\n",
      "Validation set metric: 5.119931\n",
      "Decaying LR to 0.000000\n",
      "Epoch 50, loss: 25.068045, norm: 8.173462, elapsed: 26487.876106, lrn_rate: 0.000000\n",
      "Validation time: 0.804122 seconds\n",
      "Validation set metric: 5.119931\n",
      "Epoch 51, loss: 23.197910, norm: 6.603655, elapsed: 27007.840163, lrn_rate: 0.000000\n",
      "Validation time: 0.846102 seconds\n",
      "Validation set metric: 5.119931\n",
      "Decaying LR to 0.000000\n",
      "Epoch 52, loss: 26.191601, norm: 6.955893, elapsed: 27526.307991, lrn_rate: 0.000000\n",
      "Validation time: 0.977962 seconds\n",
      "Validation set metric: 5.119931\n",
      "Epoch 53, loss: 22.765911, norm: 6.720936, elapsed: 28044.532676, lrn_rate: 0.000000\n",
      "Validation time: 0.966261 seconds\n",
      "Validation set metric: 5.119931\n",
      "Decaying LR to 0.000000\n",
      "Epoch 54, loss: 26.660145, norm: 7.047979, elapsed: 28563.961328, lrn_rate: 0.000000\n",
      "Validation time: 0.835158 seconds\n",
      "Validation set metric: 5.119931\n",
      "Epoch 55, loss: 26.209167, norm: 7.166502, elapsed: 29081.288782, lrn_rate: 0.000000\n",
      "Validation time: 0.868330 seconds\n",
      "Validation set metric: 5.119931\n",
      "Epoch 56, loss: 22.015854, norm: 6.588799, elapsed: 29598.685349, lrn_rate: 0.000000\n",
      "Validation time: 0.904294 seconds\n",
      "Validation set metric: 5.119931\n",
      "Epoch 57, loss: 20.720049, norm: 6.190250, elapsed: 30115.698690, lrn_rate: 0.000000\n",
      "Validation time: 0.875719 seconds\n",
      "Validation set metric: 5.119931\n",
      "Decaying LR to 0.000000\n",
      "Epoch 58, loss: 24.634663, norm: 7.896603, elapsed: 30634.417482, lrn_rate: 0.000000\n",
      "Validation time: 1.007468 seconds\n",
      "Validation set metric: 5.119931\n",
      "Epoch 59, loss: 24.044754, norm: 7.929625, elapsed: 31152.055806, lrn_rate: 0.000000\n",
      "Validation time: 0.970904 seconds\n",
      "Validation set metric: 5.119931\n",
      "Epoch 60, loss: 24.639431, norm: 8.415324, elapsed: 31671.640083, lrn_rate: 0.000000\n",
      "Validation time: 0.931188 seconds\n",
      "Validation set metric: 5.119931\n",
      "Decaying LR to 0.000000\n",
      "Epoch 61, loss: 27.782751, norm: 8.292831, elapsed: 32189.043280, lrn_rate: 0.000000\n",
      "Validation time: 0.839493 seconds\n",
      "Validation set metric: 5.119931\n",
      "Epoch 62, loss: 27.690781, norm: 8.940691, elapsed: 32707.182029, lrn_rate: 0.000000\n",
      "Validation time: 0.868084 seconds\n",
      "Validation set metric: 5.119931\n",
      "Decaying LR to 0.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-c597f9b25c3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m evaluator = NMTEvaluator([bs_encoder, bs_decoder], DE, EN, attention=True,\n\u001b[1;32m      9\u001b[0m                         record_attention=True)\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-105-b7b3a07a8e7c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, torch_train_iter, le, val_iter, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m                 \u001b[0mres_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_iter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-b7b3a07a8e7c>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, batch, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-b7b3a07a8e7c>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(self, batch, mode)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# For attention, will use enc_output (not otherwise)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-9351a5d8997f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tsr, hidden)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# output is [batch, sent_len, hidden_size * num_directions]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_tsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# TODO: perhaps add dropout to output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# init descriptors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_rnn_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_input_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_descs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptor_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36minit_rnn_descriptor\u001b[0;34m(fn, handle)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, hidden_size, num_layers, dropout_desc, input_mode, bidirectional, mode, datatype)\u001b[0m\n\u001b[1;32m    259\u001b[0m             ))\n\u001b[1;32m    260\u001b[0m             if version() >= 7000 and int(cuda[0]) >= 9 and (\n\u001b[0;32m--> 261\u001b[0;31m                     torch.cuda.get_device_capability(torch.cuda.current_device())[0] >= 7):\n\u001b[0m\u001b[1;32m    262\u001b[0m                 \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnnSetRNNMatrixMathType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCUDNN_DEFAULT_MATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdatatype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCUDNN_DATA_HALF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \"\"\"\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDeviceCapability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=32, device=-1,\n",
    "                                                  repeat=False, sort_key=lambda x: len(x.src))\n",
    "bs_encoder = BaseEncoder(DE, hidden_size=500, num_layers=4, word_features=500, dropout=0.2)\n",
    "# TODO: decide whether to add dropout to output states of encoder!\n",
    "bs_decoder = AttnDecoder(EN, hidden_size=500, num_layers=4, word_features=500, dropout=0.2)\n",
    "trainer = NMTTrainer([bs_encoder, bs_decoder], DE, EN, lrn_rate=1.0, \n",
    "                     lrn_decay='adaptive', attention=True)\n",
    "evaluator = NMTEvaluator([bs_encoder, bs_decoder], DE, EN, attention=True,\n",
    "                        record_attention=True)\n",
    "trainer.train(train_iter, verbose=True, le=evaluator, val_iter=val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation time: 0.456792 seconds\n",
      "6.048956472651303\n",
      "3722\n",
      "Variable containing:\n",
      " 0.6505  0.1110  0.0659  0.1725\n",
      " 0.5297  0.1554  0.2806  0.0343\n",
      " 0.0089  0.4239  0.4734  0.0938\n",
      " 0.0180  0.0371  0.9122  0.0327\n",
      " 0.0822  0.0702  0.3141  0.5335\n",
      " 0.4222  0.2591  0.0997  0.2190\n",
      " 0.1612  0.3041  0.4915  0.0432\n",
      " 0.2962  0.4637  0.0781  0.1620\n",
      "[torch.cuda.FloatTensor of size 8x4 (GPU 0)]\n",
      "\n",
      "Source\n",
      "Ich hatte Angst –\n",
      "Target\n",
      "<s> And I was scared . </s> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.evaluate(val_iter))\n",
    "print(len(train_iter))\n",
    "print(evaluator.attns_log[0][4])\n",
    "val_iter.init_epoch()\n",
    "batch = next(iter(val_iter))\n",
    "sent_inspect(batch, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "[20, 35, 0, 8, 4811, 0, 3351, 14, 9129]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsLM(nn.Module):\n",
    "    def __init__(self, TEXT, dropout=0.0, max_embed_norm=None, word_features=1000):\n",
    "        super(EmbeddingsLM, self).__init__()\n",
    "        # Initialize dropout\n",
    "        self.dropout_prob = dropout\n",
    "        self.dropout = nn.Dropout(self.dropout_prob)\n",
    "        \n",
    "        # V is size of vocab, D is dim of embedding\n",
    "        self.V = len(TEXT.vocab)\n",
    "        self.D = word_features\n",
    "        self.embeddings = nn.Embedding(self.V, self.D, max_norm=max_embed_norm)\n",
    "\n",
    "class BaseEncoder(EmbeddingsLM):\n",
    "    def __init__(self, TEXT, hidden_size=1000, num_layers=4,\n",
    "                 bidirectional=False, **kwargs):\n",
    "        super(BaseEncoder, self).__init__(TEXT, **kwargs)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.lstm = nn.LSTM(input_size=self.D, hidden_size=self.hidden_size,\n",
    "                            num_layers=self.num_layers,\n",
    "                            dropout=self.dropout_prob, batch_first=True,\n",
    "                            bidirectional=self.bidirectional)\n",
    "        \n",
    "    def forward(self, input_tsr, hidden):\n",
    "        # [batch_sz, sent_len, D]:\n",
    "        embedded_tsr = self.embeddings(input_tsr)\n",
    "\n",
    "        # output is [batch, sent_len, hidden_size * num_directions]\n",
    "        output, hidden = self.lstm(embedded_tsr, hidden)\n",
    "        \n",
    "        # TODO: perhaps add dropout to output\n",
    "        return output, hidden\n",
    "\n",
    "class BaseDecoder(BaseEncoder):\n",
    "    def __init__(self, TEXT, num_context=1, enc_bidirectional=False, **kwargs):\n",
    "        super(BaseDecoder, self).__init__(TEXT, **kwargs)\n",
    "        # V is the size of the vocab, which is what we're predicting\n",
    "        # (it's also used as input through the embedding)\n",
    "        self.num_context = num_context\n",
    "        self.enc_directions = 2 if enc_bidirectional else 1\n",
    "        # For now assume that encoder and decoder have same hidden size\n",
    "        blowup = self.num_context * self.num_layers * self.enc_directions + 1\n",
    "        self.out_linear = nn.Linear(\n",
    "            blowup * self.hidden_size, self.V)\n",
    "\n",
    "    # Context is a tuple (h_T, c_T) of hidden and cell states from\n",
    "    # last time step of encoder\n",
    "    def forward(self, input_tsr, hidden, context):\n",
    "        # [batch_sz, sent_len, D] : note that sent_len may be 1 if we\n",
    "        # feed in each word at a time!\n",
    "        embedding = self.embeddings(input_tsr)\n",
    "        embedding = F.relu(embedding)\n",
    "        output, hidden = self.lstm(embedding, hidden)\n",
    "\n",
    "        if self.num_context:\n",
    "            # We get lucky that hidden is stored as (h,c), \n",
    "            # so hidden (not cell) first\n",
    "            context_tsr = torch.cat(context[:self.num_context])\n",
    "            batch_sz = context_tsr.size(1)\n",
    "            sent_len = output.size(1)\n",
    "            # [batch_sz, 1, hidden_size * num_context]\n",
    "            context_tsr = context_tsr.permute(1,0,2).contiguous().view(batch_sz, 1, -1)\n",
    "            context_tsr = context_tsr.expand(-1, sent_len, -1)\n",
    "            # [batch_sz, sent_len, hidden_sz * (num_context + 1)]\n",
    "            output = torch.cat((output, context_tsr), dim=2)\n",
    "\n",
    "        # output is now [batch, sent_len, V]:\n",
    "        output = self.out_linear(output)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        return output, hidden\n",
    "\n",
    "class AttnDecoder(BaseEncoder):\n",
    "    def __init__(self, TEXT, enc_bidirectional=False, **kwargs):\n",
    "        super(AttnDecoder, self).__init__(TEXT, **kwargs)\n",
    "        self.enc_directions = 2 if enc_bidirectional else 1\n",
    "        blowup = self.enc_directions + 1 # one for our output, one or two for context\n",
    "        self.out_linear = nn.Linear(blowup * self.hidden_size, self.V)\n",
    "        \n",
    "    def forward(self, input_tsr, hidden, enc_output):\n",
    "        # [batch_sz, sent_len, D]:\n",
    "        embedding = self.embeddings(input_tsr)\n",
    "        embedding = F.relu(embedding)\n",
    "        dec_output, hidden = self.lstm(embedding, hidden)\n",
    "        \n",
    "        # Now do attention: enc_output is [batch_sz, sent_len_src, hidden_sz],\n",
    "        # and dec_output is [batch_sz, sent_len_trg, hidden_sz]\n",
    "        \n",
    "        # enc_output_perm is [batch_sz, hidden_sz, sent_len_src]\n",
    "        enc_output_perm = enc_output.permute(0, 2, 1)\n",
    "        \n",
    "        # should be [batch_sz, sent_len_trg, sent_len_src]\n",
    "        # Note that decoder hidden state for output pos t is compouted \n",
    "        # using hidden state of the last layer (i.e. enc_output) at pos t\n",
    "        # as opposed to t-1, as in Bahdanau\n",
    "        dot_products = torch.bmm(dec_output, enc_output_perm)\n",
    "        \n",
    "        # This is the attn distribution\n",
    "        dot_products_sftmx = F.softmax(dot_products, dim=2)\n",
    "        \n",
    "        # [batch_sz, sent_len_trg, hidden_sz]\n",
    "        context = torch.bmm(dot_products_sftmx, enc_output)\n",
    "        \n",
    "        # [batch_sz, sent_len_trg, hidden_sz * 2]\n",
    "        output = torch.cat((dec_output, context), dim=2)\n",
    "        output = self.dropout(output)\n",
    "        output = self.out_linear(output)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        return output, hidden, dot_products_sftmx      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTModelUser(object):\n",
    "    # Models is a list [Encoder, Decoder]\n",
    "    def __init__(self, models, TEXT_SRC, TEXT_TRG, **kwargs):\n",
    "        self._TEXT_SRC = TEXT_SRC\n",
    "        self._TEXT_TRG = TEXT_TRG\n",
    "        self.trg_pad = TEXT_TRG.vocab.stoi['<pad>']\n",
    "        print('Target padding token: %d' % self.trg_pad)\n",
    "        self.models = models\n",
    "        self.use_attention = kwargs.get('attention', False)\n",
    "        self.record_attention = False\n",
    "        self.reverse_enc_input = kwargs.get('reverse_enc_input', False)\n",
    "        self.cuda = kwargs.get('cuda', True) and \\\n",
    "                    torch.cuda.is_available()\n",
    "        if self.cuda:\n",
    "            print('Using CUDA...')\n",
    "        else:\n",
    "            print('CUDA is unavailable...')\n",
    "\n",
    "    def get_src_and_trg(self, batch):\n",
    "        if self.reverse_enc_input:\n",
    "            src_data = torch.t(batch.src.data)\n",
    "            ind_rev = torch.LongTensor(np.arange(src_data.size(1) - 1, -1, -1))\n",
    "            src = torch.index_select(torch.t(batch.src.data), dim=1,\n",
    "                                     index=ind_rev)\n",
    "            src = src.contiguous()\n",
    "        else:\n",
    "            src = torch.t(batch.src.data).contiguous()\n",
    "        trg = torch.t(batch.trg.data)\n",
    "        # Have to shift the target so we don't predict the word \n",
    "        # we see (this is ok since sentences in trg all begin \n",
    "        # with <s>)\n",
    "        trg_feat = trg[:, :-1].contiguous()\n",
    "        trg_lab = trg[:, 1:].contiguous()\n",
    "        return (src, trg_feat, trg_lab)\n",
    "\n",
    "    def zeros_hidden(self, batch_sz, model_num):\n",
    "        return torch.zeros(self.models[model_num].num_layers, batch_sz,\n",
    "                           self.models[model_num].hidden_size)\n",
    "\n",
    "    # Ok to have self.prev_hidden apply to encoder then decoder since\n",
    "    # encoder all ends before decoder starts\n",
    "    def prepare_hidden(self, batch_sz, zero_out=True, model_num=0):\n",
    "        if (not self.prev_hidden is None) and (not zero_out):\n",
    "            pre_hidden = self.prev_hidden\n",
    "        else:\n",
    "            pre_hidden = (self.zeros_hidden(batch_sz, model_num) \\\n",
    "                          for i in range(2))\n",
    "        if self.cuda:\n",
    "            pre_hidden = tuple(t.cuda() for t in pre_hidden)\n",
    "        return tuple(autograd.Variable(t) for t in pre_hidden)\n",
    "\n",
    "    # kwargs can contain zero_out, model_num for prepare_hidden\n",
    "    def prepare_model_inputs(self, batch, **kwargs):\n",
    "        if self.cuda:\n",
    "            src, trg_feat, trg_lab = \\\n",
    "                tuple(t.cuda() for t in self.get_src_and_trg(batch))\n",
    "        else:\n",
    "            src, trg_feat, trg_lab = self.get_src_and_trg(batch)\n",
    "\n",
    "        # TODO: can comment this out (assuming it passes\n",
    "        # -- just is checking batch-sz)\n",
    "        assert batch.src.size(1) == batch.trg.size(1)\n",
    "        var_hidden = self.prepare_hidden(batch.src.size(1), **kwargs)\n",
    "\n",
    "        var_src = autograd.Variable(src)\n",
    "        var_trg_feat = autograd.Variable(trg_feat)\n",
    "        var_trg_lab = autograd.Variable(trg_lab)\n",
    "\n",
    "        return (var_src, var_trg_feat, var_trg_lab, var_hidden)\n",
    "\n",
    "    def init_epoch(self):\n",
    "        self.prev_hidden = None\n",
    "        self.debug_cnt = 0\n",
    "        \n",
    "    def debug_model_output(self, var_src, var_trg, dec_output,\n",
    "                           num_samp=10):\n",
    "        print('DEBUG CNT: %d' % self.debug_cnt)\n",
    "        print(var_src.size(), var_trg.size(), dec_output.size())\n",
    "        self.debug_cnt += 1\n",
    "        if self.debug_cnt > 10:\n",
    "            return\n",
    "        src = var_src.data\n",
    "        trg = var_trg.data\n",
    "        _, pred = torch.topk(dec_output, k=1, dim=2)\n",
    "        pred = pred.squeeze().data\n",
    "        print(pred.size()) # should be [batch_sz, sent_len]\n",
    "        for i in range(num_samp):\n",
    "            print('=== SAMPLE %d ===' % i)\n",
    "            print('-- SRC --')\n",
    "            print(' '.join(self._TEXT_SRC.vocab.itos[src[i,j]] \\\n",
    "                                           for j in range(src.size(1))))\n",
    "            print('-- REAL TRG --')\n",
    "            print(' '.join(self._TEXT_TRG.vocab.itos[trg[i,j]] \\\n",
    "                                           for j in range(trg.size(1))))\n",
    "            print('-- PRED TRG --')\n",
    "            print(' '.join(self._TEXT_TRG.vocab.itos[pred[i,j]] \\\n",
    "                                           for j in range(pred.size(1))))\n",
    "        \n",
    "        \n",
    "    def run_model(self, batch, mode='mean'):\n",
    "        # var_src, var_trg are [batch_sz, sent_len]\n",
    "        var_src, var_trg_feat, var_trg_lab, var_hidden = \\\n",
    "            self.prepare_model_inputs(\n",
    "            batch, zero_out=True, model_num=0)\n",
    "\n",
    "        # For attention, will use enc_output (not otherwise)\n",
    "        enc_output, enc_hidden = self.models[0](var_src, var_hidden)\n",
    "        self.prev_hidden = enc_hidden\n",
    "        if self.use_attention:\n",
    "            dec_output, dec_hidden, dec_attn = self.models[1](\n",
    "                var_trg_feat, self.prev_hidden, enc_output)\n",
    "            if self.record_attention:\n",
    "                self.attns_log.append(dec_attn)\n",
    "        else:\n",
    "            # Using real words as input. Use prev_hidden both to\n",
    "            # initialize hidden state (the first time) and as context\n",
    "            # vector\n",
    "            dec_output, dec_hidden = self.models[1](\n",
    "                var_trg_feat, self.prev_hidden, enc_hidden)\n",
    "            \n",
    "        # TEMPORARY\n",
    "        # self.debug_model_output(var_src, var_trg_lab, dec_output)\n",
    "        self.prev_hidden = dec_hidden\n",
    "        loss = self.nll_loss(dec_output, var_trg_lab, mode=mode)\n",
    "        return loss\n",
    "\n",
    "    # Assume log_probs is [batch_sz, sent_len, V], output is\n",
    "    # [batch_sz, sent_len]\n",
    "    def nll_loss(self, log_probs, output, mode='mean', **kwargs):\n",
    "        sent_len = log_probs.size(1)\n",
    "        log_probs_rshp = log_probs.view(-1, log_probs.size(2))\n",
    "        output_rshp = output.view(-1)\n",
    "        if mode == 'mean':\n",
    "            # Sum over all words in sent, mean over sentences; \n",
    "            # make sure to ignore padding\n",
    "            return F.nll_loss(log_probs_rshp, output_rshp, \n",
    "                              ignore_index=self.trg_pad, \n",
    "                              **kwargs) * sent_len\n",
    "        elif mode == 'sum':\n",
    "            # Sum over all sentences and words in them\n",
    "            return F.nll_loss(log_probs_rshp, output_rshp,\n",
    "                              ignore_index=self.trg_pad,\n",
    "                              size_average=False)\n",
    "        else:\n",
    "            raise ValueError('Invalid mode field: %s' % mode)\n",
    "                \n",
    "\n",
    "class NMTEvaluator(NMTModelUser):\n",
    "    def __init__(self, models, TEXT_SRC, TEXT_TRG, **kwargs):\n",
    "        super(NMTEvaluator, self).__init__(models, TEXT_SRC, TEXT_TRG,\n",
    "                                           **kwargs)\n",
    "        # Perhaps overwrite record_attention\n",
    "        self.record_attention = kwargs.get('record_attention', False)\n",
    "        \n",
    "    def init_epoch(self):\n",
    "        super(NMTEvaluator, self).init_epoch()\n",
    "        self.attns_log = list()\n",
    "\n",
    "    def evaluate(self, test_iter, num_iter=None):\n",
    "        start_time = time.time()\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "        nll_sum = 0\n",
    "        nll_cnt = 0\n",
    "\n",
    "        self.init_epoch()\n",
    "        test_iter.init_epoch()\n",
    "        for i,batch in enumerate(test_iter):\n",
    "            nll_cnt += batch.trg.data.numel()\n",
    "            loss = self.run_model(batch, mode='sum')\n",
    "            # TODO: make sure loss just has 1 element!\n",
    "            nll_sum += loss.data[0]\n",
    "            \n",
    "            if not num_iter is None and i > num_iter:\n",
    "                break\n",
    "                        \n",
    "        # Wrap the model.eval(), just in case\n",
    "        for model in self.models:\n",
    "            model.train()\n",
    "        \n",
    "        print('Validation time: %f seconds' % (time.time() - start_time))\n",
    "        return np.exp(nll_sum / nll_cnt)\n",
    "    \n",
    "    # Performs beam search\n",
    "    def run_model_predict(self, sent, ref_beam, ref_voc,\n",
    "                          beam_size=100, pred_len=3, pred_num=None):\n",
    "        if pred_num is None:\n",
    "            pred_num = beam_size\n",
    "        \n",
    "        # [sent_len]\n",
    "        sent_tsr = torch.LongTensor(sent)\n",
    "        if self.reverse_enc_input:\n",
    "            ind_rev = torch.LongTensor(np.arange(sent_tsr.size(0) - 1, -1, -1))\n",
    "            sent_tsr = torch.index_select(sent_tsr, dim=0,\n",
    "                                          index=ind_rev)\n",
    "        if self.cuda:\n",
    "            sent_tsr = sent_tsr.cuda()\n",
    "        var_src = autograd.Variable(sent_tsr.view(1, -1).expand(beam_size, -1))\n",
    "        var_hidden = self.prepare_hidden(beam_size, zero_out=True)\n",
    "        \n",
    "        # For attention, will use enc_output (not otherwise)\n",
    "        enc_output, enc_hidden = self.models[0](var_src, var_hidden)\n",
    "        self.prev_hidden = enc_hidden\n",
    "        \n",
    "        # Make sure to start with SOS token\n",
    "        sos_token = self._TEXT_TRG.vocab.stoi['<s>']\n",
    "        self.cur_beams = (sos_token * torch.ones(beam_size, 1)).type(torch.LongTensor)\n",
    "        self.cur_beam_vals = torch.zeros(beam_size, 1).type(torch.FloatTensor)\n",
    "        if self.cuda:\n",
    "            self.cur_beams = self.cur_beams.cuda()\n",
    "            self.cur_beam_vals = self.cur_beam_vals.cuda()\n",
    "        self.cur_beams = autograd.Variable(self.cur_beams)\n",
    "        self.cur_beam_vals = autograd.Variable(self.cur_beam_vals)\n",
    "        for i in range(pred_len):\n",
    "            cur_sent = self.cur_beams[:, i:i+1]\n",
    "            if self.use_attention:\n",
    "                print(cur_sent.size())\n",
    "                print(self.prev_hidden[0].size())\n",
    "                print(enc_output.size())\n",
    "                dec_output, dec_hidden, dec_attn = self.models[1](\n",
    "                    cur_sent, self.prev_hidden, enc_output)\n",
    "                if self.record_attention:\n",
    "                    self.attns_log.append(dec_attn)\n",
    "            else:\n",
    "                # Using real words as input. Use prev_hidden both to\n",
    "                # initialize hidden state (the first time) and as context\n",
    "                # vector\n",
    "                dec_output, dec_hidden = self.models[1](\n",
    "                    cur_sent, self.prev_hidden, enc_hidden)\n",
    "            self.prev_hidden = dec_hidden\n",
    "            \n",
    "            # dec_output is [batch_sz, sent_len=1, V]\n",
    "            # print(dec_output.size())\n",
    "            # Using broadcasting:\n",
    "            dec_output = dec_output.squeeze() + self.cur_beam_vals\n",
    "            if i == 0:\n",
    "                # All start words were the same, so need to restrict \n",
    "                # to the first row\n",
    "                dec_output = dec_output[0, :]\n",
    "            else:\n",
    "                dec_output = dec_output.view(-1)\n",
    "                \n",
    "            topk_dec, topk_inds = torch.topk(dec_output, k=beam_size)\n",
    "            chosen_prev_inds = torch.index_select(ref_beam, dim=0, index=topk_inds)\n",
    "            chosen_prevs = torch.index_select(self.cur_beams, dim=0,\n",
    "                                              index=chosen_prev_inds)\n",
    "            # Important to update hidden to reflect which prev \n",
    "            # sents we choose\n",
    "            self.prev_hidden = tuple(torch.index_select(\n",
    "                    self.prev_hidden[j], dim=1, index=chosen_prev_inds) \\\n",
    "                                     for j in range(len(self.prev_hidden)))\n",
    "            \n",
    "            # Update self.cur_beam_vals: [beam_sz, 1] \n",
    "            # (we already added on prev cur_beam_vals above)\n",
    "            self.cur_beam_vals = topk_dec.view(-1, 1)\n",
    "            # print('cur_beam_vals', self.cur_beam_vals)\n",
    "\n",
    "            # [batch_sz=beam_sz, 1]\n",
    "            chosen_nexts = torch.index_select(ref_voc, dim=0, index=topk_inds).view(-1, 1)\n",
    "            # print('chosen_nexts', chosen_nexts)\n",
    "            self.cur_beams = torch.cat((chosen_prevs, chosen_nexts), dim=1)\n",
    "            # print('cur_beams', self.cur_beams)\n",
    "            \n",
    "        return self.cur_beams\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def escape(l):\n",
    "        return l.replace(\"\\\"\", \"<quote>\").replace(\",\", \"<comma>\")\n",
    "    \n",
    "    def predict(self, test_set, fn='predictions.txt', num_cands=100, pred_len=3,\n",
    "                beam_size=100):\n",
    "        start_time = time.time()\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "            \n",
    "        # Create reference idx for expanding beams and vocab\n",
    "        trg_vocab_sz = len(self._TEXT_TRG.vocab)\n",
    "        ref_beam = torch.LongTensor(np.arange(beam_size)).view(-1, 1).expand(-1, trg_vocab_sz)\n",
    "        ref_beam = ref_beam.contiguous().view(-1)\n",
    "        ref_beam = ref_beam.cuda() if self.cuda else ref_beam\n",
    "        ref_beam = autograd.Variable(ref_beam)\n",
    "        print(ref_beam.size())\n",
    "        \n",
    "        ref_voc = torch.LongTensor(np.arange(trg_vocab_sz)).view(1, -1).expand(beam_size, -1)\n",
    "        ref_voc = ref_voc.contiguous().view(-1)\n",
    "        ref_voc = ref_voc.cuda() if self.cuda else ref_voc\n",
    "        ref_voc = autograd.Variable(ref_voc)\n",
    "        print(ref_voc.size())\n",
    "            \n",
    "        self.init_epoch()\n",
    "        predictions = list()\n",
    "        for i,sent in enumerate(test_set):\n",
    "            # [pred_num, pred_len] tensor\n",
    "            best_translations = self.run_model_predict(sent, ref_beam=ref_beam,\n",
    "                                                       ref_voc=ref_voc,\n",
    "                                                       pred_len=pred_len,\n",
    "                                                       beam_size=beam_size)\n",
    "            predictions.append(best_translations)\n",
    "            # if i > 10:\n",
    "            #     break\n",
    "            \n",
    "        print('Writing predictions to %s...' % fn)\n",
    "        with open(fn, 'w') as fout:\n",
    "            print('id,word', file=fout)\n",
    "            for i,preds in enumerate(predictions):\n",
    "                # We can traverse the beam in order since topk \n",
    "                # sorts its output\n",
    "                cands = list()\n",
    "                for j in range(num_cands):\n",
    "                    # Ignore SOS\n",
    "                    words = [self._TEXT_TRG.vocab.itos[preds[j,k].data[0]] for k in range(1, pred_len + 1)]\n",
    "                    sent = '|'.join(self.escape(l) for l in words)\n",
    "                    cands.append(sent)\n",
    "                print('%d,%s' % (i+1, ' '.join(cands)), file=fout)\n",
    "        print('Computing predictions took %f seconds' % (time.time() - start_time))\n",
    "        \n",
    "        # Wrap model.eavl\n",
    "        for model in self.models:\n",
    "            model.train()\n",
    "            \n",
    "\n",
    "    \n",
    "class NMTTrainer(NMTModelUser):\n",
    "    def __init__(self, models, TEXT_SRC, TEXT_TRG, **kwargs):\n",
    "        super(NMTTrainer, self).__init__(models, TEXT_SRC, TEXT_TRG, **kwargs)\n",
    "\n",
    "        self.base_lrn_rate = kwargs.get('lrn_rate', 0.1)\n",
    "        self.optimizer_type = kwargs.get('optimizer', optim.SGD)\n",
    "        self.init_optimizers()\n",
    "\n",
    "        # Do learning rate decay:\n",
    "        self.lr_decay_opt = kwargs.get('lrn_decay', 'none')\n",
    "        if self.lr_decay_opt == 'none' or self.lr_decay_opt == 'adaptive':\n",
    "            self.lambda_lr = lambda i : 1\n",
    "        elif self.lr_decay_opt == 'invlin':\n",
    "            decay_rate = kwargs.get('lrn_decay_rate', 0.1)\n",
    "            self.lambda_lr = lambda i : 1 / (1 + (i-6) * decay_rate) if i > 6 else 1\n",
    "        else:\n",
    "            raise ValueError('Invalid learning rate decay option: %s' \\\n",
    "                             % self.lr_decay_opt)\n",
    "        self.schedulers = [optim.lr_scheduler.LambdaLR(optimizer,\n",
    "            self.lambda_lr) for optimizer in self.optimizers]\n",
    "\n",
    "        self.clip_norm = kwargs.get('clip_norm', 10)\n",
    "        self.init_lists()\n",
    "        if self.cuda:\n",
    "            for model in self.models:\n",
    "                model.cuda()\n",
    "                \n",
    "    def init_optimizers(self):\n",
    "        self.optimizers = [self.optimizer_type(filter(lambda p : p.requires_grad,\n",
    "                                                      model.parameters()),\n",
    "                                               lr = self.base_lrn_rate) for \\\n",
    "                           model in self.models]\n",
    "    def init_lists(self):\n",
    "        self.training_losses = list()\n",
    "        self.training_norms = list()\n",
    "        self.val_perfs = list()\n",
    "\n",
    "    def get_loss_data(self, loss):\n",
    "        if self.cuda:\n",
    "            return loss.data.cpu().numpy()[0]\n",
    "        else:\n",
    "            return loss.data.numpy()[0]\n",
    "\n",
    "    def make_recordings(self, loss, norm):\n",
    "        self.training_norms.append(norm)\n",
    "        self.training_losses.append(loss)\n",
    "\n",
    "    def clip_norms(self):\n",
    "        # Clip grad norm after backward but before step\n",
    "        if self.clip_norm > 0:\n",
    "            parameters = tuple()\n",
    "            for model in self.models:\n",
    "                parameters += tuple(model.parameters())\n",
    "                \n",
    "            # Norm clipping: returns a float\n",
    "            norm = nn.utils.clip_grad_norm(\n",
    "                parameters, self.clip_norm)\n",
    "        else:\n",
    "            norm = -1\n",
    "        return norm\n",
    "\n",
    "    def train_batch(self, batch, **kwargs):\n",
    "        for model in self.models:\n",
    "            model.zero_grad()\n",
    "            \n",
    "        loss = self.run_model(batch)\n",
    "        loss.backward()\n",
    "\n",
    "        # norms must be clipped after backward but before step\n",
    "        norm = self.clip_norms()\n",
    "\n",
    "        loss_data = self.get_loss_data(loss)\n",
    "        # print('TEMP: ', loss_data, norm)\n",
    "        if kwargs.get('verbose', False):\n",
    "            self.make_recordings(loss_data, norm)\n",
    "\n",
    "        for optimizer in self.optimizers:\n",
    "            optimizer.step()\n",
    "\n",
    "        # Return loss and norm (before gradient step)\n",
    "        return loss_data, norm\n",
    "\n",
    "    def init_parameters(self):\n",
    "        for model in self.models:\n",
    "            for p in model.parameters():\n",
    "                p.data.uniform_(-0.05, 0.05)\n",
    "\n",
    "    def train(self, torch_train_iter, le=None, val_iter=None, **kwargs):\n",
    "        self.init_lists()\n",
    "        start_time = time.time()\n",
    "        self.init_parameters()\n",
    "        torch_train_iter.init_epoch()\n",
    "        for epoch in range(kwargs.get('num_iter', 100)):\n",
    "            self.init_epoch()\n",
    "            for model in self.models:\n",
    "                model.train()\n",
    "                \n",
    "            # Learning rate decay, if any\n",
    "            if self.lr_decay_opt == 'adaptive':\n",
    "                if epoch > 2 and self.val_perfs[-1] > self.val_perfs[-2]:\n",
    "                    self.base_lrn_rate = self.base_lrn_rate / 2\n",
    "                    self.init_optimizers() # Looks at self.base_lrn_rate\n",
    "                    print('Decaying LR to %f' % self.base_lrn_rate)\n",
    "            else:\n",
    "                for scheduler in self.schedulers:\n",
    "                    scheduler.step()\n",
    "\n",
    "            # TODO: LR decay\n",
    "            train_iter = iter(torch_train_iter)\n",
    "\n",
    "            for batch in train_iter:\n",
    "                res_loss, res_norm = self.train_batch(batch, **kwargs)\n",
    "\n",
    "            if epoch % kwargs.get('skip_iter', 1) == 0:\n",
    "                if not kwargs.get('verbose', False):\n",
    "                    self.make_recordings(res_loss, res_norm)\n",
    "\n",
    "            print('Epoch %d, loss: %f, norm: %f, elapsed: %f, lrn_rate: %f' \\\n",
    "                  % (epoch, np.mean(self.training_losses[-10:]),\n",
    "                     np.mean(self.training_norms[-10:]),\n",
    "                     time.time() - start_time,\n",
    "                     self.base_lrn_rate)) #  * self.lambda_lr(epoch)))\n",
    "                    \n",
    "            \n",
    "            if (not le is None) and (not val_iter is None):\n",
    "                self.val_perfs.append(le.evaluate(val_iter))\n",
    "                print('Validation set metric: %f' % \\\n",
    "                      self.val_perfs[-1])\n",
    "\n",
    "        if len(self.val_perfs) >= 1:\n",
    "            print('FINAL VAL PERF', self.val_perfs[-1])\n",
    "            return self.val_perfs[-1]\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<s>\n"
     ]
    }
   ],
   "source": [
    "print(EN.vocab.stoi['<s>'])\n",
    "print(EN.vocab.itos[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## OLD STUFF BELOW HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsLM(nn.Module):\n",
    "    def __init__(self, TEXT, **kwargs):\n",
    "        super(EmbeddingsLM, self).__init__()\n",
    "        # Initialize dropout\n",
    "        self.dropout_prob = kwargs.get('dropout', 0.0)\n",
    "        self.dropout = nn.Dropout(self.dropout_prob)\n",
    "        \n",
    "        # V is size of vocab, D is dim of embedding\n",
    "        self.V = len(TEXT.vocab)\n",
    "        max_embed_norm = kwargs.get('max_embed_norm', None)\n",
    "        self.D = kwargs.get('word_features', 1000)\n",
    "        self.embeddings = nn.Embedding(self.V, self.D, max_norm=max_embed_norm)\n",
    "\n",
    "class BaseEncoder(EmbeddingsLM):\n",
    "    def __init__(self, TEXT, **kwargs):\n",
    "        super(BaseEncoder, self).__init__(TEXT, **kwargs)\n",
    "        self.hidden_size = kwargs.get('hidden_size', 1000)\n",
    "        self.num_layers = kwargs.get('num_layers', 4)\n",
    "        self.lstm = nn.LSTM(input_size=self.D, hidden_size=self.hidden_size,\n",
    "                            num_layers=self.num_layers,\n",
    "                            dropout=self.dropout_prob, batch_first=True)\n",
    "        \n",
    "    def forward(self, input_tsr, hidden):\n",
    "        # [batch_sz, sent_len, D]:\n",
    "        embedded_tsr = self.embeddings(input_tsr)\n",
    "\n",
    "        # output is [batch, sent_len, hidden_size]\n",
    "        output, hidden = self.lstm(embedded_tsr, hidden)\n",
    "        \n",
    "        # TODO: perhaps add dropout to output\n",
    "        return output, hidden\n",
    "\n",
    "class BaseDecoder(BaseEncoder):\n",
    "    def __init__(self, TEXT, **kwargs):\n",
    "        super(BaseDecoder, self).__init__(TEXT, **kwargs)\n",
    "        # V is the size of the vocab, which is what we're predicting\n",
    "        # (it's also used as input through the embedding)\n",
    "        self.num_context = kwargs.get('num_context', 1)\n",
    "        # For now assume that encoder and decoder have same hidden size\n",
    "        blowup = self.num_context * self.num_layers + 1\n",
    "        self.out_linear = nn.Linear(blowup * self.hidden_size, self.V)\n",
    "\n",
    "    # Context is a tuple (h_T, c_T) of hidden and cell states from\n",
    "    # last time step of encoder\n",
    "    def forward(self, input_tsr, hidden, context):\n",
    "        # [batch_sz, sent_len, D] : note that sent_len may be 1 if we\n",
    "        # feed in each word at a time!\n",
    "        embedding = self.embeddings(input_tsr)\n",
    "        embedding = F.relu(embedding)\n",
    "        output, hidden = self.lstm(embedding, hidden)\n",
    "\n",
    "        if self.num_context:\n",
    "            # We get lucky that hidden is stored as (h,c), \n",
    "            # so hidden (not cell) first\n",
    "            context_tsr = torch.cat(context[:self.num_context])\n",
    "            batch_sz = context_tsr.size(1)\n",
    "            sent_len = output.size(1)\n",
    "            # [batch_sz, 1, hidden_size * num_context]\n",
    "            context_tsr = context_tsr.permute(1,0,2).contiguous().view(batch_sz, 1, -1)\n",
    "            context_tsr = context_tsr.expand(-1, sent_len, -1)\n",
    "            # [batch_sz, sent_len, hidden_sz * (num_context + 1)]\n",
    "            output = torch.cat((output, context_tsr), dim=2)\n",
    "\n",
    "        # output is now [batch, sent_len, V]:\n",
    "        output = self.out_linear(output)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        return output, hidden\n",
    "\n",
    "class AttnDecoder(BaseEncoder):\n",
    "    def __init__(self, TEXT, **kwargs):\n",
    "        super(AttnDecoder, self).__init__(TEXT, **kwargs)\n",
    "        # TODO: more setup\n",
    "        \n",
    "    def forward(self, input_tsr, hidden, encoder_output):\n",
    "        # [batch_sz, sent_len, D]:\n",
    "        embedding = self.embeddings(input_tsr)\n",
    "        embedding = F.relu(embedding)\n",
    "        output, hidden = self.lstm(embedding, hidden)\n",
    "        \n",
    "        # Now do attention: encoder_output is [batch_sz, sent_len"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
