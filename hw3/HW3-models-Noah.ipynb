{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text text processing library\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import Vectors\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "from models import *\n",
    "from helpers import *\n",
    "# import main\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import time\n",
    "import itertools as it\n",
    "MAX_LEN = 20\n",
    "MIN_FREQ = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "DE = data.Field(tokenize=tokenize_de)\n",
    "\n",
    "# only target needs BOS/EOS:\n",
    "EN = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, eos_token = EOS_WORD) \n",
    "\n",
    "train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(DE, EN), \n",
    "                                         filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
    "                                         len(vars(x)['trg']) <= MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "EN.build_vocab(train.trg, min_freq=MIN_FREQ)\n",
    "\n",
    "pred_set = []\n",
    "for i, line in enumerate(open(\"source_test.txt\"), 1):\n",
    "    words = line.split()[:-1]\n",
    "    pred_set.append([DE.vocab.stoi[s] for s in words])\n",
    "\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits((train, val, test), batch_size=32, device=-1,\n",
    "                                                  repeat=False, sort_key=lambda x: len(x.src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = next(iter(test_iter))\n",
    "# sent_inspect(batch,4)\n",
    "def sent_inspect(batch, idx=0):\n",
    "    print(\"Source\")\n",
    "    print(' '.join([DE.vocab.itos[w] for w in batch.src.data[:,idx]]))\n",
    "    print(\"Target\")\n",
    "    print(' '.join([EN.vocab.itos[w] for w in batch.trg.data[:,idx]]))\n",
    "# print(DE.vocab.stoi['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wo sich der Lauf des <unk> früher befand .\n",
      "<s> We started to be able to see where the <unk> used to flow . </s> <pad> <pad>\n",
      "Das führte mich dazu , Satellitenbilder zu benutzen .\n",
      "<s> This is really what brought me to using satellite imagery . </s> <pad> <pad> <pad> <pad> <pad>\n",
      "Wie unterscheidet sich diese Geschichte von der anderen ?\n",
      "<s> How is this story different ? </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Im Raum war ein junger Mann , <unk> .\n",
      "<s> One of the young men in the room was <unk> . </s> <pad> <pad> <pad> <pad> <pad>\n",
      "Ich brachte rund 90 junge <unk> Führungskräfte zusammen .\n",
      "<s> I brought together about 90 young Somali leaders . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Es vergeht vielleicht ein Jahr , aber nichts .\n",
      "<s> Maybe a year passes , nothing . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Sein Dorf liegt in der Nähe von <unk> .\n",
      "<s> His village is near <unk> . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Ich denke , diese beiden Figuren sind Experten .\n",
      "<s> I think these people are experts . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Vielleicht ist es nicht nur das <unk> Kleid .\n",
      "<s> Maybe it 's not just the <unk> dress . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Wer sind diese Typen ? Was lernen sie ?\n",
      "<s> Who are these guys ? What are they learning ? </s> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(' '.join(DE.vocab.itos[w] for w in debug_set[i]))\n",
    "    print(' '.join(EN.vocab.itos[w] for w in debug_ans[i]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3468000])\n",
      "torch.Size([3468000])\n",
      "Writing predictions to predictions_real_300_eos-2.txt...\n",
      "Computing predictions took 325.554955 seconds\n"
     ]
    }
   ],
   "source": [
    "save_checkpoint(bs_encoder, at_decoder, filename='saved_models/attn_big_0.epoch_10.ckpt.tar')\n",
    "evaluator.predict(pred_set, fn='predictions_real_300_eos-2.txt',beam_size=300, ignore_eos=True)\n",
    "# evaluator.predict(pred_set, fn='predictions_real_200_eos.txt',beam_size=200, ignore_eos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Epoch 0, loss: 75.106003, norm: 5.068851, elapsed: 601.591950, lrn_rate: 0.700000\n",
      "Validation time: 1.177268 seconds\n",
      "Validation set metric: 15.046797\n",
      "Epoch 1, loss: 64.709015, norm: 6.823921, elapsed: 1202.462563, lrn_rate: 0.700000\n",
      "Validation time: 1.123111 seconds\n",
      "Validation set metric: 10.318951\n",
      "Epoch 2, loss: 55.162987, norm: 5.810015, elapsed: 1815.646121, lrn_rate: 0.700000\n",
      "Validation time: 1.158648 seconds\n",
      "Validation set metric: 8.200983\n",
      "Epoch 3, loss: 48.013638, norm: 6.298200, elapsed: 2430.358610, lrn_rate: 0.700000\n",
      "Validation time: 1.222892 seconds\n",
      "Validation set metric: 7.256750\n",
      "Epoch 4, loss: 55.855797, norm: 8.171973, elapsed: 3034.166331, lrn_rate: 0.700000\n",
      "Validation time: 1.161787 seconds\n",
      "Validation set metric: 7.055706\n",
      "Epoch 5, loss: 51.494362, norm: 9.309718, elapsed: 3637.575163, lrn_rate: 0.700000\n",
      "Validation time: 1.184436 seconds\n",
      "Validation set metric: 7.108363\n",
      "Decaying LR to 0.350000\n",
      "Epoch 6, loss: 34.349045, norm: 8.055377, elapsed: 4239.637285, lrn_rate: 0.350000\n",
      "Validation time: 1.196922 seconds\n",
      "Validation set metric: 6.700641\n",
      "Epoch 7, loss: 26.329096, norm: 8.606746, elapsed: 4846.299028, lrn_rate: 0.350000\n",
      "Validation time: 1.140525 seconds\n",
      "Validation set metric: 7.049315\n",
      "Decaying LR to 0.175000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-ffd2c44189bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                      lrn_decay='adaptive', reverse_enc_input=False)\n\u001b[1;32m      7\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNMTEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs_decoder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_enc_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-78-565b039c9b12>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, torch_train_iter, le, val_iter, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m                 \u001b[0mres_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_iter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-565b039c9b12>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, batch, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-565b039c9b12>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(self, batch, mode)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# For attention, will use enc_output (not otherwise)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-cab290137def>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tsr, hidden)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# output is [batch, sent_len, hidden_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_tsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# TODO: perhaps add dropout to output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# init descriptors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_rnn_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_input_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_descs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptor_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36minit_rnn_descriptor\u001b[0;34m(fn, handle)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, hidden_size, num_layers, dropout_desc, input_mode, bidirectional, mode, datatype)\u001b[0m\n\u001b[1;32m    259\u001b[0m             ))\n\u001b[1;32m    260\u001b[0m             if version() >= 7000 and int(cuda[0]) >= 9 and (\n\u001b[0;32m--> 261\u001b[0;31m                     torch.cuda.get_device_capability(torch.cuda.current_device())[0] >= 7):\n\u001b[0m\u001b[1;32m    262\u001b[0m                 \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnnSetRNNMatrixMathType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCUDNN_DEFAULT_MATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdatatype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCUDNN_DATA_HALF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \"\"\"\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDeviceCapability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=32, device=-1,\n",
    "                                                  repeat=False, sort_key=lambda x: len(x.src))\n",
    "bs_encoder = BaseEncoder(DE, hidden_size=500, num_layers=4, word_features=500)\n",
    "bs_decoder = BaseDecoder(EN, hidden_size=500, num_layers=4, word_features=500)\n",
    "trainer = NMTTrainer([bs_encoder, bs_decoder], DE, EN, lrn_rate=0.7, \n",
    "                     lrn_decay='adaptive', reverse_enc_input=False)\n",
    "evaluator = NMTEvaluator([bs_encoder, bs_decoder], DE, EN, reverse_enc_input=False)\n",
    "trainer.train(train_iter, verbose=True, le=evaluator, val_iter=val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 76.252197, norm: 4.725919, elapsed: 353.864778, lrn_rate: 1.000000\n",
      "Validation time: 0.583281 seconds\n",
      "Validation set metric: 16.969514\n",
      "Saving model to saved_models/attn_med_3.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 76.925499, norm: 5.523378, elapsed: 713.133499, lrn_rate: 1.000000\n",
      "Validation time: 0.572580 seconds\n",
      "Validation set metric: 12.591491\n",
      "Saving model to saved_models/attn_med_3.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 55.661785, norm: 5.266655, elapsed: 1077.052984, lrn_rate: 1.000000\n",
      "Validation time: 0.495382 seconds\n",
      "Validation set metric: 8.166244\n",
      "Saving model to saved_models/attn_med_3.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 51.431374, norm: 7.361608, elapsed: 1439.067216, lrn_rate: 1.000000\n",
      "Validation time: 0.569628 seconds\n",
      "Validation set metric: 7.040756\n",
      "Saving model to saved_models/attn_med_3.epoch_3.ckpt.tar\n",
      "Epoch 4, loss: 52.481609, norm: 5.975768, elapsed: 1800.621420, lrn_rate: 1.000000\n",
      "Validation time: 0.500064 seconds\n",
      "Validation set metric: 6.357040\n",
      "Saving model to saved_models/attn_med_3.epoch_4.ckpt.tar\n",
      "Epoch 5, loss: 42.558281, norm: 7.238148, elapsed: 2166.440852, lrn_rate: 1.000000\n",
      "Validation time: 0.623585 seconds\n",
      "Validation set metric: 6.022433\n",
      "Saving model to saved_models/attn_med_3.epoch_5.ckpt.tar\n",
      "Epoch 6, loss: 50.505329, norm: 7.597331, elapsed: 2529.489301, lrn_rate: 1.000000\n",
      "Validation time: 0.475188 seconds\n",
      "Validation set metric: 5.834021\n",
      "Saving model to saved_models/attn_med_3.epoch_6.ckpt.tar\n",
      "Epoch 7, loss: 47.384521, norm: 8.123848, elapsed: 2892.993687, lrn_rate: 1.000000\n",
      "Validation time: 0.627247 seconds\n",
      "Validation set metric: 5.603065\n",
      "Saving model to saved_models/attn_med_3.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 8, loss: 40.082497, norm: 7.110181, elapsed: 3258.181777, lrn_rate: 0.500000\n",
      "Validation time: 0.547459 seconds\n",
      "Validation set metric: 5.207345\n",
      "Saving model to saved_models/attn_med_3.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 9, loss: 35.665710, norm: 6.422038, elapsed: 3621.085573, lrn_rate: 0.250000\n",
      "Validation time: 0.749694 seconds\n",
      "Validation set metric: 5.020391\n",
      "Saving model to saved_models/attn_med_3.epoch_9.ckpt.tar\n",
      "Decaying LR to 0.125000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bc1718d7b21a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                         record_attention=False)\n\u001b[1;32m     13\u001b[0m trainer.train(train_iter, verbose=True, le=evaluator, val_iter=val_iter,\n\u001b[0;32m---> 14\u001b[0;31m               save_model_fn='attn_med_3')\n\u001b[0m",
      "\u001b[0;32m~/cs287/hw3/helpers.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, torch_train_iter, le, val_iter, save_model_fn, init_parameters, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m                 \u001b[0mres_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_iter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs287/hw3/helpers.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, batch, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# norms must be clipped after backward but before step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=32, device=-1,\n",
    "                                                  repeat=False, sort_key=lambda x: len(x.src))\n",
    "bs_encoder = BaseEncoder(DE, hidden_size=300, num_layers=4, word_features=300, \n",
    "                         dropout=0.2)\n",
    "# TODO: decide whether to add dropout to output states of encoder!\n",
    "at_decoder = AttnDecoder(EN, hidden_size=300, num_layers=4, word_features=300, dropout=0.2,\n",
    "                         tie_weights=True, enc_linear=300)\n",
    "trainer = NMTTrainer([bs_encoder, at_decoder], DE, EN, lrn_rate=1.0, \n",
    "                     lrn_decay='adaptive', attention=True,\n",
    "                     clip_norm=5, lrn_decay_force=8)\n",
    "evaluator = NMTEvaluator([bs_encoder, at_decoder], DE, EN, attention=True,\n",
    "                        record_attention=False)\n",
    "trainer.train(train_iter, verbose=True, le=evaluator, val_iter=val_iter,\n",
    "              save_model_fn='attn_med_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 False 4 0.2\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 83.561142, norm: 4.071474, elapsed: 271.279075, lrn_rate: 1.000000\n",
      "Validation time: 0.360532 seconds\n",
      "Validation set metric: 22.966567\n",
      "Saving model to saved_models/attn_grid_0.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 82.306152, norm: 4.954175, elapsed: 548.610403, lrn_rate: 1.000000\n",
      "Validation time: 0.354557 seconds\n",
      "Validation set metric: 15.265598\n",
      "Saving model to saved_models/attn_grid_0.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 59.941078, norm: 4.696200, elapsed: 828.961941, lrn_rate: 1.000000\n",
      "Validation time: 0.392126 seconds\n",
      "Validation set metric: 9.756422\n",
      "Saving model to saved_models/attn_grid_0.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 55.912140, norm: 5.782441, elapsed: 1111.078448, lrn_rate: 1.000000\n",
      "Validation time: 0.360725 seconds\n",
      "Validation set metric: 7.972600\n",
      "Saving model to saved_models/attn_grid_0.epoch_3.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 4, loss: 54.147552, norm: 5.253220, elapsed: 1392.845590, lrn_rate: 0.500000\n",
      "Validation time: 0.376834 seconds\n",
      "Validation set metric: 6.815474\n",
      "Saving model to saved_models/attn_grid_0.epoch_4.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 5, loss: 43.327965, norm: 6.232311, elapsed: 1674.932675, lrn_rate: 0.250000\n",
      "Validation time: 0.379969 seconds\n",
      "Validation set metric: 6.307426\n",
      "Saving model to saved_models/attn_grid_0.epoch_5.ckpt.tar\n",
      "Decaying LR to 0.125000\n",
      "Epoch 6, loss: 50.873741, norm: 6.914220, elapsed: 1957.194886, lrn_rate: 0.125000\n",
      "Validation time: 0.361607 seconds\n",
      "Validation set metric: 6.090649\n",
      "Saving model to saved_models/attn_grid_0.epoch_6.ckpt.tar\n",
      "Decaying LR to 0.062500\n",
      "Epoch 7, loss: 48.331512, norm: 5.963121, elapsed: 2240.120492, lrn_rate: 0.062500\n",
      "Validation time: 0.389374 seconds\n",
      "Validation set metric: 6.008249\n",
      "Saving model to saved_models/attn_grid_0.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.031250\n",
      "Epoch 8, loss: 44.363621, norm: 5.598820, elapsed: 2523.012309, lrn_rate: 0.031250\n",
      "Validation time: 0.377136 seconds\n",
      "Validation set metric: 5.965104\n",
      "Saving model to saved_models/attn_grid_0.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.015625\n",
      "Epoch 9, loss: 43.252693, norm: 5.788473, elapsed: 2807.376643, lrn_rate: 0.015625\n",
      "Validation time: 0.353863 seconds\n",
      "Validation set metric: 5.945370\n",
      "Saving model to saved_models/attn_grid_0.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 5.945369884957124\n",
      "200 False 4 0.4\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 83.931732, norm: 4.161091, elapsed: 272.424800, lrn_rate: 1.000000\n",
      "Validation time: 0.351562 seconds\n",
      "Validation set metric: 22.726181\n",
      "Saving model to saved_models/attn_grid_1.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 87.767494, norm: 4.834038, elapsed: 545.748289, lrn_rate: 1.000000\n",
      "Validation time: 0.356378 seconds\n",
      "Validation set metric: 18.173647\n",
      "Saving model to saved_models/attn_grid_1.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 68.219200, norm: 4.212573, elapsed: 820.910688, lrn_rate: 1.000000\n",
      "Validation time: 0.348892 seconds\n",
      "Validation set metric: 14.374986\n",
      "Saving model to saved_models/attn_grid_1.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 63.636070, norm: 5.670929, elapsed: 1095.612525, lrn_rate: 1.000000\n",
      "Validation time: 0.355230 seconds\n",
      "Validation set metric: 10.502690\n",
      "Saving model to saved_models/attn_grid_1.epoch_3.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 4, loss: 62.408348, norm: 5.245264, elapsed: 1372.954282, lrn_rate: 0.500000\n",
      "Validation time: 0.378727 seconds\n",
      "Validation set metric: 8.745535\n",
      "Saving model to saved_models/attn_grid_1.epoch_4.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 5, loss: 51.085903, norm: 6.189110, elapsed: 1651.839379, lrn_rate: 0.250000\n",
      "Validation time: 0.354607 seconds\n",
      "Validation set metric: 7.971170\n",
      "Saving model to saved_models/attn_grid_1.epoch_5.ckpt.tar\n",
      "Decaying LR to 0.125000\n",
      "Epoch 6, loss: 60.441063, norm: 7.284904, elapsed: 1931.029200, lrn_rate: 0.125000\n",
      "Validation time: 0.360559 seconds\n",
      "Validation set metric: 7.591719\n",
      "Saving model to saved_models/attn_grid_1.epoch_6.ckpt.tar\n",
      "Decaying LR to 0.062500\n",
      "Epoch 7, loss: 57.327953, norm: 5.992233, elapsed: 2210.519960, lrn_rate: 0.062500\n",
      "Validation time: 0.349486 seconds\n",
      "Validation set metric: 7.432932\n",
      "Saving model to saved_models/attn_grid_1.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.031250\n",
      "Epoch 8, loss: 52.496510, norm: 5.785281, elapsed: 2490.403746, lrn_rate: 0.031250\n",
      "Validation time: 0.355883 seconds\n",
      "Validation set metric: 7.341582\n",
      "Saving model to saved_models/attn_grid_1.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.015625\n",
      "Epoch 9, loss: 51.212994, norm: 5.904938, elapsed: 2769.520470, lrn_rate: 0.015625\n",
      "Validation time: 0.361634 seconds\n",
      "Validation set metric: 7.306199\n",
      "Saving model to saved_models/attn_grid_1.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 7.306198857053239\n",
      "200 False 8 0.2\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 85.067680, norm: 4.042343, elapsed: 275.287274, lrn_rate: 1.000000\n",
      "Validation time: 0.355261 seconds\n",
      "Validation set metric: 24.352474\n",
      "Saving model to saved_models/attn_grid_2.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 84.108170, norm: 5.042083, elapsed: 554.569927, lrn_rate: 1.000000\n",
      "Validation time: 0.363921 seconds\n",
      "Validation set metric: 15.921558\n",
      "Saving model to saved_models/attn_grid_2.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 60.803658, norm: 4.668750, elapsed: 834.639272, lrn_rate: 1.000000\n",
      "Validation time: 0.388792 seconds\n",
      "Validation set metric: 10.366450\n",
      "Saving model to saved_models/attn_grid_2.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 56.618866, norm: 5.502721, elapsed: 1116.324159, lrn_rate: 1.000000\n",
      "Validation time: 0.402103 seconds\n",
      "Validation set metric: 8.323915\n",
      "Saving model to saved_models/attn_grid_2.epoch_3.ckpt.tar\n",
      "Epoch 4, loss: 56.617249, norm: 4.964903, elapsed: 1397.799498, lrn_rate: 1.000000\n",
      "Validation time: 0.398780 seconds\n",
      "Validation set metric: 7.570488\n",
      "Saving model to saved_models/attn_grid_2.epoch_4.ckpt.tar\n",
      "Epoch 5, loss: 46.629814, norm: 5.708736, elapsed: 1681.887902, lrn_rate: 1.000000\n",
      "Validation time: 0.381419 seconds\n",
      "Validation set metric: 6.961106\n",
      "Saving model to saved_models/attn_grid_2.epoch_5.ckpt.tar\n",
      "Epoch 6, loss: 54.142597, norm: 6.370638, elapsed: 1965.840851, lrn_rate: 1.000000\n",
      "Validation time: 0.392831 seconds\n",
      "Validation set metric: 6.730813\n",
      "Saving model to saved_models/attn_grid_2.epoch_6.ckpt.tar\n",
      "Epoch 7, loss: 51.517876, norm: 5.396397, elapsed: 2247.925877, lrn_rate: 1.000000\n",
      "Validation time: 0.362355 seconds\n",
      "Validation set metric: 6.421638\n",
      "Saving model to saved_models/attn_grid_2.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 8, loss: 43.787796, norm: 4.886232, elapsed: 2530.831523, lrn_rate: 0.500000\n",
      "Validation time: 0.370876 seconds\n",
      "Validation set metric: 5.952314\n",
      "Saving model to saved_models/attn_grid_2.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 9, loss: 40.818443, norm: 5.034775, elapsed: 2815.202959, lrn_rate: 0.250000\n",
      "Validation time: 0.371427 seconds\n",
      "Validation set metric: 5.723113\n",
      "Saving model to saved_models/attn_grid_2.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 5.72311309192254\n",
      "200 False 8 0.4\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 83.809555, norm: 4.057537, elapsed: 273.457965, lrn_rate: 1.000000\n",
      "Validation time: 0.365764 seconds\n",
      "Validation set metric: 23.071917\n",
      "Saving model to saved_models/attn_grid_3.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 86.704704, norm: 4.726288, elapsed: 547.393016, lrn_rate: 1.000000\n",
      "Validation time: 0.395032 seconds\n",
      "Validation set metric: 17.307456\n",
      "Saving model to saved_models/attn_grid_3.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 66.911827, norm: 4.402825, elapsed: 822.156838, lrn_rate: 1.000000\n",
      "Validation time: 0.356835 seconds\n",
      "Validation set metric: 13.374448\n",
      "Saving model to saved_models/attn_grid_3.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 62.270794, norm: 5.694883, elapsed: 1098.873116, lrn_rate: 1.000000\n",
      "Validation time: 0.353263 seconds\n",
      "Validation set metric: 9.893477\n",
      "Saving model to saved_models/attn_grid_3.epoch_3.ckpt.tar\n",
      "Epoch 4, loss: 62.905273, norm: 5.290662, elapsed: 1378.331791, lrn_rate: 1.000000\n",
      "Validation time: 0.373175 seconds\n",
      "Validation set metric: 8.682508\n",
      "Saving model to saved_models/attn_grid_3.epoch_4.ckpt.tar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss: 52.777771, norm: 5.691047, elapsed: 1657.517624, lrn_rate: 1.000000\n",
      "Validation time: 0.355772 seconds\n",
      "Validation set metric: 7.938821\n",
      "Saving model to saved_models/attn_grid_3.epoch_5.ckpt.tar\n",
      "Epoch 6, loss: 61.794411, norm: 6.426108, elapsed: 1936.887601, lrn_rate: 1.000000\n",
      "Validation time: 0.348664 seconds\n",
      "Validation set metric: 7.579755\n",
      "Saving model to saved_models/attn_grid_3.epoch_6.ckpt.tar\n",
      "Epoch 7, loss: 58.316906, norm: 5.636143, elapsed: 2217.693143, lrn_rate: 1.000000\n",
      "Validation time: 0.371190 seconds\n",
      "Validation set metric: 7.299893\n",
      "Saving model to saved_models/attn_grid_3.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 8, loss: 51.196472, norm: 5.013029, elapsed: 2497.512262, lrn_rate: 0.500000\n",
      "Validation time: 0.349605 seconds\n",
      "Validation set metric: 6.763396\n",
      "Saving model to saved_models/attn_grid_3.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 9, loss: 47.804970, norm: 5.102167, elapsed: 2778.161504, lrn_rate: 0.250000\n",
      "Validation time: 0.367842 seconds\n",
      "Validation set metric: 6.543959\n",
      "Saving model to saved_models/attn_grid_3.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 6.543959344008501\n",
      "200 True 4 0.2\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 77.921799, norm: 4.201652, elapsed: 273.800331, lrn_rate: 1.000000\n",
      "Validation time: 0.404151 seconds\n",
      "Validation set metric: 18.321237\n",
      "Saving model to saved_models/attn_grid_4.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 80.061142, norm: 4.923499, elapsed: 550.228777, lrn_rate: 1.000000\n",
      "Validation time: 0.391620 seconds\n",
      "Validation set metric: 13.918483\n",
      "Saving model to saved_models/attn_grid_4.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 59.586132, norm: 4.608985, elapsed: 827.197041, lrn_rate: 1.000000\n",
      "Validation time: 0.353776 seconds\n",
      "Validation set metric: 9.644605\n",
      "Saving model to saved_models/attn_grid_4.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 55.045631, norm: 5.908368, elapsed: 1105.585392, lrn_rate: 1.000000\n",
      "Validation time: 0.361324 seconds\n",
      "Validation set metric: 7.915523\n",
      "Saving model to saved_models/attn_grid_4.epoch_3.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 4, loss: 53.947441, norm: 5.361520, elapsed: 1385.202334, lrn_rate: 0.500000\n",
      "Validation time: 0.418510 seconds\n",
      "Validation set metric: 6.787118\n",
      "Saving model to saved_models/attn_grid_4.epoch_4.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 5, loss: 43.542664, norm: 6.245208, elapsed: 1665.456568, lrn_rate: 0.250000\n",
      "Validation time: 0.356272 seconds\n",
      "Validation set metric: 6.295384\n",
      "Saving model to saved_models/attn_grid_4.epoch_5.ckpt.tar\n",
      "Decaying LR to 0.125000\n",
      "Epoch 6, loss: 51.070637, norm: 6.960669, elapsed: 1946.965244, lrn_rate: 0.125000\n",
      "Validation time: 0.351350 seconds\n",
      "Validation set metric: 6.081556\n",
      "Saving model to saved_models/attn_grid_4.epoch_6.ckpt.tar\n",
      "Decaying LR to 0.062500\n",
      "Epoch 7, loss: 48.500435, norm: 5.910114, elapsed: 2226.234590, lrn_rate: 0.062500\n",
      "Validation time: 0.360739 seconds\n",
      "Validation set metric: 6.005617\n",
      "Saving model to saved_models/attn_grid_4.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.031250\n",
      "Epoch 8, loss: 44.064594, norm: 5.544730, elapsed: 2507.387086, lrn_rate: 0.031250\n",
      "Validation time: 0.355819 seconds\n",
      "Validation set metric: 5.950150\n",
      "Saving model to saved_models/attn_grid_4.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.015625\n",
      "Epoch 9, loss: 43.022419, norm: 5.858527, elapsed: 2789.384343, lrn_rate: 0.015625\n",
      "Validation time: 0.392147 seconds\n",
      "Validation set metric: 5.929888\n",
      "Saving model to saved_models/attn_grid_4.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 5.929888163985206\n",
      "200 True 4 0.4\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 80.919846, norm: 4.582043, elapsed: 269.123326, lrn_rate: 1.000000\n",
      "Validation time: 0.385350 seconds\n",
      "Validation set metric: 19.629608\n",
      "Saving model to saved_models/attn_grid_5.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 83.846222, norm: 5.241071, elapsed: 542.191104, lrn_rate: 1.000000\n",
      "Validation time: 0.353693 seconds\n",
      "Validation set metric: 14.764272\n",
      "Saving model to saved_models/attn_grid_5.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 65.174332, norm: 4.778107, elapsed: 814.743778, lrn_rate: 1.000000\n",
      "Validation time: 0.353189 seconds\n",
      "Validation set metric: 11.886541\n",
      "Saving model to saved_models/attn_grid_5.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 60.981152, norm: 5.968712, elapsed: 1090.004043, lrn_rate: 1.000000\n",
      "Validation time: 0.353783 seconds\n",
      "Validation set metric: 9.335173\n",
      "Saving model to saved_models/attn_grid_5.epoch_3.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 4, loss: 61.191242, norm: 5.375038, elapsed: 1365.859091, lrn_rate: 0.500000\n",
      "Validation time: 0.386384 seconds\n",
      "Validation set metric: 7.989257\n",
      "Saving model to saved_models/attn_grid_5.epoch_4.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 5, loss: 50.051792, norm: 6.178527, elapsed: 1642.623610, lrn_rate: 0.250000\n",
      "Validation time: 0.354101 seconds\n",
      "Validation set metric: 7.398204\n",
      "Saving model to saved_models/attn_grid_5.epoch_5.ckpt.tar\n",
      "Decaying LR to 0.125000\n",
      "Epoch 6, loss: 59.307312, norm: 7.137314, elapsed: 1919.201460, lrn_rate: 0.125000\n",
      "Validation time: 0.354267 seconds\n",
      "Validation set metric: 7.162647\n",
      "Saving model to saved_models/attn_grid_5.epoch_6.ckpt.tar\n",
      "Decaying LR to 0.062500\n",
      "Epoch 7, loss: 56.147991, norm: 5.810665, elapsed: 2194.852220, lrn_rate: 0.062500\n",
      "Validation time: 0.388363 seconds\n",
      "Validation set metric: 7.045846\n",
      "Saving model to saved_models/attn_grid_5.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.031250\n",
      "Epoch 8, loss: 51.828869, norm: 5.715759, elapsed: 2471.200237, lrn_rate: 0.031250\n",
      "Validation time: 0.400573 seconds\n",
      "Validation set metric: 6.985106\n",
      "Saving model to saved_models/attn_grid_5.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.015625\n",
      "Epoch 9, loss: 50.278885, norm: 5.570264, elapsed: 2748.088653, lrn_rate: 0.015625\n",
      "Validation time: 0.391616 seconds\n",
      "Validation set metric: 6.955871\n",
      "Saving model to saved_models/attn_grid_5.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 6.955870959106877\n",
      "200 True 8 0.2\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 78.055939, norm: 4.399601, elapsed: 272.657089, lrn_rate: 1.000000\n",
      "Validation time: 0.354965 seconds\n",
      "Validation set metric: 18.165227\n",
      "Saving model to saved_models/attn_grid_6.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 78.824440, norm: 5.276427, elapsed: 550.013885, lrn_rate: 1.000000\n",
      "Validation time: 0.367056 seconds\n",
      "Validation set metric: 13.387901\n",
      "Saving model to saved_models/attn_grid_6.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 57.863720, norm: 4.895478, elapsed: 828.730086, lrn_rate: 1.000000\n",
      "Validation time: 0.352305 seconds\n",
      "Validation set metric: 8.991170\n",
      "Saving model to saved_models/attn_grid_6.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 54.028553, norm: 5.656609, elapsed: 1109.136795, lrn_rate: 1.000000\n",
      "Validation time: 0.361284 seconds\n",
      "Validation set metric: 7.579922\n",
      "Saving model to saved_models/attn_grid_6.epoch_3.ckpt.tar\n",
      "Epoch 4, loss: 55.050648, norm: 5.349475, elapsed: 1390.106972, lrn_rate: 1.000000\n",
      "Validation time: 0.353842 seconds\n",
      "Validation set metric: 6.919784\n",
      "Saving model to saved_models/attn_grid_6.epoch_4.ckpt.tar\n",
      "Epoch 5, loss: 45.343040, norm: 6.299519, elapsed: 1670.594209, lrn_rate: 1.000000\n",
      "Validation time: 0.356303 seconds\n",
      "Validation set metric: 6.427721\n",
      "Saving model to saved_models/attn_grid_6.epoch_5.ckpt.tar\n",
      "Epoch 6, loss: 52.707630, norm: 6.814468, elapsed: 1951.234881, lrn_rate: 1.000000\n",
      "Validation time: 0.348605 seconds\n",
      "Validation set metric: 6.243900\n",
      "Saving model to saved_models/attn_grid_6.epoch_6.ckpt.tar\n",
      "Epoch 7, loss: 50.012188, norm: 5.943955, elapsed: 2231.551357, lrn_rate: 1.000000\n",
      "Validation time: 0.418138 seconds\n",
      "Validation set metric: 5.947431\n",
      "Saving model to saved_models/attn_grid_6.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 8, loss: 43.016766, norm: 5.050098, elapsed: 2512.055833, lrn_rate: 0.500000\n",
      "Validation time: 0.363793 seconds\n",
      "Validation set metric: 5.485799\n",
      "Saving model to saved_models/attn_grid_6.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 9, loss: 40.185081, norm: 5.137766, elapsed: 2792.097615, lrn_rate: 0.250000\n",
      "Validation time: 0.365701 seconds\n",
      "Validation set metric: 5.315936\n",
      "Saving model to saved_models/attn_grid_6.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 5.315935501788608\n",
      "200 True 8 0.4\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 80.696709, norm: 4.487724, elapsed: 268.828376, lrn_rate: 1.000000\n",
      "Validation time: 0.356540 seconds\n",
      "Validation set metric: 19.476453\n",
      "Saving model to saved_models/attn_grid_7.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 84.230835, norm: 5.347474, elapsed: 540.498028, lrn_rate: 1.000000\n",
      "Validation time: 0.353929 seconds\n",
      "Validation set metric: 14.954864\n",
      "Saving model to saved_models/attn_grid_7.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 64.211594, norm: 4.860816, elapsed: 813.037319, lrn_rate: 1.000000\n",
      "Validation time: 0.354883 seconds\n",
      "Validation set metric: 11.287956\n",
      "Saving model to saved_models/attn_grid_7.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 60.588867, norm: 6.156037, elapsed: 1087.799996, lrn_rate: 1.000000\n",
      "Validation time: 0.348687 seconds\n",
      "Validation set metric: 9.001583\n",
      "Saving model to saved_models/attn_grid_7.epoch_3.ckpt.tar\n",
      "Epoch 4, loss: 62.230396, norm: 5.461389, elapsed: 1363.474364, lrn_rate: 1.000000\n",
      "Validation time: 0.371995 seconds\n",
      "Validation set metric: 8.228699\n",
      "Saving model to saved_models/attn_grid_7.epoch_4.ckpt.tar\n",
      "Epoch 5, loss: 51.283405, norm: 6.145927, elapsed: 1638.798782, lrn_rate: 1.000000\n",
      "Validation time: 0.358811 seconds\n",
      "Validation set metric: 7.638402\n",
      "Saving model to saved_models/attn_grid_7.epoch_5.ckpt.tar\n",
      "Epoch 6, loss: 61.524147, norm: 7.029633, elapsed: 1915.414260, lrn_rate: 1.000000\n",
      "Validation time: 0.361229 seconds\n",
      "Validation set metric: 7.317560\n",
      "Saving model to saved_models/attn_grid_7.epoch_6.ckpt.tar\n",
      "Epoch 7, loss: 57.577705, norm: 5.748381, elapsed: 2190.865862, lrn_rate: 1.000000\n",
      "Validation time: 0.365750 seconds\n",
      "Validation set metric: 7.090227\n",
      "Saving model to saved_models/attn_grid_7.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 8, loss: 51.088554, norm: 6.523343, elapsed: 2467.822230, lrn_rate: 0.500000\n",
      "Validation time: 0.375150 seconds\n",
      "Validation set metric: 6.569260\n",
      "Saving model to saved_models/attn_grid_7.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 9, loss: 48.479004, norm: 5.179575, elapsed: 2744.953962, lrn_rate: 0.250000\n",
      "Validation time: 0.355020 seconds\n",
      "Validation set metric: 6.369815\n",
      "Saving model to saved_models/attn_grid_7.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 6.369814560538489\n",
      "400 False 4 0.2\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 76.013931, norm: 4.984907, elapsed: 441.719422, lrn_rate: 1.000000\n",
      "Validation time: 0.719462 seconds\n",
      "Validation set metric: 16.896606\n",
      "Saving model to saved_models/attn_grid_8.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 69.334068, norm: 6.838554, elapsed: 887.813493, lrn_rate: 1.000000\n",
      "Validation time: 0.741214 seconds\n",
      "Validation set metric: 9.312835\n",
      "Saving model to saved_models/attn_grid_8.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 52.829327, norm: 5.360114, elapsed: 1334.857489, lrn_rate: 1.000000\n",
      "Validation time: 0.843638 seconds\n",
      "Validation set metric: 7.313180\n",
      "Saving model to saved_models/attn_grid_8.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 49.375183, norm: 6.728409, elapsed: 1782.912957, lrn_rate: 1.000000\n",
      "Validation time: 0.675194 seconds\n",
      "Validation set metric: 6.458962\n",
      "Saving model to saved_models/attn_grid_8.epoch_3.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 4, loss: 47.607494, norm: 6.027325, elapsed: 2230.707132, lrn_rate: 0.500000\n",
      "Validation time: 0.793595 seconds\n",
      "Validation set metric: 5.666680\n",
      "Saving model to saved_models/attn_grid_8.epoch_4.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 5, loss: 37.086143, norm: 7.075492, elapsed: 2693.598260, lrn_rate: 0.250000\n",
      "Validation time: 0.874730 seconds\n",
      "Validation set metric: 5.397645\n",
      "Saving model to saved_models/attn_grid_8.epoch_5.ckpt.tar\n",
      "Decaying LR to 0.125000\n",
      "Epoch 6, loss: 43.877644, norm: 8.391942, elapsed: 3158.934554, lrn_rate: 0.125000\n",
      "Validation time: 0.780769 seconds\n",
      "Validation set metric: 5.279377\n",
      "Saving model to saved_models/attn_grid_8.epoch_6.ckpt.tar\n",
      "Decaying LR to 0.062500\n",
      "Epoch 7, loss: 41.404530, norm: 6.978399, elapsed: 3624.027682, lrn_rate: 0.062500\n",
      "Validation time: 0.796287 seconds\n",
      "Validation set metric: 5.264551\n",
      "Saving model to saved_models/attn_grid_8.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.031250\n",
      "Epoch 8, loss: 36.868183, norm: 6.648023, elapsed: 4090.833524, lrn_rate: 0.031250\n",
      "Validation time: 0.626812 seconds\n",
      "Validation set metric: 5.249808\n",
      "Saving model to saved_models/attn_grid_8.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.015625\n",
      "Epoch 9, loss: 35.882256, norm: 6.842906, elapsed: 4561.072343, lrn_rate: 0.015625\n",
      "Validation time: 0.765557 seconds\n",
      "Validation set metric: 5.237747\n",
      "Saving model to saved_models/attn_grid_8.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 5.2377473354136415\n",
      "400 False 4 0.4\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 76.563705, norm: 5.911415, elapsed: 455.875975, lrn_rate: 1.000000\n",
      "Validation time: 0.693812 seconds\n",
      "Validation set metric: 15.977037\n",
      "Saving model to saved_models/attn_grid_9.epoch_0.ckpt.tar\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for hs, tw, force, drop in it.product([200,400,600],[False, True],\n",
    "                                      [4,8],[0.2, 0.4]):\n",
    "    print(hs, tw, force, drop)\n",
    "    train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=32, device=-1,\n",
    "                                                      repeat=False, sort_key=lambda x: len(x.src))\n",
    "    bs_encoder = BaseEncoder(DE, hidden_size=hs, num_layers=4, word_features=hs, \n",
    "                             dropout=drop)\n",
    "    # TODO: decide whether to add dropout to output states of encoder!\n",
    "    at_decoder = AttnDecoder(EN, hidden_size=hs, num_layers=4, word_features=hs, dropout=drop,\n",
    "                             tie_weights=tw)\n",
    "    trainer = NMTTrainer([bs_encoder, at_decoder], DE, EN, lrn_rate=1.0, \n",
    "                         lrn_decay='adaptive', attention=True,\n",
    "                         clip_norm=5, lrn_decay_force=force)\n",
    "    evaluator = NMTEvaluator([bs_encoder, at_decoder], DE, EN, attention=True,\n",
    "                            record_attention=False)\n",
    "    trainer.train(train_iter, verbose=True, le=evaluator, val_iter=val_iter,\n",
    "                  save_model_fn='attn_grid_%d' % cnt, num_iter=10)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Validation time: 0.677992 seconds\n",
      "5.322171705651731\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  False\n",
      "Epoch 0, loss: 39.508476, norm: 6.285943, elapsed: 426.947739, lrn_rate: 0.500000\n",
      "Validation time: 0.728775 seconds\n",
      "Validation set metric: 5.209565\n",
      "Saving model to saved_models/attn_med_1b.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 44.648376, norm: 7.371956, elapsed: 859.301896, lrn_rate: 0.500000\n",
      "Validation time: 0.614820 seconds\n",
      "Validation set metric: 5.190459\n",
      "Saving model to saved_models/attn_med_1b.epoch_1.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 2, loss: 38.062698, norm: 7.248244, elapsed: 1291.240771, lrn_rate: 0.250000\n",
      "Validation time: 0.749838 seconds\n",
      "Validation set metric: 5.085312\n",
      "Saving model to saved_models/attn_med_1b.epoch_2.ckpt.tar\n",
      "Decaying LR to 0.125000\n",
      "Epoch 3, loss: 32.695580, norm: 6.297701, elapsed: 1722.055861, lrn_rate: 0.125000\n",
      "Validation time: 0.788171 seconds\n",
      "Validation set metric: 5.076100\n",
      "Saving model to saved_models/attn_med_1b.epoch_3.ckpt.tar\n",
      "Decaying LR to 0.062500\n",
      "Epoch 4, loss: 35.089790, norm: 6.534322, elapsed: 2152.567385, lrn_rate: 0.062500\n",
      "Validation time: 0.662246 seconds\n",
      "Validation set metric: 5.091741\n",
      "Saving model to saved_models/attn_med_1b.epoch_4.ckpt.tar\n",
      "Decaying LR to 0.031250\n",
      "Epoch 5, loss: 31.575603, norm: 6.593545, elapsed: 2585.185066, lrn_rate: 0.031250\n",
      "Validation time: 0.663013 seconds\n",
      "Validation set metric: 5.105446\n",
      "Saving model to saved_models/attn_med_1b.epoch_5.ckpt.tar\n",
      "Decaying LR to 0.015625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bdd8cc10b2ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                      clip_norm=5, lrn_decay_force=2)\n\u001b[1;32m     15\u001b[0m trainer.train(train_iter, verbose=True, le=evaluator, val_iter=val_iter,\n\u001b[0;32m---> 16\u001b[0;31m               save_model_fn='attn_med_1b', init_parameters=False)\n\u001b[0m",
      "\u001b[0;32m~/cs287/hw3/helpers.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, torch_train_iter, le, val_iter, save_model_fn, init_parameters, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m                 \u001b[0mres_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_iter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs287/hw3/helpers.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, batch, **kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# norms must be clipped after backward but before step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mloss_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs287/hw3/helpers.py\u001b[0m in \u001b[0;36mclip_norms\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# Norm clipping: returns a float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             norm = nn.utils.clip_grad_norm(\n\u001b[0;32m--> 434\u001b[0;31m                 parameters, self.clip_norm)\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mparam_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mtotal_norm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparam_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load a model and continue training:\n",
    "ld_enc, ld_dec = load_checkpoint('saved_models/attn_med_1.epoch_8.ckpt.tar')\n",
    "ld_encoder = BaseEncoder(DE, hidden_size=400, num_layers=4, word_features=400, \n",
    "                         dropout=0.2)\n",
    "ld_decoder = AttnDecoder(EN, hidden_size=400, num_layers=4, word_features=400, \n",
    "                         dropout=0.2)\n",
    "set_parameters(ld_encoder, ld_enc)\n",
    "set_parameters(ld_decoder, ld_dec)\n",
    "evaluator = NMTEvaluator([ld_encoder, ld_decoder], DE, EN, attention=True,\n",
    "                        record_attention=False)\n",
    "print(evaluator.evaluate(val_iter))\n",
    "trainer = NMTTrainer([ld_encoder, ld_decoder], DE, EN, lrn_rate=0.5, \n",
    "                     lrn_decay='adaptive', attention=True,\n",
    "                     clip_norm=5, lrn_decay_force=2)\n",
    "trainer.train(train_iter, verbose=True, le=evaluator, val_iter=val_iter,\n",
    "              save_model_fn='attn_med_1b', init_parameters=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation time: 0.659822 seconds\n",
      "5.120132318658038\n",
      "Validation time: 0.872873 seconds\n",
      "6.3874894806368365\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.evaluate(val_iter))\n",
    "print(evaluator.evaluate(test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation time: 0.456792 seconds\n",
      "6.048956472651303\n",
      "3722\n",
      "Variable containing:\n",
      " 0.6505  0.1110  0.0659  0.1725\n",
      " 0.5297  0.1554  0.2806  0.0343\n",
      " 0.0089  0.4239  0.4734  0.0938\n",
      " 0.0180  0.0371  0.9122  0.0327\n",
      " 0.0822  0.0702  0.3141  0.5335\n",
      " 0.4222  0.2591  0.0997  0.2190\n",
      " 0.1612  0.3041  0.4915  0.0432\n",
      " 0.2962  0.4637  0.0781  0.1620\n",
      "[torch.cuda.FloatTensor of size 8x4 (GPU 0)]\n",
      "\n",
      "Source\n",
      "Ich hatte Angst –\n",
      "Target\n",
      "<s> And I was scared . </s> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.evaluate(val_iter))\n",
    "print(len(train_iter))\n",
    "print(evaluator.attns_log[0][4])\n",
    "val_iter.init_epoch()\n",
    "batch = next(iter(val_iter))\n",
    "sent_inspect(batch, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Validation time: 0.834653 seconds\n",
      "4.805516453880054\n",
      "Validation time: 1.456081 seconds\n",
      "5.948858129956995\n",
      "torch.Size([2312000])\n",
      "torch.Size([2312000])\n",
      "Writing predictions to predictions_med_2_200.txt...\n",
      "Computing predictions took 145.327281 seconds\n"
     ]
    }
   ],
   "source": [
    "# save_checkpoint(bs_encoder, at_decoder, filename='saved_models/attn_big_0.epoch_10.ckpt.tar')\n",
    "ld_enc, ld_dec = load_checkpoint('saved_models/attn_med_2.epoch_12.ckpt.tar')\n",
    "ld_encoder = BaseEncoder(DE, hidden_size=500, num_layers=4, word_features=500, dropout=0.3)\n",
    "ld_decoder = AttnDecoder(EN, hidden_size=500, num_layers=4, word_features=500, dropout=0.3)\n",
    "set_parameters(ld_encoder, ld_enc)\n",
    "set_parameters(ld_decoder, ld_dec)\n",
    "evaluator = NMTEvaluator([ld_encoder, ld_decoder], DE, EN, attention=True,\n",
    "                        record_attention=False)\n",
    "print(evaluator.evaluate(val_iter))\n",
    "print(evaluator.evaluate(test_iter))\n",
    "evaluator.predict(pred_set, fn='predictions_med_2_200.txt',beam_size=200, ignore_eos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter.init_epoch()\n",
    "debug_iter = iter(test_iter)\n",
    "for i in range(10):\n",
    "    batch = next(debug_iter)\n",
    "debug_set = [batch.src.data[:, i] for i in range(batch.src.data.size(1))]\n",
    "debug_ans = [batch.trg.data[:, i] for i in range(batch.trg.data.size(1))]\n",
    "evaluator.predict(pred_set, fn='predictions_real.txt',beam_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-inf\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([-np.inf])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(3 < np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PROBABLY NOT RELEVANT STUFF BELOW HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs_decoder_new = AttnDecoder(EN, hidden_size=500, num_layers=4, word_features=500, dropout=0.2)\n",
    "old_params = list(bs_decoder.parameters())\n",
    "for i,p in enumerate(bs_decoder_new.parameters()):\n",
    "    p.data = old_params[i].data\n",
    "print(list(bs_decoder_new.parameters())[0])\n",
    "print(list(bs_decoder.parameters())[0])\n",
    "bs_decoder_new.lstm.flatten_parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
