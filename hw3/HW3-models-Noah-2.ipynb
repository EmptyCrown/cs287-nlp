{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text text processing library\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import Vectors\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "from models import *\n",
    "from helpers import *\n",
    "# import main\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import time\n",
    "import itertools as it\n",
    "MAX_LEN = 20\n",
    "MIN_FREQ = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "DE = data.Field(tokenize=tokenize_de)\n",
    "\n",
    "# only target needs BOS/EOS:\n",
    "EN = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, eos_token = EOS_WORD) \n",
    "\n",
    "train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(DE, EN), \n",
    "                                         filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
    "                                         len(vars(x)['trg']) <= MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "EN.build_vocab(train.trg, min_freq=MIN_FREQ)\n",
    "\n",
    "pred_set = []\n",
    "for i, line in enumerate(open(\"source_test.txt\"), 1):\n",
    "    words = line.split()# [:-1]\n",
    "    pred_set.append([DE.vocab.stoi[s] for s in words])\n",
    "\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits((train, val, test), batch_size=32, device=-1,\n",
    "                                                  repeat=False, sort_key=lambda x: len(x.src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = next(iter(test_iter))\n",
    "# sent_inspect(batch,4)\n",
    "def sent_inspect(batch, idx=0):\n",
    "    print(\"Source\")\n",
    "    print(' '.join([DE.vocab.itos[w] for w in batch.src.data[:,idx]]))\n",
    "    print(\"Target\")\n",
    "    print(' '.join([EN.vocab.itos[w] for w in batch.trg.data[:,idx]]))\n",
    "# print(DE.vocab.stoi['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wo sich der Lauf des <unk> früher befand .\n",
      "<s> We started to be able to see where the <unk> used to flow . </s> <pad> <pad>\n",
      "Das führte mich dazu , Satellitenbilder zu benutzen .\n",
      "<s> This is really what brought me to using satellite imagery . </s> <pad> <pad> <pad> <pad> <pad>\n",
      "Wie unterscheidet sich diese Geschichte von der anderen ?\n",
      "<s> How is this story different ? </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Im Raum war ein junger Mann , <unk> .\n",
      "<s> One of the young men in the room was <unk> . </s> <pad> <pad> <pad> <pad> <pad>\n",
      "Ich brachte rund 90 junge <unk> Führungskräfte zusammen .\n",
      "<s> I brought together about 90 young Somali leaders . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Es vergeht vielleicht ein Jahr , aber nichts .\n",
      "<s> Maybe a year passes , nothing . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Sein Dorf liegt in der Nähe von <unk> .\n",
      "<s> His village is near <unk> . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Ich denke , diese beiden Figuren sind Experten .\n",
      "<s> I think these people are experts . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Vielleicht ist es nicht nur das <unk> Kleid .\n",
      "<s> Maybe it 's not just the <unk> dress . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Wer sind diese Typen ? Was lernen sie ?\n",
      "<s> Who are these guys ? What are they learning ? </s> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(' '.join(DE.vocab.itos[w] for w in debug_set[i]))\n",
    "    print(' '.join(EN.vocab.itos[w] for w in debug_ans[i]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13353, 500])\n",
      "torch.Size([2000, 500])\n",
      "torch.Size([2000, 500])\n",
      "torch.Size([2000])\n",
      "torch.Size([2000])\n",
      "torch.Size([2000, 500])\n",
      "torch.Size([2000, 500])\n",
      "torch.Size([2000])\n",
      "torch.Size([2000])\n",
      "torch.Size([2000, 500])\n",
      "torch.Size([2000, 500])\n",
      "torch.Size([2000])\n",
      "torch.Size([2000])\n",
      "torch.Size([2000, 500])\n",
      "torch.Size([2000, 500])\n",
      "torch.Size([2000])\n",
      "torch.Size([2000])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('saved_models/attn_med_2.epoch_12.ckpt.tar')\n",
    "for p in state_dict['model_encoder']:\n",
    "    print(state_dict['model_encoder'][p].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Epoch 0, loss: 75.106003, norm: 5.068851, elapsed: 601.591950, lrn_rate: 0.700000\n",
      "Validation time: 1.177268 seconds\n",
      "Validation set metric: 15.046797\n",
      "Epoch 1, loss: 64.709015, norm: 6.823921, elapsed: 1202.462563, lrn_rate: 0.700000\n",
      "Validation time: 1.123111 seconds\n",
      "Validation set metric: 10.318951\n",
      "Epoch 2, loss: 55.162987, norm: 5.810015, elapsed: 1815.646121, lrn_rate: 0.700000\n",
      "Validation time: 1.158648 seconds\n",
      "Validation set metric: 8.200983\n",
      "Epoch 3, loss: 48.013638, norm: 6.298200, elapsed: 2430.358610, lrn_rate: 0.700000\n",
      "Validation time: 1.222892 seconds\n",
      "Validation set metric: 7.256750\n",
      "Epoch 4, loss: 55.855797, norm: 8.171973, elapsed: 3034.166331, lrn_rate: 0.700000\n",
      "Validation time: 1.161787 seconds\n",
      "Validation set metric: 7.055706\n",
      "Epoch 5, loss: 51.494362, norm: 9.309718, elapsed: 3637.575163, lrn_rate: 0.700000\n",
      "Validation time: 1.184436 seconds\n",
      "Validation set metric: 7.108363\n",
      "Decaying LR to 0.350000\n",
      "Epoch 6, loss: 34.349045, norm: 8.055377, elapsed: 4239.637285, lrn_rate: 0.350000\n",
      "Validation time: 1.196922 seconds\n",
      "Validation set metric: 6.700641\n",
      "Epoch 7, loss: 26.329096, norm: 8.606746, elapsed: 4846.299028, lrn_rate: 0.350000\n",
      "Validation time: 1.140525 seconds\n",
      "Validation set metric: 7.049315\n",
      "Decaying LR to 0.175000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-ffd2c44189bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                      lrn_decay='adaptive', reverse_enc_input=False)\n\u001b[1;32m      7\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNMTEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs_decoder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_enc_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-78-565b039c9b12>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, torch_train_iter, le, val_iter, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m                 \u001b[0mres_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_iter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-565b039c9b12>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, batch, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-565b039c9b12>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(self, batch, mode)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# For attention, will use enc_output (not otherwise)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-cab290137def>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tsr, hidden)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# output is [batch, sent_len, hidden_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_tsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# TODO: perhaps add dropout to output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# init descriptors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_rnn_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_input_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_descs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptor_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36minit_rnn_descriptor\u001b[0;34m(fn, handle)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/backends/cudnn/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, hidden_size, num_layers, dropout_desc, input_mode, bidirectional, mode, datatype)\u001b[0m\n\u001b[1;32m    259\u001b[0m             ))\n\u001b[1;32m    260\u001b[0m             if version() >= 7000 and int(cuda[0]) >= 9 and (\n\u001b[0;32m--> 261\u001b[0;31m                     torch.cuda.get_device_capability(torch.cuda.current_device())[0] >= 7):\n\u001b[0m\u001b[1;32m    262\u001b[0m                 \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnnSetRNNMatrixMathType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCUDNN_DEFAULT_MATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdatatype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCUDNN_DATA_HALF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \"\"\"\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDeviceCapability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=32, device=-1,\n",
    "                                                  repeat=False, sort_key=lambda x: len(x.src))\n",
    "bs_encoder = BaseEncoder(DE, hidden_size=500, num_layers=4, word_features=500)\n",
    "bs_decoder = BaseDecoder(EN, hidden_size=500, num_layers=4, word_features=500)\n",
    "trainer = NMTTrainer([bs_encoder, bs_decoder], DE, EN, lrn_rate=0.7, \n",
    "                     lrn_decay='adaptive', reverse_enc_input=False)\n",
    "evaluator = NMTEvaluator([bs_encoder, bs_decoder], DE, EN, reverse_enc_input=False)\n",
    "trainer.train(train_iter, verbose=True, le=evaluator, val_iter=val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.3333\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = autograd.Variable(torch.Tensor([[1,1],[2,2]]))\n",
    "b = torch.sum((a != 4).type(torch.FloatTensor)) / 3\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using final MLP\n",
      "Target padding token: 1\n",
      "Source padding token: 1\n",
      "Using CUDA...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "torch.index_select received an invalid combination of arguments - got (\u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.cuda.LongTensor\u001b[0m), but expected (torch.FloatTensor source, int dim, torch.LongTensor index)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1d32511a44d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m evaluator = NMTEvaluator([bs_encoder, at_decoder], DE, EN, attention=True,\n\u001b[1;32m      8\u001b[0m                         record_attention=False, cuda=True)\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-e69fd452cf91>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, test_iter, num_iter)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mnll_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0;31m# TODO: make sure loss just has 1 element!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mnll_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-e69fd452cf91>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(self, batch, mode)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# For attention, will use enc_output (not otherwise)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_enc_prev_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-f6832d1ec865>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tsr, hidden)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# [batch_sz, sent_len, D]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0membedded_tsr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tsr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/thnn/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cls, ctx, indices, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.index_select received an invalid combination of arguments - got (\u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.cuda.LongTensor\u001b[0m), but expected (torch.FloatTensor source, int dim, torch.LongTensor index)"
     ]
    }
   ],
   "source": [
    "bs_encoder = BaseEncoder(DE, hidden_size=650, num_layers=4, word_features=650, \n",
    "                         bidirectional=True, dropout=0.35)\n",
    "# TODO: decide whether to add dropout to output states of encoder!\n",
    "at_decoder = AttnDecoder(EN, hidden_size=650, num_layers=4, word_features=650, dropout=0.35,\n",
    "                         tie_weights=True, enc_linear=650,\n",
    "                         enc_bidirectional=True)\n",
    "evaluator = NMTEvaluator([bs_encoder, at_decoder], DE, EN, attention=True,\n",
    "                        record_attention=False, cuda=True)\n",
    "evaluator.evaluate(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using final MLP\n",
      "Target padding token: 1\n",
      "Source padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Source padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 46.713978, norm: 5.329768, elapsed: 1063.894383, lrn_rate: 1.200000\n",
      "Validation time: 1.941442 seconds\n",
      "Validation set metric: 10.928670\n",
      "Saving model to saved_models/attn_med_5.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 42.267780, norm: 7.347247, elapsed: 2163.232243, lrn_rate: 1.200000\n",
      "Validation time: 1.904391 seconds\n",
      "Validation set metric: 6.930205\n",
      "Saving model to saved_models/attn_med_5.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 36.884426, norm: 7.626665, elapsed: 3208.078403, lrn_rate: 1.200000\n",
      "Validation time: 1.817674 seconds\n",
      "Validation set metric: 5.795428\n",
      "Saving model to saved_models/attn_med_5.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 31.893240, norm: 6.090264, elapsed: 4255.479510, lrn_rate: 1.200000\n",
      "Validation time: 1.843599 seconds\n",
      "Validation set metric: 5.251451\n",
      "Saving model to saved_models/attn_med_5.epoch_3.ckpt.tar\n",
      "Epoch 4, loss: 34.269463, norm: 6.271408, elapsed: 5301.015239, lrn_rate: 1.200000\n",
      "Validation time: 1.878317 seconds\n",
      "Validation set metric: 4.977437\n",
      "Saving model to saved_models/attn_med_5.epoch_4.ckpt.tar\n",
      "Epoch 5, loss: 30.130325, norm: 6.102463, elapsed: 6348.086979, lrn_rate: 1.200000\n",
      "Validation time: 1.914788 seconds\n",
      "Validation set metric: 4.806715\n",
      "Saving model to saved_models/attn_med_5.epoch_5.ckpt.tar\n",
      "Epoch 6, loss: 30.701176, norm: 8.403505, elapsed: 7394.851094, lrn_rate: 1.200000\n",
      "Validation time: 1.970458 seconds\n",
      "Validation set metric: 4.643665\n",
      "Saving model to saved_models/attn_med_5.epoch_6.ckpt.tar\n",
      "Epoch 7, loss: 30.256733, norm: 7.704153, elapsed: 8446.352725, lrn_rate: 1.200000\n",
      "Validation time: 1.945064 seconds\n",
      "Validation set metric: 4.613053\n",
      "Saving model to saved_models/attn_med_5.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.600000\n",
      "Epoch 8, loss: 26.882694, norm: 6.951996, elapsed: 9498.123146, lrn_rate: 0.600000\n",
      "Validation time: 1.780255 seconds\n",
      "Validation set metric: 4.367376\n",
      "Saving model to saved_models/attn_med_5.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.300000\n",
      "Epoch 9, loss: 23.544054, norm: 7.642145, elapsed: 10547.934266, lrn_rate: 0.300000\n",
      "Validation time: 1.908327 seconds\n",
      "Validation set metric: 4.295395\n",
      "Saving model to saved_models/attn_med_5.epoch_9.ckpt.tar\n",
      "Decaying LR to 0.150000\n",
      "Epoch 10, loss: 21.876459, norm: 9.498790, elapsed: 11595.942855, lrn_rate: 0.150000\n",
      "Validation time: 1.931998 seconds\n",
      "Validation set metric: 4.293765\n",
      "Saving model to saved_models/attn_med_5.epoch_10.ckpt.tar\n",
      "Decaying LR to 0.075000\n",
      "Epoch 11, loss: 19.729061, norm: 6.939862, elapsed: 12646.532219, lrn_rate: 0.075000\n",
      "Validation time: 2.039602 seconds\n",
      "Validation set metric: 4.319367\n",
      "Saving model to saved_models/attn_med_5.epoch_11.ckpt.tar\n",
      "Decaying LR to 0.037500\n",
      "Epoch 12, loss: 19.253206, norm: 7.081698, elapsed: 13692.962103, lrn_rate: 0.037500\n",
      "Validation time: 1.980938 seconds\n",
      "Validation set metric: 4.336978\n",
      "Saving model to saved_models/attn_med_5.epoch_12.ckpt.tar\n",
      "Decaying LR to 0.018750\n",
      "Epoch 13, loss: 19.956722, norm: 9.532681, elapsed: 14742.002679, lrn_rate: 0.018750\n",
      "Validation time: 1.929855 seconds\n",
      "Validation set metric: 4.334616\n",
      "Saving model to saved_models/attn_med_5.epoch_13.ckpt.tar\n",
      "Decaying LR to 0.009375\n",
      "Epoch 14, loss: 19.673527, norm: 7.187007, elapsed: 15789.994987, lrn_rate: 0.009375\n",
      "Validation time: 1.889208 seconds\n",
      "Validation set metric: 4.336221\n",
      "Saving model to saved_models/attn_med_5.epoch_14.ckpt.tar\n",
      "Decaying LR to 0.004687\n",
      "Epoch 15, loss: 24.756987, norm: 9.835148, elapsed: 16837.432251, lrn_rate: 0.004687\n",
      "Validation time: 1.879341 seconds\n",
      "Validation set metric: 4.338009\n",
      "Saving model to saved_models/attn_med_5.epoch_15.ckpt.tar\n",
      "Decaying LR to 0.002344\n",
      "Epoch 16, loss: 19.212957, norm: 6.744505, elapsed: 17883.628807, lrn_rate: 0.002344\n",
      "Validation time: 1.859986 seconds\n",
      "Validation set metric: 4.337942\n",
      "Saving model to saved_models/attn_med_5.epoch_16.ckpt.tar\n",
      "Decaying LR to 0.001172\n",
      "Epoch 17, loss: 20.900364, norm: 11.724198, elapsed: 18928.885718, lrn_rate: 0.001172\n",
      "Validation time: 1.909735 seconds\n",
      "Validation set metric: 4.337952\n",
      "Saving model to saved_models/attn_med_5.epoch_17.ckpt.tar\n",
      "Decaying LR to 0.000586\n",
      "Epoch 18, loss: 23.690250, norm: 8.814668, elapsed: 19976.985049, lrn_rate: 0.000586\n",
      "Validation time: 1.840697 seconds\n",
      "Validation set metric: 4.338313\n",
      "Saving model to saved_models/attn_med_5.epoch_18.ckpt.tar\n",
      "Decaying LR to 0.000293\n",
      "Epoch 19, loss: 18.161837, norm: 7.431848, elapsed: 21027.056560, lrn_rate: 0.000293\n",
      "Validation time: 1.870655 seconds\n",
      "Validation set metric: 4.338334\n",
      "Saving model to saved_models/attn_med_5.epoch_19.ckpt.tar\n",
      "FINAL VAL PERF 4.338333858249031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.338333858249031"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=32, device=-1,\n",
    "                                                  repeat=False, sort_key=lambda x: len(x.src))\n",
    "bs_encoder = BaseEncoder(DE, hidden_size=650, num_layers=4, word_features=650, \n",
    "                         bidirectional=True, dropout=0.35)\n",
    "# TODO: decide whether to add dropout to output states of encoder!\n",
    "at_decoder = AttnDecoder(EN, hidden_size=650, num_layers=4, word_features=650, dropout=0.35,\n",
    "                         tie_weights=True, enc_linear=650,\n",
    "                         enc_bidirectional=True)\n",
    "trainer = NMTTrainer([bs_encoder, at_decoder], DE, EN, lrn_rate=1.2, \n",
    "                     lrn_decay='adaptive', attention=True,\n",
    "                     clip_norm=5, lrn_decay_force=8, cuda=True)\n",
    "evaluator = NMTEvaluator([bs_encoder, at_decoder], DE, EN, attention=True,\n",
    "                        record_attention=False, cuda=True)\n",
    "trainer.train(train_iter, verbose=True, le=evaluator, val_iter=val_iter,\n",
    "              save_model_fn='attn_med_5', num_iter=20)\n",
    "# KEYXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 False 4 0.2\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 83.561142, norm: 4.071474, elapsed: 271.279075, lrn_rate: 1.000000\n",
      "Validation time: 0.360532 seconds\n",
      "Validation set metric: 22.966567\n",
      "Saving model to saved_models/attn_grid_0.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 82.306152, norm: 4.954175, elapsed: 548.610403, lrn_rate: 1.000000\n",
      "Validation time: 0.354557 seconds\n",
      "Validation set metric: 15.265598\n",
      "Saving model to saved_models/attn_grid_0.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 59.941078, norm: 4.696200, elapsed: 828.961941, lrn_rate: 1.000000\n",
      "Validation time: 0.392126 seconds\n",
      "Validation set metric: 9.756422\n",
      "Saving model to saved_models/attn_grid_0.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 55.912140, norm: 5.782441, elapsed: 1111.078448, lrn_rate: 1.000000\n",
      "Validation time: 0.360725 seconds\n",
      "Validation set metric: 7.972600\n",
      "Saving model to saved_models/attn_grid_0.epoch_3.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 4, loss: 54.147552, norm: 5.253220, elapsed: 1392.845590, lrn_rate: 0.500000\n",
      "Validation time: 0.376834 seconds\n",
      "Validation set metric: 6.815474\n",
      "Saving model to saved_models/attn_grid_0.epoch_4.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 5, loss: 43.327965, norm: 6.232311, elapsed: 1674.932675, lrn_rate: 0.250000\n",
      "Validation time: 0.379969 seconds\n",
      "Validation set metric: 6.307426\n",
      "Saving model to saved_models/attn_grid_0.epoch_5.ckpt.tar\n",
      "Decaying LR to 0.125000\n",
      "Epoch 6, loss: 50.873741, norm: 6.914220, elapsed: 1957.194886, lrn_rate: 0.125000\n",
      "Validation time: 0.361607 seconds\n",
      "Validation set metric: 6.090649\n",
      "Saving model to saved_models/attn_grid_0.epoch_6.ckpt.tar\n",
      "Decaying LR to 0.062500\n",
      "Epoch 7, loss: 48.331512, norm: 5.963121, elapsed: 2240.120492, lrn_rate: 0.062500\n",
      "Validation time: 0.389374 seconds\n",
      "Validation set metric: 6.008249\n",
      "Saving model to saved_models/attn_grid_0.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.031250\n",
      "Epoch 8, loss: 44.363621, norm: 5.598820, elapsed: 2523.012309, lrn_rate: 0.031250\n",
      "Validation time: 0.377136 seconds\n",
      "Validation set metric: 5.965104\n",
      "Saving model to saved_models/attn_grid_0.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.015625\n",
      "Epoch 9, loss: 43.252693, norm: 5.788473, elapsed: 2807.376643, lrn_rate: 0.015625\n",
      "Validation time: 0.353863 seconds\n",
      "Validation set metric: 5.945370\n",
      "Saving model to saved_models/attn_grid_0.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 5.945369884957124\n",
      "200 False 4 0.4\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 83.931732, norm: 4.161091, elapsed: 272.424800, lrn_rate: 1.000000\n",
      "Validation time: 0.351562 seconds\n",
      "Validation set metric: 22.726181\n",
      "Saving model to saved_models/attn_grid_1.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 87.767494, norm: 4.834038, elapsed: 545.748289, lrn_rate: 1.000000\n",
      "Validation time: 0.356378 seconds\n",
      "Validation set metric: 18.173647\n",
      "Saving model to saved_models/attn_grid_1.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 68.219200, norm: 4.212573, elapsed: 820.910688, lrn_rate: 1.000000\n",
      "Validation time: 0.348892 seconds\n",
      "Validation set metric: 14.374986\n",
      "Saving model to saved_models/attn_grid_1.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 63.636070, norm: 5.670929, elapsed: 1095.612525, lrn_rate: 1.000000\n",
      "Validation time: 0.355230 seconds\n",
      "Validation set metric: 10.502690\n",
      "Saving model to saved_models/attn_grid_1.epoch_3.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 4, loss: 62.408348, norm: 5.245264, elapsed: 1372.954282, lrn_rate: 0.500000\n",
      "Validation time: 0.378727 seconds\n",
      "Validation set metric: 8.745535\n",
      "Saving model to saved_models/attn_grid_1.epoch_4.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 5, loss: 51.085903, norm: 6.189110, elapsed: 1651.839379, lrn_rate: 0.250000\n",
      "Validation time: 0.354607 seconds\n",
      "Validation set metric: 7.971170\n",
      "Saving model to saved_models/attn_grid_1.epoch_5.ckpt.tar\n",
      "Decaying LR to 0.125000\n",
      "Epoch 6, loss: 60.441063, norm: 7.284904, elapsed: 1931.029200, lrn_rate: 0.125000\n",
      "Validation time: 0.360559 seconds\n",
      "Validation set metric: 7.591719\n",
      "Saving model to saved_models/attn_grid_1.epoch_6.ckpt.tar\n",
      "Decaying LR to 0.062500\n",
      "Epoch 7, loss: 57.327953, norm: 5.992233, elapsed: 2210.519960, lrn_rate: 0.062500\n",
      "Validation time: 0.349486 seconds\n",
      "Validation set metric: 7.432932\n",
      "Saving model to saved_models/attn_grid_1.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.031250\n",
      "Epoch 8, loss: 52.496510, norm: 5.785281, elapsed: 2490.403746, lrn_rate: 0.031250\n",
      "Validation time: 0.355883 seconds\n",
      "Validation set metric: 7.341582\n",
      "Saving model to saved_models/attn_grid_1.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.015625\n",
      "Epoch 9, loss: 51.212994, norm: 5.904938, elapsed: 2769.520470, lrn_rate: 0.015625\n",
      "Validation time: 0.361634 seconds\n",
      "Validation set metric: 7.306199\n",
      "Saving model to saved_models/attn_grid_1.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 7.306198857053239\n",
      "200 False 8 0.2\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 85.067680, norm: 4.042343, elapsed: 275.287274, lrn_rate: 1.000000\n",
      "Validation time: 0.355261 seconds\n",
      "Validation set metric: 24.352474\n",
      "Saving model to saved_models/attn_grid_2.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 84.108170, norm: 5.042083, elapsed: 554.569927, lrn_rate: 1.000000\n",
      "Validation time: 0.363921 seconds\n",
      "Validation set metric: 15.921558\n",
      "Saving model to saved_models/attn_grid_2.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 60.803658, norm: 4.668750, elapsed: 834.639272, lrn_rate: 1.000000\n",
      "Validation time: 0.388792 seconds\n",
      "Validation set metric: 10.366450\n",
      "Saving model to saved_models/attn_grid_2.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 56.618866, norm: 5.502721, elapsed: 1116.324159, lrn_rate: 1.000000\n",
      "Validation time: 0.402103 seconds\n",
      "Validation set metric: 8.323915\n",
      "Saving model to saved_models/attn_grid_2.epoch_3.ckpt.tar\n",
      "Epoch 4, loss: 56.617249, norm: 4.964903, elapsed: 1397.799498, lrn_rate: 1.000000\n",
      "Validation time: 0.398780 seconds\n",
      "Validation set metric: 7.570488\n",
      "Saving model to saved_models/attn_grid_2.epoch_4.ckpt.tar\n",
      "Epoch 5, loss: 46.629814, norm: 5.708736, elapsed: 1681.887902, lrn_rate: 1.000000\n",
      "Validation time: 0.381419 seconds\n",
      "Validation set metric: 6.961106\n",
      "Saving model to saved_models/attn_grid_2.epoch_5.ckpt.tar\n",
      "Epoch 6, loss: 54.142597, norm: 6.370638, elapsed: 1965.840851, lrn_rate: 1.000000\n",
      "Validation time: 0.392831 seconds\n",
      "Validation set metric: 6.730813\n",
      "Saving model to saved_models/attn_grid_2.epoch_6.ckpt.tar\n",
      "Epoch 7, loss: 51.517876, norm: 5.396397, elapsed: 2247.925877, lrn_rate: 1.000000\n",
      "Validation time: 0.362355 seconds\n",
      "Validation set metric: 6.421638\n",
      "Saving model to saved_models/attn_grid_2.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 8, loss: 43.787796, norm: 4.886232, elapsed: 2530.831523, lrn_rate: 0.500000\n",
      "Validation time: 0.370876 seconds\n",
      "Validation set metric: 5.952314\n",
      "Saving model to saved_models/attn_grid_2.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 9, loss: 40.818443, norm: 5.034775, elapsed: 2815.202959, lrn_rate: 0.250000\n",
      "Validation time: 0.371427 seconds\n",
      "Validation set metric: 5.723113\n",
      "Saving model to saved_models/attn_grid_2.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 5.72311309192254\n",
      "200 False 8 0.4\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 83.809555, norm: 4.057537, elapsed: 273.457965, lrn_rate: 1.000000\n",
      "Validation time: 0.365764 seconds\n",
      "Validation set metric: 23.071917\n",
      "Saving model to saved_models/attn_grid_3.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 86.704704, norm: 4.726288, elapsed: 547.393016, lrn_rate: 1.000000\n",
      "Validation time: 0.395032 seconds\n",
      "Validation set metric: 17.307456\n",
      "Saving model to saved_models/attn_grid_3.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 66.911827, norm: 4.402825, elapsed: 822.156838, lrn_rate: 1.000000\n",
      "Validation time: 0.356835 seconds\n",
      "Validation set metric: 13.374448\n",
      "Saving model to saved_models/attn_grid_3.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 62.270794, norm: 5.694883, elapsed: 1098.873116, lrn_rate: 1.000000\n",
      "Validation time: 0.353263 seconds\n",
      "Validation set metric: 9.893477\n",
      "Saving model to saved_models/attn_grid_3.epoch_3.ckpt.tar\n",
      "Epoch 4, loss: 62.905273, norm: 5.290662, elapsed: 1378.331791, lrn_rate: 1.000000\n",
      "Validation time: 0.373175 seconds\n",
      "Validation set metric: 8.682508\n",
      "Saving model to saved_models/attn_grid_3.epoch_4.ckpt.tar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss: 52.777771, norm: 5.691047, elapsed: 1657.517624, lrn_rate: 1.000000\n",
      "Validation time: 0.355772 seconds\n",
      "Validation set metric: 7.938821\n",
      "Saving model to saved_models/attn_grid_3.epoch_5.ckpt.tar\n",
      "Epoch 6, loss: 61.794411, norm: 6.426108, elapsed: 1936.887601, lrn_rate: 1.000000\n",
      "Validation time: 0.348664 seconds\n",
      "Validation set metric: 7.579755\n",
      "Saving model to saved_models/attn_grid_3.epoch_6.ckpt.tar\n",
      "Epoch 7, loss: 58.316906, norm: 5.636143, elapsed: 2217.693143, lrn_rate: 1.000000\n",
      "Validation time: 0.371190 seconds\n",
      "Validation set metric: 7.299893\n",
      "Saving model to saved_models/attn_grid_3.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 8, loss: 51.196472, norm: 5.013029, elapsed: 2497.512262, lrn_rate: 0.500000\n",
      "Validation time: 0.349605 seconds\n",
      "Validation set metric: 6.763396\n",
      "Saving model to saved_models/attn_grid_3.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 9, loss: 47.804970, norm: 5.102167, elapsed: 2778.161504, lrn_rate: 0.250000\n",
      "Validation time: 0.367842 seconds\n",
      "Validation set metric: 6.543959\n",
      "Saving model to saved_models/attn_grid_3.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 6.543959344008501\n",
      "200 True 4 0.2\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 77.921799, norm: 4.201652, elapsed: 273.800331, lrn_rate: 1.000000\n",
      "Validation time: 0.404151 seconds\n",
      "Validation set metric: 18.321237\n",
      "Saving model to saved_models/attn_grid_4.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 80.061142, norm: 4.923499, elapsed: 550.228777, lrn_rate: 1.000000\n",
      "Validation time: 0.391620 seconds\n",
      "Validation set metric: 13.918483\n",
      "Saving model to saved_models/attn_grid_4.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 59.586132, norm: 4.608985, elapsed: 827.197041, lrn_rate: 1.000000\n",
      "Validation time: 0.353776 seconds\n",
      "Validation set metric: 9.644605\n",
      "Saving model to saved_models/attn_grid_4.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 55.045631, norm: 5.908368, elapsed: 1105.585392, lrn_rate: 1.000000\n",
      "Validation time: 0.361324 seconds\n",
      "Validation set metric: 7.915523\n",
      "Saving model to saved_models/attn_grid_4.epoch_3.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 4, loss: 53.947441, norm: 5.361520, elapsed: 1385.202334, lrn_rate: 0.500000\n",
      "Validation time: 0.418510 seconds\n",
      "Validation set metric: 6.787118\n",
      "Saving model to saved_models/attn_grid_4.epoch_4.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 5, loss: 43.542664, norm: 6.245208, elapsed: 1665.456568, lrn_rate: 0.250000\n",
      "Validation time: 0.356272 seconds\n",
      "Validation set metric: 6.295384\n",
      "Saving model to saved_models/attn_grid_4.epoch_5.ckpt.tar\n",
      "Decaying LR to 0.125000\n",
      "Epoch 6, loss: 51.070637, norm: 6.960669, elapsed: 1946.965244, lrn_rate: 0.125000\n",
      "Validation time: 0.351350 seconds\n",
      "Validation set metric: 6.081556\n",
      "Saving model to saved_models/attn_grid_4.epoch_6.ckpt.tar\n",
      "Decaying LR to 0.062500\n",
      "Epoch 7, loss: 48.500435, norm: 5.910114, elapsed: 2226.234590, lrn_rate: 0.062500\n",
      "Validation time: 0.360739 seconds\n",
      "Validation set metric: 6.005617\n",
      "Saving model to saved_models/attn_grid_4.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.031250\n",
      "Epoch 8, loss: 44.064594, norm: 5.544730, elapsed: 2507.387086, lrn_rate: 0.031250\n",
      "Validation time: 0.355819 seconds\n",
      "Validation set metric: 5.950150\n",
      "Saving model to saved_models/attn_grid_4.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.015625\n",
      "Epoch 9, loss: 43.022419, norm: 5.858527, elapsed: 2789.384343, lrn_rate: 0.015625\n",
      "Validation time: 0.392147 seconds\n",
      "Validation set metric: 5.929888\n",
      "Saving model to saved_models/attn_grid_4.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 5.929888163985206\n",
      "200 True 4 0.4\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 80.919846, norm: 4.582043, elapsed: 269.123326, lrn_rate: 1.000000\n",
      "Validation time: 0.385350 seconds\n",
      "Validation set metric: 19.629608\n",
      "Saving model to saved_models/attn_grid_5.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 83.846222, norm: 5.241071, elapsed: 542.191104, lrn_rate: 1.000000\n",
      "Validation time: 0.353693 seconds\n",
      "Validation set metric: 14.764272\n",
      "Saving model to saved_models/attn_grid_5.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 65.174332, norm: 4.778107, elapsed: 814.743778, lrn_rate: 1.000000\n",
      "Validation time: 0.353189 seconds\n",
      "Validation set metric: 11.886541\n",
      "Saving model to saved_models/attn_grid_5.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 60.981152, norm: 5.968712, elapsed: 1090.004043, lrn_rate: 1.000000\n",
      "Validation time: 0.353783 seconds\n",
      "Validation set metric: 9.335173\n",
      "Saving model to saved_models/attn_grid_5.epoch_3.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 4, loss: 61.191242, norm: 5.375038, elapsed: 1365.859091, lrn_rate: 0.500000\n",
      "Validation time: 0.386384 seconds\n",
      "Validation set metric: 7.989257\n",
      "Saving model to saved_models/attn_grid_5.epoch_4.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 5, loss: 50.051792, norm: 6.178527, elapsed: 1642.623610, lrn_rate: 0.250000\n",
      "Validation time: 0.354101 seconds\n",
      "Validation set metric: 7.398204\n",
      "Saving model to saved_models/attn_grid_5.epoch_5.ckpt.tar\n",
      "Decaying LR to 0.125000\n",
      "Epoch 6, loss: 59.307312, norm: 7.137314, elapsed: 1919.201460, lrn_rate: 0.125000\n",
      "Validation time: 0.354267 seconds\n",
      "Validation set metric: 7.162647\n",
      "Saving model to saved_models/attn_grid_5.epoch_6.ckpt.tar\n",
      "Decaying LR to 0.062500\n",
      "Epoch 7, loss: 56.147991, norm: 5.810665, elapsed: 2194.852220, lrn_rate: 0.062500\n",
      "Validation time: 0.388363 seconds\n",
      "Validation set metric: 7.045846\n",
      "Saving model to saved_models/attn_grid_5.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.031250\n",
      "Epoch 8, loss: 51.828869, norm: 5.715759, elapsed: 2471.200237, lrn_rate: 0.031250\n",
      "Validation time: 0.400573 seconds\n",
      "Validation set metric: 6.985106\n",
      "Saving model to saved_models/attn_grid_5.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.015625\n",
      "Epoch 9, loss: 50.278885, norm: 5.570264, elapsed: 2748.088653, lrn_rate: 0.015625\n",
      "Validation time: 0.391616 seconds\n",
      "Validation set metric: 6.955871\n",
      "Saving model to saved_models/attn_grid_5.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 6.955870959106877\n",
      "200 True 8 0.2\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 78.055939, norm: 4.399601, elapsed: 272.657089, lrn_rate: 1.000000\n",
      "Validation time: 0.354965 seconds\n",
      "Validation set metric: 18.165227\n",
      "Saving model to saved_models/attn_grid_6.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 78.824440, norm: 5.276427, elapsed: 550.013885, lrn_rate: 1.000000\n",
      "Validation time: 0.367056 seconds\n",
      "Validation set metric: 13.387901\n",
      "Saving model to saved_models/attn_grid_6.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 57.863720, norm: 4.895478, elapsed: 828.730086, lrn_rate: 1.000000\n",
      "Validation time: 0.352305 seconds\n",
      "Validation set metric: 8.991170\n",
      "Saving model to saved_models/attn_grid_6.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 54.028553, norm: 5.656609, elapsed: 1109.136795, lrn_rate: 1.000000\n",
      "Validation time: 0.361284 seconds\n",
      "Validation set metric: 7.579922\n",
      "Saving model to saved_models/attn_grid_6.epoch_3.ckpt.tar\n",
      "Epoch 4, loss: 55.050648, norm: 5.349475, elapsed: 1390.106972, lrn_rate: 1.000000\n",
      "Validation time: 0.353842 seconds\n",
      "Validation set metric: 6.919784\n",
      "Saving model to saved_models/attn_grid_6.epoch_4.ckpt.tar\n",
      "Epoch 5, loss: 45.343040, norm: 6.299519, elapsed: 1670.594209, lrn_rate: 1.000000\n",
      "Validation time: 0.356303 seconds\n",
      "Validation set metric: 6.427721\n",
      "Saving model to saved_models/attn_grid_6.epoch_5.ckpt.tar\n",
      "Epoch 6, loss: 52.707630, norm: 6.814468, elapsed: 1951.234881, lrn_rate: 1.000000\n",
      "Validation time: 0.348605 seconds\n",
      "Validation set metric: 6.243900\n",
      "Saving model to saved_models/attn_grid_6.epoch_6.ckpt.tar\n",
      "Epoch 7, loss: 50.012188, norm: 5.943955, elapsed: 2231.551357, lrn_rate: 1.000000\n",
      "Validation time: 0.418138 seconds\n",
      "Validation set metric: 5.947431\n",
      "Saving model to saved_models/attn_grid_6.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 8, loss: 43.016766, norm: 5.050098, elapsed: 2512.055833, lrn_rate: 0.500000\n",
      "Validation time: 0.363793 seconds\n",
      "Validation set metric: 5.485799\n",
      "Saving model to saved_models/attn_grid_6.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 9, loss: 40.185081, norm: 5.137766, elapsed: 2792.097615, lrn_rate: 0.250000\n",
      "Validation time: 0.365701 seconds\n",
      "Validation set metric: 5.315936\n",
      "Saving model to saved_models/attn_grid_6.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 5.315935501788608\n",
      "200 True 8 0.4\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 80.696709, norm: 4.487724, elapsed: 268.828376, lrn_rate: 1.000000\n",
      "Validation time: 0.356540 seconds\n",
      "Validation set metric: 19.476453\n",
      "Saving model to saved_models/attn_grid_7.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 84.230835, norm: 5.347474, elapsed: 540.498028, lrn_rate: 1.000000\n",
      "Validation time: 0.353929 seconds\n",
      "Validation set metric: 14.954864\n",
      "Saving model to saved_models/attn_grid_7.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 64.211594, norm: 4.860816, elapsed: 813.037319, lrn_rate: 1.000000\n",
      "Validation time: 0.354883 seconds\n",
      "Validation set metric: 11.287956\n",
      "Saving model to saved_models/attn_grid_7.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 60.588867, norm: 6.156037, elapsed: 1087.799996, lrn_rate: 1.000000\n",
      "Validation time: 0.348687 seconds\n",
      "Validation set metric: 9.001583\n",
      "Saving model to saved_models/attn_grid_7.epoch_3.ckpt.tar\n",
      "Epoch 4, loss: 62.230396, norm: 5.461389, elapsed: 1363.474364, lrn_rate: 1.000000\n",
      "Validation time: 0.371995 seconds\n",
      "Validation set metric: 8.228699\n",
      "Saving model to saved_models/attn_grid_7.epoch_4.ckpt.tar\n",
      "Epoch 5, loss: 51.283405, norm: 6.145927, elapsed: 1638.798782, lrn_rate: 1.000000\n",
      "Validation time: 0.358811 seconds\n",
      "Validation set metric: 7.638402\n",
      "Saving model to saved_models/attn_grid_7.epoch_5.ckpt.tar\n",
      "Epoch 6, loss: 61.524147, norm: 7.029633, elapsed: 1915.414260, lrn_rate: 1.000000\n",
      "Validation time: 0.361229 seconds\n",
      "Validation set metric: 7.317560\n",
      "Saving model to saved_models/attn_grid_7.epoch_6.ckpt.tar\n",
      "Epoch 7, loss: 57.577705, norm: 5.748381, elapsed: 2190.865862, lrn_rate: 1.000000\n",
      "Validation time: 0.365750 seconds\n",
      "Validation set metric: 7.090227\n",
      "Saving model to saved_models/attn_grid_7.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 8, loss: 51.088554, norm: 6.523343, elapsed: 2467.822230, lrn_rate: 0.500000\n",
      "Validation time: 0.375150 seconds\n",
      "Validation set metric: 6.569260\n",
      "Saving model to saved_models/attn_grid_7.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 9, loss: 48.479004, norm: 5.179575, elapsed: 2744.953962, lrn_rate: 0.250000\n",
      "Validation time: 0.355020 seconds\n",
      "Validation set metric: 6.369815\n",
      "Saving model to saved_models/attn_grid_7.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 6.369814560538489\n",
      "400 False 4 0.2\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 76.013931, norm: 4.984907, elapsed: 441.719422, lrn_rate: 1.000000\n",
      "Validation time: 0.719462 seconds\n",
      "Validation set metric: 16.896606\n",
      "Saving model to saved_models/attn_grid_8.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 69.334068, norm: 6.838554, elapsed: 887.813493, lrn_rate: 1.000000\n",
      "Validation time: 0.741214 seconds\n",
      "Validation set metric: 9.312835\n",
      "Saving model to saved_models/attn_grid_8.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 52.829327, norm: 5.360114, elapsed: 1334.857489, lrn_rate: 1.000000\n",
      "Validation time: 0.843638 seconds\n",
      "Validation set metric: 7.313180\n",
      "Saving model to saved_models/attn_grid_8.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 49.375183, norm: 6.728409, elapsed: 1782.912957, lrn_rate: 1.000000\n",
      "Validation time: 0.675194 seconds\n",
      "Validation set metric: 6.458962\n",
      "Saving model to saved_models/attn_grid_8.epoch_3.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 4, loss: 47.607494, norm: 6.027325, elapsed: 2230.707132, lrn_rate: 0.500000\n",
      "Validation time: 0.793595 seconds\n",
      "Validation set metric: 5.666680\n",
      "Saving model to saved_models/attn_grid_8.epoch_4.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 5, loss: 37.086143, norm: 7.075492, elapsed: 2693.598260, lrn_rate: 0.250000\n",
      "Validation time: 0.874730 seconds\n",
      "Validation set metric: 5.397645\n",
      "Saving model to saved_models/attn_grid_8.epoch_5.ckpt.tar\n",
      "Decaying LR to 0.125000\n",
      "Epoch 6, loss: 43.877644, norm: 8.391942, elapsed: 3158.934554, lrn_rate: 0.125000\n",
      "Validation time: 0.780769 seconds\n",
      "Validation set metric: 5.279377\n",
      "Saving model to saved_models/attn_grid_8.epoch_6.ckpt.tar\n",
      "Decaying LR to 0.062500\n",
      "Epoch 7, loss: 41.404530, norm: 6.978399, elapsed: 3624.027682, lrn_rate: 0.062500\n",
      "Validation time: 0.796287 seconds\n",
      "Validation set metric: 5.264551\n",
      "Saving model to saved_models/attn_grid_8.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.031250\n",
      "Epoch 8, loss: 36.868183, norm: 6.648023, elapsed: 4090.833524, lrn_rate: 0.031250\n",
      "Validation time: 0.626812 seconds\n",
      "Validation set metric: 5.249808\n",
      "Saving model to saved_models/attn_grid_8.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.015625\n",
      "Epoch 9, loss: 35.882256, norm: 6.842906, elapsed: 4561.072343, lrn_rate: 0.015625\n",
      "Validation time: 0.765557 seconds\n",
      "Validation set metric: 5.237747\n",
      "Saving model to saved_models/attn_grid_8.epoch_9.ckpt.tar\n",
      "FINAL VAL PERF 5.2377473354136415\n",
      "400 False 4 0.4\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  True\n",
      "Epoch 0, loss: 76.563705, norm: 5.911415, elapsed: 455.875975, lrn_rate: 1.000000\n",
      "Validation time: 0.693812 seconds\n",
      "Validation set metric: 15.977037\n",
      "Saving model to saved_models/attn_grid_9.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 70.776237, norm: 7.351193, elapsed: 920.386000, lrn_rate: 1.000000\n",
      "Validation time: 0.736591 seconds\n",
      "Validation set metric: 9.430819\n",
      "Saving model to saved_models/attn_grid_9.epoch_1.ckpt.tar\n",
      "Epoch 2, loss: 55.107819, norm: 5.958332, elapsed: 1385.179906, lrn_rate: 1.000000\n",
      "Validation time: 0.738710 seconds\n",
      "Validation set metric: 7.601131\n",
      "Saving model to saved_models/attn_grid_9.epoch_2.ckpt.tar\n",
      "Epoch 3, loss: 52.549431, norm: 7.006198, elapsed: 1849.190932, lrn_rate: 1.000000\n",
      "Validation time: 0.835269 seconds\n",
      "Validation set metric: 6.708083\n",
      "Saving model to saved_models/attn_grid_9.epoch_3.ckpt.tar\n",
      "Decaying LR to 0.500000\n",
      "Epoch 4, loss: 51.415947, norm: 6.396795, elapsed: 2315.782051, lrn_rate: 0.500000\n",
      "Validation time: 0.918275 seconds\n",
      "Validation set metric: 5.962437\n",
      "Saving model to saved_models/attn_grid_9.epoch_4.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 5, loss: 41.581474, norm: 7.315292, elapsed: 2791.153168, lrn_rate: 0.250000\n",
      "Validation time: 0.727789 seconds\n",
      "Validation set metric: 5.626896\n",
      "Saving model to saved_models/attn_grid_9.epoch_5.ckpt.tar\n",
      "Decaying LR to 0.125000\n",
      "Epoch 6, loss: 48.155838, norm: 8.468993, elapsed: 3260.779359, lrn_rate: 0.125000\n",
      "Validation time: 0.670628 seconds\n",
      "Validation set metric: 5.468408\n",
      "Saving model to saved_models/attn_grid_9.epoch_6.ckpt.tar\n",
      "Decaying LR to 0.062500\n",
      "Epoch 7, loss: 46.264179, norm: 6.928561, elapsed: 3728.343514, lrn_rate: 0.062500\n",
      "Validation time: 0.709721 seconds\n",
      "Validation set metric: 5.421141\n",
      "Saving model to saved_models/attn_grid_9.epoch_7.ckpt.tar\n",
      "Decaying LR to 0.031250\n",
      "Epoch 8, loss: 42.016472, norm: 6.633673, elapsed: 4197.836678, lrn_rate: 0.031250\n",
      "Validation time: 0.742999 seconds\n",
      "Validation set metric: 5.398870\n",
      "Saving model to saved_models/attn_grid_9.epoch_8.ckpt.tar\n",
      "Decaying LR to 0.015625\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for hs, tw, force, drop in it.product([200,400,600],[False, True],\n",
    "                                      [4,8],[0.2, 0.4]):\n",
    "    print(hs, tw, force, drop)\n",
    "    train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=32, device=-1,\n",
    "                                                      repeat=False, sort_key=lambda x: len(x.src))\n",
    "    bs_encoder = BaseEncoder(DE, hidden_size=hs, num_layers=4, word_features=hs, \n",
    "                             dropout=drop)\n",
    "    # TODO: decide whether to add dropout to output states of encoder!\n",
    "    at_decoder = AttnDecoder(EN, hidden_size=hs, num_layers=4, word_features=hs, dropout=drop,\n",
    "                             tie_weights=tw)\n",
    "    trainer = NMTTrainer([bs_encoder, at_decoder], DE, EN, lrn_rate=1.0, \n",
    "                         lrn_decay='adaptive', attention=True,\n",
    "                         clip_norm=5, lrn_decay_force=force)\n",
    "    evaluator = NMTEvaluator([bs_encoder, at_decoder], DE, EN, attention=True,\n",
    "                            record_attention=False)\n",
    "    trainer.train(train_iter, verbose=True, le=evaluator, val_iter=val_iter,\n",
    "                  save_model_fn='attn_grid_%d' % cnt, num_iter=10)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Validation time: 0.677992 seconds\n",
      "5.322171705651731\n",
      "Target padding token: 1\n",
      "Using CUDA...\n",
      "Innitializing parameters status:  False\n",
      "Epoch 0, loss: 39.508476, norm: 6.285943, elapsed: 426.947739, lrn_rate: 0.500000\n",
      "Validation time: 0.728775 seconds\n",
      "Validation set metric: 5.209565\n",
      "Saving model to saved_models/attn_med_1b.epoch_0.ckpt.tar\n",
      "Epoch 1, loss: 44.648376, norm: 7.371956, elapsed: 859.301896, lrn_rate: 0.500000\n",
      "Validation time: 0.614820 seconds\n",
      "Validation set metric: 5.190459\n",
      "Saving model to saved_models/attn_med_1b.epoch_1.ckpt.tar\n",
      "Decaying LR to 0.250000\n",
      "Epoch 2, loss: 38.062698, norm: 7.248244, elapsed: 1291.240771, lrn_rate: 0.250000\n",
      "Validation time: 0.749838 seconds\n",
      "Validation set metric: 5.085312\n",
      "Saving model to saved_models/attn_med_1b.epoch_2.ckpt.tar\n",
      "Decaying LR to 0.125000\n",
      "Epoch 3, loss: 32.695580, norm: 6.297701, elapsed: 1722.055861, lrn_rate: 0.125000\n",
      "Validation time: 0.788171 seconds\n",
      "Validation set metric: 5.076100\n",
      "Saving model to saved_models/attn_med_1b.epoch_3.ckpt.tar\n",
      "Decaying LR to 0.062500\n",
      "Epoch 4, loss: 35.089790, norm: 6.534322, elapsed: 2152.567385, lrn_rate: 0.062500\n",
      "Validation time: 0.662246 seconds\n",
      "Validation set metric: 5.091741\n",
      "Saving model to saved_models/attn_med_1b.epoch_4.ckpt.tar\n",
      "Decaying LR to 0.031250\n",
      "Epoch 5, loss: 31.575603, norm: 6.593545, elapsed: 2585.185066, lrn_rate: 0.031250\n",
      "Validation time: 0.663013 seconds\n",
      "Validation set metric: 5.105446\n",
      "Saving model to saved_models/attn_med_1b.epoch_5.ckpt.tar\n",
      "Decaying LR to 0.015625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bdd8cc10b2ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                      clip_norm=5, lrn_decay_force=2)\n\u001b[1;32m     15\u001b[0m trainer.train(train_iter, verbose=True, le=evaluator, val_iter=val_iter,\n\u001b[0;32m---> 16\u001b[0;31m               save_model_fn='attn_med_1b', init_parameters=False)\n\u001b[0m",
      "\u001b[0;32m~/cs287/hw3/helpers.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, torch_train_iter, le, val_iter, save_model_fn, init_parameters, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m                 \u001b[0mres_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_iter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs287/hw3/helpers.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, batch, **kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# norms must be clipped after backward but before step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mloss_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs287/hw3/helpers.py\u001b[0m in \u001b[0;36mclip_norms\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# Norm clipping: returns a float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             norm = nn.utils.clip_grad_norm(\n\u001b[0;32m--> 434\u001b[0;31m                 parameters, self.clip_norm)\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mparam_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mtotal_norm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparam_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load a model and continue training:\n",
    "ld_enc, ld_dec = load_checkpoint('saved_models/attn_med_1.epoch_8.ckpt.tar')\n",
    "ld_encoder = BaseEncoder(DE, hidden_size=400, num_layers=4, word_features=400, \n",
    "                         dropout=0.2)\n",
    "ld_decoder = AttnDecoder(EN, hidden_size=400, num_layers=4, word_features=400, \n",
    "                         dropout=0.2)\n",
    "set_parameters(ld_encoder, ld_enc)\n",
    "set_parameters(ld_decoder, ld_dec)\n",
    "evaluator = NMTEvaluator([ld_encoder, ld_decoder], DE, EN, attention=True,\n",
    "                        record_attention=False)\n",
    "print(evaluator.evaluate(val_iter))\n",
    "trainer = NMTTrainer([ld_encoder, ld_decoder], DE, EN, lrn_rate=0.5, \n",
    "                     lrn_decay='adaptive', attention=True,\n",
    "                     clip_norm=5, lrn_decay_force=2)\n",
    "trainer.train(train_iter, verbose=True, le=evaluator, val_iter=val_iter,\n",
    "              save_model_fn='attn_med_1b', init_parameters=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation time: 0.659822 seconds\n",
      "5.120132318658038\n",
      "Validation time: 0.872873 seconds\n",
      "6.3874894806368365\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.evaluate(val_iter))\n",
    "print(evaluator.evaluate(test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation time: 0.456792 seconds\n",
      "6.048956472651303\n",
      "3722\n",
      "Variable containing:\n",
      " 0.6505  0.1110  0.0659  0.1725\n",
      " 0.5297  0.1554  0.2806  0.0343\n",
      " 0.0089  0.4239  0.4734  0.0938\n",
      " 0.0180  0.0371  0.9122  0.0327\n",
      " 0.0822  0.0702  0.3141  0.5335\n",
      " 0.4222  0.2591  0.0997  0.2190\n",
      " 0.1612  0.3041  0.4915  0.0432\n",
      " 0.2962  0.4637  0.0781  0.1620\n",
      "[torch.cuda.FloatTensor of size 8x4 (GPU 0)]\n",
      "\n",
      "Source\n",
      "Ich hatte Angst –\n",
      "Target\n",
      "<s> And I was scared . </s> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.evaluate(val_iter))\n",
    "print(len(train_iter))\n",
    "print(evaluator.attns_log[0][4])\n",
    "val_iter.init_epoch()\n",
    "batch = next(iter(val_iter))\n",
    "sent_inspect(batch, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using final MLP\n",
      "Target padding token: 1\n",
      "Source padding token: 1\n",
      "Using CUDA...\n",
      "Validation time: 1.909739 seconds\n",
      "4.293765398892552\n"
     ]
    }
   ],
   "source": [
    "# save_checkpoint(bs_encoder, at_decoder, filename='saved_models/attn_big_0.epoch_10.ckpt.tar')\n",
    "def load_validate_model(fn):\n",
    "    ld_enc, ld_dec = load_checkpoint(fn)\n",
    "    ld_encoder = BaseEncoder(DE, hidden_size=650, num_layers=4, word_features=650, \n",
    "                             bidirectional=True, dropout=0.35)\n",
    "    ld_decoder = AttnDecoder(EN, hidden_size=650, num_layers=4, word_features=650, dropout=0.35,\n",
    "                             tie_weights=False, enc_linear=650,\n",
    "                             enc_bidirectional=True)\n",
    "    set_parameters(ld_encoder, ld_enc)\n",
    "    set_parameters(ld_decoder, ld_dec)\n",
    "    evaluator = NMTEvaluator([ld_encoder, ld_decoder], DE, EN, attention=True,\n",
    "                            record_attention=True)\n",
    "    print(evaluator.evaluate(val_iter))\n",
    "    return evaluator\n",
    "evaluator=load_validate_model('saved_models/attn_med_5.epoch_10.ckpt.tar')\n",
    "# print(evaluator.evaluate(test_iter)) # KEYYY\n",
    "# evaluator.predict(pred_set, fn='predictions_big_2_100.txt',beam_size=200, ignore_eos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using final MLP\n",
      "Target padding token: 1\n",
      "Source padding token: 1\n",
      "Using CUDA...\n",
      "Validation time: 1.906080 seconds\n",
      "10.928670369486982\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86fc8dcda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using final MLP\n",
      "Target padding token: 1\n",
      "Source padding token: 1\n",
      "Using CUDA...\n",
      "Validation time: 1.887554 seconds\n",
      "6.93020460762847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86fc82fb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86fc97e550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using final MLP\n",
      "Target padding token: 1\n",
      "Source padding token: 1\n",
      "Using CUDA...\n",
      "Validation time: 1.847894 seconds\n",
      "5.79542815876869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86fc79b048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86fc7c2860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using final MLP\n",
      "Target padding token: 1\n",
      "Source padding token: 1\n",
      "Using CUDA...\n",
      "Validation time: 2.416572 seconds\n",
      "4.643665067292896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86fc779cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86fc7af128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using final MLP\n",
      "Target padding token: 1\n",
      "Source padding token: 1\n",
      "Using CUDA...\n",
      "Validation time: 1.987229 seconds\n",
      "4.293765398892552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86fc7a2f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86fc7d7898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86fc838da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ep in [0,1,2,6,10]:\n",
    "    evaluator = load_validate_model('saved_models/attn_med_5.epoch_%d.ckpt.tar' % ep)\n",
    "    attn_list = list(evaluator.attns_log[10][i][1] for i in range(4))\n",
    "    evaluator.visualize_attn(*attn_list)\n",
    "    plt.savefig('attn_plots/learning_%d.pdf' % ep)\n",
    "# attn_list = list(evaluator.attns_log[17][i][1] for i in range(4))\n",
    "# evaluator.visualize_attn(*attn_list)\n",
    "# plt.savefig('attn_plots/attn_vis_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter.init_epoch()\n",
    "debug_iter = iter(test_iter)\n",
    "for i in range(10):\n",
    "    batch = next(debug_iter)\n",
    "debug_set = [batch.src.data[:, i] for i in range(batch.src.data.size(1))]\n",
    "debug_ans = [batch.trg.data[:, i] for i in range(batch.trg.data.size(1))]\n",
    "evaluator.predict(pred_set, fn='predictions_real.txt',beam_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation time: 1.352269 seconds\n",
      "4.868429206982359\n",
      "Validation time: 1.816732 seconds\n",
      "6.052567905074193\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.evaluate(val_iter))\n",
    "print(evaluator.evaluate(test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-inf\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([-np.inf])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that NMT{Trainer/Evaluator} extends\n",
    "class NMTModelUser(object):\n",
    "    # Models is a list [Encoder, Decoder]\n",
    "    def __init__(self, models, TEXT_SRC, TEXT_TRG, mask_src=False,\n",
    "                 attention=False, reverse_enc_input=False, cuda=True):\n",
    "        self._TEXT_SRC = TEXT_SRC\n",
    "        self._TEXT_TRG = TEXT_TRG\n",
    "        self.trg_pad = TEXT_TRG.vocab.stoi['<pad>']\n",
    "        self.src_pad = TEXT_SRC.vocab.stoi['<pad>']\n",
    "        print('Target padding token: %d' % self.trg_pad)\n",
    "        print('Source padding token: %d' % self.src_pad)\n",
    "        self.models = models\n",
    "        self.mask_src = mask_src\n",
    "        self.use_attention = attention\n",
    "        self.record_attention = False\n",
    "        self.reverse_enc_input = reverse_enc_input\n",
    "        self.cuda = cuda and torch.cuda.is_available()\n",
    "        if self.cuda:\n",
    "            print('Using CUDA...')\n",
    "        else:\n",
    "            print('CUDA is unavailable...')\n",
    "\n",
    "    def get_src_and_trg(self, batch):\n",
    "        if self.reverse_enc_input:\n",
    "            src_data = torch.t(batch.src.data)\n",
    "            ind_rev = torch.LongTensor(np.arange(src_data.size(1) - 1, -1, -1))\n",
    "            src = torch.index_select(torch.t(batch.src.data), dim=1,\n",
    "                                     index=ind_rev)\n",
    "            src = src.contiguous()\n",
    "        else:\n",
    "            src = torch.t(batch.src.data).contiguous()\n",
    "        trg = torch.t(batch.trg.data)\n",
    "        # Have to shift the target so we don't predict the word \n",
    "        # we see (this is ok since sentences in trg all begin \n",
    "        # with <s>)\n",
    "        trg_feat = trg[:, :-1].contiguous()\n",
    "        trg_lab = trg[:, 1:].contiguous()\n",
    "        return (src, trg_feat, trg_lab)\n",
    "\n",
    "    def zeros_hidden(self, batch_sz, model_num):\n",
    "        num_directions = 2 if self.models[model_num].bidirectional else 1\n",
    "        return torch.zeros(self.models[model_num].num_layers * num_directions, \n",
    "                           batch_sz,\n",
    "                           self.models[model_num].hidden_size)\n",
    "\n",
    "    # Ok to have self.prev_hidden apply to encoder then decoder since\n",
    "    # encoder all ends before decoder starts\n",
    "    def prepare_hidden(self, batch_sz, zero_out=True, model_num=0):\n",
    "        if (not self.prev_hidden is None) and (not zero_out):\n",
    "            pre_hidden = self.prev_hidden\n",
    "        else:\n",
    "            pre_hidden = (self.zeros_hidden(batch_sz, model_num) \\\n",
    "                          for i in range(2))\n",
    "        if self.cuda:\n",
    "            pre_hidden = tuple(t.cuda() for t in pre_hidden)\n",
    "        return tuple(autograd.Variable(t) for t in pre_hidden)\n",
    "\n",
    "    # kwargs can contain zero_out, model_num for prepare_hidden\n",
    "    def prepare_model_inputs(self, batch, **kwargs):\n",
    "        if self.cuda:\n",
    "            src, trg_feat, trg_lab = \\\n",
    "                tuple(t.cuda() for t in self.get_src_and_trg(batch))\n",
    "        else:\n",
    "            src, trg_feat, trg_lab = self.get_src_and_trg(batch)\n",
    "\n",
    "        # TODO: can comment this out (assuming it passes\n",
    "        # -- just is checking batch-sz)\n",
    "        assert batch.src.size(1) == batch.trg.size(1)\n",
    "        var_hidden = self.prepare_hidden(batch.src.size(1), **kwargs)\n",
    "\n",
    "        var_src = autograd.Variable(src)\n",
    "        var_trg_feat = autograd.Variable(trg_feat)\n",
    "        var_trg_lab = autograd.Variable(trg_lab)\n",
    "\n",
    "        return (var_src, var_trg_feat, var_trg_lab, var_hidden)\n",
    "\n",
    "    def init_epoch(self):\n",
    "        self.prev_hidden = None\n",
    "        self.debug_cnt = 0\n",
    "        \n",
    "    def debug_model_output(self, var_src, var_trg, dec_output,\n",
    "                           num_samp=10):\n",
    "        print('DEBUG CNT: %d' % self.debug_cnt)\n",
    "        print(var_src.size(), var_trg.size(), dec_output.size())\n",
    "        self.debug_cnt += 1\n",
    "        if self.debug_cnt > 10:\n",
    "            return\n",
    "        src = var_src.data\n",
    "        trg = var_trg.data\n",
    "        _, pred = torch.topk(dec_output, k=1, dim=2)\n",
    "        pred = pred.squeeze().data\n",
    "        print(pred.size()) # should be [batch_sz, sent_len]\n",
    "        for i in range(num_samp):\n",
    "            print('=== SAMPLE %d ===' % i)\n",
    "            print('-- SRC --')\n",
    "            print(' '.join(self._TEXT_SRC.vocab.itos[src[i,j]] \\\n",
    "                                           for j in range(src.size(1))))\n",
    "            print('-- REAL TRG --')\n",
    "            print(' '.join(self._TEXT_TRG.vocab.itos[trg[i,j]] \\\n",
    "                                           for j in range(trg.size(1))))\n",
    "            print('-- PRED TRG --')\n",
    "            print(' '.join(self._TEXT_TRG.vocab.itos[pred[i,j]] \\\n",
    "                                           for j in range(pred.size(1))))\n",
    "\n",
    "\n",
    "    def set_enc_prev_hidden(self, enc_hidden):\n",
    "        # Each element of hidden is [F(x_T), B(x_1)]; we want to use\n",
    "        # the first\n",
    "        if self.models[1].enc_directions == 2:\n",
    "            assert self.use_attention\n",
    "            # This is the first hidden B(x_1) of the backwards layer\n",
    "            self.prev_hidden = tuple(h[self.models[0].num_layers:,:,:] for \\\n",
    "                                     h in enc_hidden)\n",
    "        else:\n",
    "            self.prev_hidden = enc_hidden\n",
    "\n",
    "    def generate_attn_mask(self, var_src):\n",
    "        if not self.mask_src:\n",
    "            return None\n",
    "        # Using broadcasting \n",
    "        pad_mask = torch.eq(var_src, self.src_pad).type(torch.FloatTensor)\n",
    "        pad_mask = pad_mask.cuda() if self.cuda else pad_mask\n",
    "        return pad_mask\n",
    "        \n",
    "    def run_model(self, batch, mode='mean'):\n",
    "        # var_src, var_trg are [batch_sz, sent_len]\n",
    "        var_src, var_trg_feat, var_trg_lab, var_hidden = \\\n",
    "            self.prepare_model_inputs(\n",
    "            batch, zero_out=True, model_num=0)\n",
    "\n",
    "        # For attention, will use enc_output (not otherwise)\n",
    "        enc_output, enc_hidden = self.models[0](var_src, var_hidden)\n",
    "        self.set_enc_prev_hidden(enc_hidden)\n",
    "            \n",
    "        if self.use_attention:\n",
    "            pad_mask = self.generate_attn_mask(var_src)\n",
    "            dec_output, dec_hidden, dec_attn = self.models[1](\n",
    "                var_trg_feat, self.prev_hidden, enc_output, pad_mask)\n",
    "            if self.record_attention:\n",
    "                _, pred = torch.topk(dec_output, k=1, dim=2)\n",
    "                self.attns_log.append((dec_attn, var_src, pred.squeeze(),\n",
    "                                       var_trg_lab))\n",
    "        else:\n",
    "            # Using real words as input. Use prev_hidden both to\n",
    "            # initialize hidden state (the first time) and as context\n",
    "            # vector\n",
    "            dec_output, dec_hidden = self.models[1](\n",
    "                var_trg_feat, self.prev_hidden, enc_hidden)\n",
    "            \n",
    "        # TEMPORARY\n",
    "        # self.debug_model_output(var_src, var_trg_lab, dec_output)\n",
    "        self.prev_hidden = dec_hidden\n",
    "        loss = self.nll_loss(dec_output, var_trg_lab, mode=mode)\n",
    "        return loss\n",
    "\n",
    "    # Assume log_probs is [batch_sz, sent_len, V], output is\n",
    "    # [batch_sz, sent_len]\n",
    "    def nll_loss(self, log_probs, output, mode='mean', **kwargs):\n",
    "        batch_sz = log_probs.size(0)\n",
    "        sl_type = torch.cuda.FloatTensor if self.cuda else \\\n",
    "            torch.FloatTensor\n",
    "        sent_len = torch.sum((output != self.trg_pad).type(sl_type)) / batch_sz\n",
    "        # sent_len = sent_len.data[0]\n",
    "        # sent_len = log_probs.size(1)\n",
    "        # print(sent_len, log_probs.size())\n",
    "        log_probs_rshp = log_probs.view(-1, log_probs.size(2))\n",
    "        output_rshp = output.view(-1)\n",
    "        if mode == 'mean':\n",
    "            # Sum over all words in sent, mean over sentences; \n",
    "            # make sure to ignore padding\n",
    "            return F.nll_loss(log_probs_rshp, output_rshp, \n",
    "                              ignore_index=self.trg_pad, \n",
    "                              **kwargs) * sent_len\n",
    "        elif mode == 'sum':\n",
    "            # Sum over all sentences and words in them\n",
    "            return F.nll_loss(log_probs_rshp, output_rshp,\n",
    "                              ignore_index=self.trg_pad,\n",
    "                              size_average=False)\n",
    "        else:\n",
    "            raise ValueError('Invalid mode field: %s' % mode)\n",
    "            \n",
    "class NMTEvaluator(NMTModelUser):\n",
    "    def __init__(self, models, TEXT_SRC, TEXT_TRG, record_attention=False,\n",
    "                 visualize_freq=None, **kwargs):\n",
    "        super(NMTEvaluator, self).__init__(models, TEXT_SRC, TEXT_TRG,\n",
    "                                           **kwargs)\n",
    "        # Perhaps overwrite record_attention\n",
    "        self.record_attention = record_attention\n",
    "        self.visualize_freq = visualize_freq\n",
    "        \n",
    "    def init_epoch(self):\n",
    "        super(NMTEvaluator, self).init_epoch()\n",
    "        self.attns_log = list()\n",
    "        \n",
    "    def visualize_attn(self, dec_attn_smpl, var_src_smpl, pred_smpl,\n",
    "                       var_trg_lab=None):\n",
    "        # dec_attn_smpl is [src_len, pred_len], var_src_smpl is [src_len],\n",
    "        # pred_smpl is [pred_len]\n",
    "        attn = dec_attn_smpl.cpu().data.numpy()\n",
    "        src_words = np.array(list(map(lambda x: self._TEXT_SRC.vocab.itos[x], \n",
    "                                      var_src_smpl.cpu().data.numpy())))\n",
    "        pred_words = np.array(list(map(lambda x: self._TEXT_TRG.vocab.itos[x], \n",
    "                                       pred_smpl.cpu().data.numpy())))\n",
    "        if not var_trg_lab is None:\n",
    "            trg_cpu = var_trg_lab.cpu().data.numpy()\n",
    "            trg_words = np.array(list(map(lambda x : self._TEXT_TRG.vocab.itos[x],\n",
    "                                         trg_cpu)))\n",
    "            pred_words = np.array(['%s (%s)' % (pred_words[i], trg_words[i]) for \\\n",
    "                                   i in range(pred_words.shape[0])])\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(attn, cmap='gray')\n",
    "        plt.xticks(range(len(src_words)),src_words, rotation='vertical')\n",
    "        plt.yticks(range(len(pred_words)),pred_words)\n",
    "        ax.xaxis.tick_top()\n",
    "        plt.show()\n",
    "\n",
    "    def evaluate(self, test_iter, num_iter=None):\n",
    "        start_time = time.time()\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "        nll_sum = 0\n",
    "        nll_cnt = 0\n",
    "\n",
    "        self.init_epoch()\n",
    "        test_iter.init_epoch()\n",
    "        for i,batch in enumerate(test_iter):\n",
    "            nll_cnt += batch.trg.data.numel()\n",
    "            loss = self.run_model(batch, mode='sum')\n",
    "            # TODO: make sure loss just has 1 element!\n",
    "            nll_sum += loss.data[0]\n",
    "            \n",
    "            if self.visualize_freq and i % self.visualize_freq == 0:\n",
    "                sample = self.attns_log[-1]\n",
    "                self.visualize_attn(sample[0][0], sample[1][0], sample[2][0])\n",
    "            if not num_iter is None and i > num_iter:\n",
    "                break\n",
    "                        \n",
    "        # Wrap the model.eval(), just in case\n",
    "        for model in self.models:\n",
    "            model.train()\n",
    "        \n",
    "        print('Validation time: %f seconds' % (time.time() - start_time))\n",
    "        return np.exp(nll_sum / nll_cnt)\n",
    "    \n",
    "    # Performs beam search\n",
    "    def run_model_predict(self, sent, ref_beam, ref_voc,\n",
    "                          beam_size=100, pred_len=3, pred_num=None,\n",
    "                          ignore_eos=False):\n",
    "        if pred_num is None:\n",
    "            pred_num = beam_size\n",
    "        \n",
    "        # [sent_len]\n",
    "        sent_tsr = torch.LongTensor(sent)\n",
    "        if self.reverse_enc_input:\n",
    "            ind_rev = torch.LongTensor(np.arange(sent_tsr.size(0) - 1, -1, -1))\n",
    "            sent_tsr = torch.index_select(sent_tsr, dim=0,\n",
    "                                          index=ind_rev)\n",
    "        if self.cuda:\n",
    "            sent_tsr = sent_tsr.cuda()\n",
    "        var_src = autograd.Variable(sent_tsr.view(1, -1).expand(beam_size, -1))\n",
    "        var_hidden = self.prepare_hidden(beam_size, zero_out=True)\n",
    "        \n",
    "        # For attention, will use enc_output (not otherwise)\n",
    "        enc_output, enc_hidden = self.models[0](var_src, var_hidden)\n",
    "        self.set_enc_prev_hidden(enc_hidden)\n",
    "        \n",
    "        # Make sure to start with SOS token\n",
    "        sos_token = self._TEXT_TRG.vocab.stoi['<s>']\n",
    "        self.cur_beams = (sos_token * torch.ones(beam_size, 1)).type(torch.LongTensor)\n",
    "        self.cur_beam_vals = torch.zeros(beam_size, 1).type(torch.FloatTensor)\n",
    "        if self.cuda:\n",
    "            self.cur_beams = self.cur_beams.cuda()\n",
    "            self.cur_beam_vals = self.cur_beam_vals.cuda()\n",
    "        self.cur_beams = autograd.Variable(self.cur_beams)\n",
    "        self.cur_beam_vals = autograd.Variable(self.cur_beam_vals)\n",
    "        for i in range(pred_len):\n",
    "            cur_sent = self.cur_beams[:, i:i+1]\n",
    "            if self.use_attention:\n",
    "                pad_mask = self.generate_attn_mask(var_src)\n",
    "\n",
    "                dec_output, dec_hidden, dec_attn = self.models[1](\n",
    "                    cur_sent, self.prev_hidden, enc_output, pad_mask)\n",
    "                if self.record_attention:\n",
    "                    _, pred = torch.topk(dec_output, k=1, dim=2)\n",
    "                    self.attns_log.append((dec_attn, var_src, pred.squeeze(),\n",
    "                                           None))\n",
    "            else:\n",
    "                # Using real words as input. Use prev_hidden both to\n",
    "                # initialize hidden state (the first time) and as context\n",
    "                # vector\n",
    "                dec_output, dec_hidden = self.models[1](\n",
    "                    cur_sent, self.prev_hidden, enc_hidden)\n",
    "            self.prev_hidden = dec_hidden\n",
    "            \n",
    "            # dec_output is [batch_sz, sent_len=1, V]\n",
    "            # print(dec_output.size())\n",
    "            # Using broadcasting:\n",
    "            dec_output = dec_output.squeeze()\n",
    "\n",
    "            # Deal with EOS tokens:\n",
    "            if ignore_eos:\n",
    "                eos_token = self._TEXT_TRG.vocab.stoi['</s>']\n",
    "                dec_output[:, eos_token] = -np.inf\n",
    "\n",
    "            dec_output = dec_output + self.cur_beam_vals\n",
    "            if i == 0:\n",
    "                # All start words were the same, so need to restrict \n",
    "                # to the first row\n",
    "                dec_output = dec_output[0, :]\n",
    "            else:\n",
    "                dec_output = dec_output.view(-1)\n",
    "                \n",
    "            topk_dec, topk_inds = torch.topk(dec_output, k=beam_size)\n",
    "            chosen_prev_inds = torch.index_select(ref_beam, dim=0, index=topk_inds)\n",
    "            chosen_prevs = torch.index_select(self.cur_beams, dim=0,\n",
    "                                              index=chosen_prev_inds)\n",
    "            # Important to update hidden to reflect which prev \n",
    "            # sents we choose\n",
    "            self.prev_hidden = tuple(torch.index_select(\n",
    "                    self.prev_hidden[j], dim=1, index=chosen_prev_inds) \\\n",
    "                                     for j in range(len(self.prev_hidden)))\n",
    "            \n",
    "            # Update self.cur_beam_vals: [beam_sz, 1] \n",
    "            # (we already added on prev cur_beam_vals above)\n",
    "            self.cur_beam_vals = topk_dec.view(-1, 1)\n",
    "            # print('cur_beam_vals', self.cur_beam_vals)\n",
    "\n",
    "            # [batch_sz=beam_sz, 1]\n",
    "            chosen_nexts = torch.index_select(ref_voc, dim=0, index=topk_inds).view(-1, 1)\n",
    "            # print('chosen_nexts', chosen_nexts)\n",
    "            self.cur_beams = torch.cat((chosen_prevs, chosen_nexts), dim=1)\n",
    "            # print('cur_beams', self.cur_beams)\n",
    "            \n",
    "        return self.cur_beams\n",
    "    \n",
    "    @staticmethod\n",
    "    def escape(l):\n",
    "        return l.replace(\"\\\"\", \"<quote>\").replace(\",\", \"<comma>\")\n",
    "    \n",
    "    def predict(self, test_set, fn='predictions.txt', num_cands=100, pred_len=3,\n",
    "                beam_size=100, ignore_eos=False):\n",
    "        start_time = time.time()\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "            \n",
    "        # Create reference idx for expanding beams and vocab\n",
    "        trg_vocab_sz = len(self._TEXT_TRG.vocab)\n",
    "        ref_beam = torch.LongTensor(np.arange(beam_size)).view(-1, 1).expand(-1, trg_vocab_sz)\n",
    "        ref_beam = ref_beam.contiguous().view(-1)\n",
    "        ref_beam = ref_beam.cuda() if self.cuda else ref_beam\n",
    "        ref_beam = autograd.Variable(ref_beam)\n",
    "        print(ref_beam.size())\n",
    "        \n",
    "        ref_voc = torch.LongTensor(np.arange(trg_vocab_sz)).view(1, -1).expand(beam_size, -1)\n",
    "        ref_voc = ref_voc.contiguous().view(-1)\n",
    "        ref_voc = ref_voc.cuda() if self.cuda else ref_voc\n",
    "        ref_voc = autograd.Variable(ref_voc)\n",
    "        print(ref_voc.size())\n",
    "            \n",
    "        self.init_epoch()\n",
    "        predictions = list()\n",
    "        for i,sent in enumerate(test_set):\n",
    "            # [pred_num, pred_len] tensor\n",
    "            best_translations = self.run_model_predict(sent, ref_beam=ref_beam,\n",
    "                                                       ref_voc=ref_voc,\n",
    "                                                       pred_len=pred_len,\n",
    "                                                       beam_size=beam_size,\n",
    "                                                       ignore_eos=ignore_eos)\n",
    "            predictions.append(best_translations)\n",
    "            # if i > 10:\n",
    "            #     break\n",
    "            \n",
    "        print('Writing predictions to %s...' % fn)\n",
    "        with open(fn, 'w') as fout:\n",
    "            print('id,word', file=fout)\n",
    "            for i,preds in enumerate(predictions):\n",
    "                # We can traverse the beam in order since topk \n",
    "                # sorts its output\n",
    "                cands = list()\n",
    "                for j in range(num_cands):\n",
    "                    # Ignore SOS\n",
    "                    words = [self._TEXT_TRG.vocab.itos[preds[j,k].data[0]] for k in range(1, pred_len + 1)]\n",
    "                    sent = '|'.join(self.escape(l) for l in words)\n",
    "                    cands.append(sent)\n",
    "                print('%d,%s' % (i+1, ' '.join(cands)), file=fout)\n",
    "        print('Computing predictions took %f seconds' % (time.time() - start_time))\n",
    "        \n",
    "        # Wrap model.eavl\n",
    "        for model in self.models:\n",
    "            model.train()\n",
    "            \n",
    "\n",
    "    \n",
    "class NMTTrainer(NMTModelUser):\n",
    "    def __init__(self, models, TEXT_SRC, TEXT_TRG, lrn_rate=0.1,\n",
    "                 optimizer=optim.SGD, lrn_decay='none',\n",
    "                 lrn_decay_force=np.inf,\n",
    "                 lrn_decay_rate=0.1,\n",
    "                 clip_norm=10, **kwargs):\n",
    "        super(NMTTrainer, self).__init__(models, TEXT_SRC, TEXT_TRG, **kwargs)\n",
    "\n",
    "        self.base_lrn_rate = lrn_rate\n",
    "        self.optimizer_type = optimizer\n",
    "        self.init_optimizers()\n",
    "\n",
    "        # Do learning rate decay:\n",
    "        self.lr_decay_opt = lrn_decay\n",
    "        self.lr_decay_force = lrn_decay_force\n",
    "        if self.lr_decay_opt == 'none' or self.lr_decay_opt == 'adaptive':\n",
    "            self.lambda_lr = lambda i : 1\n",
    "        elif self.lr_decay_opt == 'invlin':\n",
    "            decay_rate = lrn_decay_rate\n",
    "            self.lambda_lr = lambda i : 1 / (1 + (i-6) * decay_rate) if i > 6 else 1\n",
    "        else:\n",
    "            raise ValueError('Invalid learning rate decay option: %s' \\\n",
    "                             % self.lr_decay_opt)\n",
    "        self.schedulers = [optim.lr_scheduler.LambdaLR(optimizer,\n",
    "            self.lambda_lr) for optimizer in self.optimizers]\n",
    "\n",
    "        self.clip_norm = clip_norm\n",
    "        self.init_lists()\n",
    "        if self.cuda:\n",
    "            for model in self.models:\n",
    "                model.cuda()\n",
    "                \n",
    "    def init_optimizers(self):\n",
    "        self.optimizers = [self.optimizer_type(filter(lambda p : p.requires_grad,\n",
    "                                                      model.parameters()),\n",
    "                                               lr = self.base_lrn_rate) for \\\n",
    "                           model in self.models]\n",
    "    def init_lists(self):\n",
    "        self.training_losses = list()\n",
    "        self.training_norms = list()\n",
    "        self.val_perfs = list()\n",
    "\n",
    "    def get_loss_data(self, loss):\n",
    "        if self.cuda:\n",
    "            return loss.data.cpu().numpy()[0]\n",
    "        else:\n",
    "            return loss.data.numpy()[0]\n",
    "\n",
    "    def make_recordings(self, loss, norm):\n",
    "        self.training_norms.append(norm)\n",
    "        self.training_losses.append(loss)\n",
    "\n",
    "    def clip_norms(self):\n",
    "        # Clip grad norm after backward but before step\n",
    "        if self.clip_norm > 0:\n",
    "            parameters = tuple()\n",
    "            for model in self.models:\n",
    "                parameters += tuple(model.parameters())\n",
    "                \n",
    "            # Norm clipping: returns a float\n",
    "            norm = nn.utils.clip_grad_norm(\n",
    "                parameters, self.clip_norm)\n",
    "        else:\n",
    "            norm = -1\n",
    "        return norm\n",
    "\n",
    "    def train_batch(self, batch, **kwargs):\n",
    "        for model in self.models:\n",
    "            model.zero_grad()\n",
    "            \n",
    "        loss = self.run_model(batch)\n",
    "        loss.backward()\n",
    "\n",
    "        # norms must be clipped after backward but before step\n",
    "        norm = self.clip_norms()\n",
    "\n",
    "        loss_data = self.get_loss_data(loss)\n",
    "        # print('TEMP: ', loss_data, norm)\n",
    "        if kwargs.get('verbose', False):\n",
    "            self.make_recordings(loss_data, norm)\n",
    "\n",
    "        for optimizer in self.optimizers:\n",
    "            optimizer.step()\n",
    "\n",
    "        # Return loss and norm (before gradient step)\n",
    "        return loss_data, norm\n",
    "\n",
    "    def init_parameters(self):\n",
    "        for model in self.models:\n",
    "            for p in model.parameters():\n",
    "                p.data.uniform_(-0.05, 0.05)\n",
    "\n",
    "    def train(self, torch_train_iter, le=None, val_iter=None,\n",
    "              save_model_fn=None, init_parameters=True, **kwargs):\n",
    "        self.init_lists()\n",
    "        start_time = time.time()\n",
    "        print(\"Innitializing parameters status: \", init_parameters)\n",
    "        if init_parameters:\n",
    "            self.init_parameters()\n",
    "\n",
    "        torch_train_iter.init_epoch()\n",
    "        for epoch in range(kwargs.get('num_iter', 100)):\n",
    "            self.init_epoch()\n",
    "            for model in self.models:\n",
    "                model.train()\n",
    "                \n",
    "            # Learning rate decay, if any\n",
    "            if self.lr_decay_opt == 'adaptive':\n",
    "                if (epoch > 2 and self.val_perfs[-1] > self.val_perfs[-2]) or \\\n",
    "                   (epoch >= self.lr_decay_force):\n",
    "                    self.base_lrn_rate = self.base_lrn_rate / 2\n",
    "                    self.init_optimizers() # Looks at self.base_lrn_rate\n",
    "                    print('Decaying LR to %f' % self.base_lrn_rate)\n",
    "            else:\n",
    "                for scheduler in self.schedulers:\n",
    "                    scheduler.step()\n",
    "\n",
    "            # TODO: LR decay\n",
    "            train_iter = iter(torch_train_iter)\n",
    "\n",
    "            for batch in train_iter:\n",
    "                res_loss, res_norm = self.train_batch(batch, **kwargs)\n",
    "\n",
    "            if epoch % kwargs.get('skip_iter', 1) == 0:\n",
    "                if not kwargs.get('verbose', False):\n",
    "                    self.make_recordings(res_loss, res_norm)\n",
    "\n",
    "            print('Epoch %d, loss: %f, norm: %f, elapsed: %f, lrn_rate: %f' \\\n",
    "                  % (epoch, np.mean(self.training_losses[-10:]),\n",
    "                     np.mean(self.training_norms[-10:]),\n",
    "                     time.time() - start_time,\n",
    "                     self.base_lrn_rate)) #  * self.lambda_lr(epoch)))\n",
    "                    \n",
    "            \n",
    "            if (not le is None) and (not val_iter is None):\n",
    "                self.val_perfs.append(le.evaluate(val_iter))\n",
    "                print('Validation set metric: %f' % \\\n",
    "                      self.val_perfs[-1])\n",
    "\n",
    "            if not save_model_fn is None:\n",
    "                pathname = 'saved_models/' + save_model_fn + \\\n",
    "                           '.epoch_%d.ckpt.tar' % epoch\n",
    "                print('Saving model to %s' % pathname)\n",
    "                save_checkpoint(self.models[0], self.models[1],\n",
    "                           pathname)\n",
    "\n",
    "        if len(self.val_perfs) >= 1:\n",
    "            print('FINAL VAL PERF', self.val_perfs[-1])\n",
    "            return self.val_perfs[-1]\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsLM(nn.Module):\n",
    "    def __init__(self, TEXT, dropout=0.0, max_embed_norm=None, word_features=1000):\n",
    "        super(EmbeddingsLM, self).__init__()\n",
    "        # Initialize dropout\n",
    "        self.dropout_prob = dropout\n",
    "        self.dropout = nn.Dropout(self.dropout_prob)\n",
    "        \n",
    "        # V is size of vocab, D is dim of embedding\n",
    "        self.V = len(TEXT.vocab)\n",
    "        self.D = word_features\n",
    "        self.embeddings = nn.Embedding(self.V, self.D, max_norm=max_embed_norm)\n",
    "\n",
    "class BaseEncoder(EmbeddingsLM):\n",
    "    def __init__(self, TEXT, hidden_size=1000, num_layers=4,\n",
    "                 bidirectional=False, **kwargs):\n",
    "        super(BaseEncoder, self).__init__(TEXT, **kwargs)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.lstm = nn.LSTM(input_size=self.D, hidden_size=self.hidden_size,\n",
    "                            num_layers=self.num_layers,\n",
    "                            dropout=self.dropout_prob, batch_first=True,\n",
    "                            bidirectional=self.bidirectional)\n",
    "\n",
    "        \n",
    "    def forward(self, input_tsr, hidden):\n",
    "        # [batch_sz, sent_len, D]:\n",
    "        embedded_tsr = self.embeddings(input_tsr)\n",
    "\n",
    "        # XXX\n",
    "        embedded_tsr = self.dropout(embedded_tsr)\n",
    "\n",
    "        # output is [batch, sent_len, hidden_size * num_directions]\n",
    "        output, hidden = self.lstm(embedded_tsr, hidden)\n",
    "\n",
    "        # TODO: this is experimental XXX: should be careful here since\n",
    "        # the weighted sum of outputs (i.e. context) is already being\n",
    "        # dropout'ed in the context part of the decoder (but not for\n",
    "        # attn right now)\n",
    "        # output = self.dropout(output)\n",
    "        \n",
    "        # TODO: perhaps add dropout to output\n",
    "        return output, hidden\n",
    "\n",
    "class BaseDecoder(BaseEncoder):\n",
    "    def __init__(self, TEXT, num_context=1, enc_bidirectional=False, **kwargs):\n",
    "        super(BaseDecoder, self).__init__(TEXT, **kwargs)\n",
    "        # V is the size of the vocab, which is what we're predicting\n",
    "        # (it's also used as input through the embedding)\n",
    "        self.num_context = num_context\n",
    "        self.enc_directions = 2 if enc_bidirectional else 1\n",
    "        # For now assume that encoder and decoder have same hidden size\n",
    "        blowup = self.num_context * self.num_layers * self.enc_directions + 1\n",
    "        self.out_linear = nn.Linear(\n",
    "            blowup * self.hidden_size, self.V)\n",
    "\n",
    "    # Context is a tuple (h_T, c_T) of hidden and cell states from\n",
    "    # last time step of encoder\n",
    "    def forward(self, input_tsr, hidden, context):\n",
    "        # [batch_sz, sent_len, D] : note that sent_len may be 1 if we\n",
    "        # feed in each word at a time!\n",
    "        embedding = self.embeddings(input_tsr)\n",
    "        embedding = F.relu(embedding)\n",
    "        output, hidden = self.lstm(embedding, hidden)\n",
    "\n",
    "        if self.num_context:\n",
    "            # We get lucky that hidden is stored as (h,c), \n",
    "            # so hidden (not cell) first\n",
    "            context_tsr = torch.cat(context[:self.num_context])\n",
    "            batch_sz = context_tsr.size(1)\n",
    "            sent_len = output.size(1)\n",
    "            # [batch_sz, 1, hidden_size * num_context]\n",
    "            context_tsr = context_tsr.permute(1,0,2).contiguous().view(batch_sz, 1, -1)\n",
    "            context_tsr = context_tsr.expand(-1, sent_len, -1)\n",
    "            # [batch_sz, sent_len, hidden_sz * (num_context + 1)]\n",
    "            output = torch.cat((output, context_tsr), dim=2)\n",
    "\n",
    "        # output is now [batch, sent_len, V]:\n",
    "        output = self.out_linear(output)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        return output, hidden\n",
    "\n",
    "class AttnDecoder(BaseEncoder):\n",
    "    def __init__(self, TEXT, enc_bidirectional=False, tie_weights=False,\n",
    "                 enc_linear=0, **kwargs):\n",
    "        super(AttnDecoder, self).__init__(TEXT, **kwargs)\n",
    "        print('Using final MLP')\n",
    "        self.enc_directions = 2 if enc_bidirectional else 1\n",
    "        # XXX\n",
    "        blowup = self.enc_directions # one for our output, one or two for context\n",
    "        self.out_linear_dec = nn.Linear(self.hidden_size, self.V)\n",
    "        self.out_linear_contxt = nn.Linear(blowup * self.hidden_size, self.V)\n",
    "        # self.mlp_linear = nn.Linear(self.hidden_size, self.V)\n",
    "\n",
    "        self.enc_linear = enc_linear\n",
    "        if self.enc_linear > 0:\n",
    "            self.attn_linear = nn.Linear(self.enc_directions * self.enc_linear,\n",
    "                                         self.hidden_size)\n",
    "\n",
    "        \n",
    "        if tie_weights:\n",
    "            if self.hidden_size != self.D:\n",
    "                raise ValueError('For tied weights, hidden_size must equal num embeddings!')\n",
    "            self.out_linear_dec.weight = self.embeddings.weight\n",
    "        \n",
    "    def forward(self, input_tsr, hidden, enc_output, mask_inds=None):\n",
    "        # [batch_sz, sent_len, D]:\n",
    "        embedding = self.embeddings(input_tsr)\n",
    "\n",
    "        # XXX\n",
    "        # embedding = F.relu(embedding)\n",
    "        embedding = self.dropout(embedding)\n",
    "        \n",
    "        dec_output, hidden = self.lstm(embedding, hidden)\n",
    "        \n",
    "        # Now do attention: enc_output is [batch_sz, sent_len_src, hidden_sz],\n",
    "        # and dec_output is [batch_sz, sent_len_trg, hidden_sz]\n",
    "        \n",
    "        # Normally do linear layer after dropout\n",
    "        if self.enc_linear > 0:\n",
    "            # print(enc_output.size())\n",
    "            # print(self.enc_directions * self.enc_linear,\n",
    "            #                              self.hidden_size)\n",
    "            enc_output_lin = self.attn_linear(enc_output)\n",
    "        else:\n",
    "            enc_output_lin = enc_output\n",
    "\n",
    "        # enc_output_perm is [batch_sz, hidden_sz, sent_len_src]\n",
    "        enc_output_perm = enc_output_lin.permute(0, 2, 1)\n",
    "        \n",
    "        # should be [batch_sz, sent_len_trg, sent_len_src]\n",
    "        # Note that decoder hidden state for output pos t is compouted \n",
    "        # using hidden state of the last layer (i.e. enc_output) at pos t\n",
    "        # as opposed to t-1, as in Bahdanau\n",
    "        dot_products = torch.bmm(dec_output, enc_output_perm)\n",
    "\n",
    "        # mask_inds is [batch_sz, sent_len_src]\n",
    "        if not mask_inds is None:\n",
    "            # np.inf gives nans...\n",
    "            # Using braodcasting\n",
    "            mask_inds = autograd.Variable(torch.Tensor([np.inf])) * mask_inds\n",
    "            # remove nans\n",
    "            mask_inds[mask_inds != mask_inds] = 0\n",
    "            dot_products = dot_products - torch.unsqueeze(mask_inds, 1)\n",
    "        \n",
    "        # This is the attn distribution, [batch_sz, sent_len_trg, sent_len_src]\n",
    "        dot_products_sftmx = F.softmax(dot_products, dim=2)\n",
    "\n",
    "        \n",
    "        # [batch_sz, sent_len_trg, hidden_sz]\n",
    "        context = torch.bmm(dot_products_sftmx, enc_output)\n",
    "\n",
    "        # XXX\n",
    "        output_1 = self.out_linear_dec(self.dropout(dec_output))\n",
    "        output_2 = self.out_linear_contxt(self.dropout(context))\n",
    "        output = output_1 + output_2\n",
    "        # output = self.mlp_linear(self.dropout(F.tanh(output)))\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        \n",
    "        # [batch_sz, sent_len_trg, hidden_sz * 2]\n",
    "        # output = torch.cat((dec_output, context), dim=2)\n",
    "        # output = self.dropout(output)\n",
    "        # output = self.out_linear(output)\n",
    "        # output = F.log_softmax(output, dim=2)\n",
    "        return output, hidden, dot_products_sftmx      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "a = np.array(['a', 'b','c'])\n",
    "idx = np.where(a == 'd')[0]\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PROBABLY NOT RELEVANT STUFF BELOW HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs_decoder_new = AttnDecoder(EN, hidden_size=500, num_layers=4, word_features=500, dropout=0.2)\n",
    "old_params = list(bs_decoder.parameters())\n",
    "for i,p in enumerate(bs_decoder_new.parameters()):\n",
    "    p.data = old_params[i].data\n",
    "print(list(bs_decoder_new.parameters())[0])\n",
    "print(list(bs_decoder.parameters())[0])\n",
    "bs_decoder_new.lstm.flatten_parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
