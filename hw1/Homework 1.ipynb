{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework you will be building several varieties of text classifiers.\n",
    "\n",
    "## Goal\n",
    "\n",
    "We ask that you construct the following models in PyTorch:\n",
    "\n",
    "1. A naive Bayes unigram classifer (follow Wang and Manning http://www.aclweb.org/anthology/P/P12/P12-2.pdf#page=118: you should only implement Naive Bayes, not the combined classifer with SVM).\n",
    "2. A logistic regression model over word types (you can implement this as $y = \\sigma(\\sum_i W x_i + b)$) \n",
    "3. A continuous bag-of-word neural network with embeddings (similar to CBOW in Mikolov et al https://arxiv.org/pdf/1301.3781.pdf).\n",
    "4. A simple convolutional neural network (any variant of CNN as described in Kim http://aclweb.org/anthology/D/D14/D14-1181.pdf).\n",
    "5. Your own extensions to these models...\n",
    "\n",
    "Consult the papers provided for hyperparameters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This notebook provides a working definition of the setup of the problem itself. You may construct your models inline or use an external setup (preferred) to build your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "# Text text processing library and methods for pretrained word embeddings\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will use of this problem is known as the Stanford Sentiment Treebank (https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf). It is a variant of a standard sentiment classification task. For simplicity, we will use the most basic form. Classifying a sentence as positive or negative in sentiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, `torchtext` requires that we define a mapping from the raw text data to featurized indices. These fields make it easy to map back and forth between readable data and math, which helps for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our input $x$\n",
    "TEXT = torchtext.data.Field()\n",
    "\n",
    "# Our labels $y$\n",
    "LABEL = torchtext.data.Field(sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.data.field.Field object at 0x139618dd8>\n"
     ]
    }
   ],
   "source": [
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we input our data. Here we will use the standard SST train split, and tell it the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, val, test = torchtext.datasets.SST.splits(\n",
    "    TEXT, LABEL,\n",
    "    filter_pred=lambda ex: ex.label != 'neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at this data. It's still in its original form, we can see that each example consists of a label and the original words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train) 6920\n",
      "vars(train[0]) {'text': ['The', 'Rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'Century', \"'s\", 'new', '``', 'Conan', \"''\", 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'Arnold', 'Schwarzenegger', ',', 'Jean-Claud', 'Van', 'Damme', 'or', 'Steven', 'Segal', '.'], 'label': 'positive'}\n"
     ]
    }
   ],
   "source": [
    "print('len(train)', len(test))\n",
    "print('vars(train[0])', vars(train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to map this data to features, we need to assign an index to each word an label. The function build vocab allows us to do this and provides useful options that we will need in future assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(TEXT.vocab) 16284\n",
      "len(LABEL.vocab) 3 ['<unk>', 'positive', 'negative']\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train)\n",
    "LABEL.build_vocab(train)\n",
    "print('len(TEXT.vocab)', len(TEXT.vocab))\n",
    "print('len(LABEL.vocab)', len(LABEL.vocab), LABEL.vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we are ready to create batches of our training data that can be used for training and validating the model. This function produces 3 iterators that will let us go through the train, val and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits(\n",
    "    (train, val, test), batch_size=10, device=-1, repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a single batch from one of these iterators. The library automatically converts the underlying words into indices. It then produces tensors for batches of x and y. In this case it will consist of the number of words of the longest sentence (with padding) followed by the number of batches. We can use the vocabulary dictionary to convert back from these indices to words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of text batch [max sent length, batch size] torch.Size([18, 10])\n",
      "Second in batch Variable containing:\n",
      "   21\n",
      "   16\n",
      "   17\n",
      "  198\n",
      "   15\n",
      "  123\n",
      " 2211\n",
      "   20\n",
      "  626\n",
      "   15\n",
      "   96\n",
      "   34\n",
      "   20\n",
      "  346\n",
      "    5\n",
      " 1085\n",
      " 3495\n",
      "    2\n",
      "[torch.LongTensor of size 18]\n",
      "\n",
      "Converted back to string:  Several uninteresting , unlikeable people do bad things to and with each other in `` Unfaithful . ''\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of text batch [max sent length, batch size]\", batch.text.size())\n",
    "print(\"Second in batch\", batch.text[:,2])\n",
    "print(\"Converted back to string: \", \" \".join([TEXT.vocab.itos[i] for i in batch.text[:, 1].data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly it produces a vector for each of the labels in the batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of label batch [batch size] torch.Size([10])\n",
      "Second in batch Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Converted back to string:  negative\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of label batch [batch size]\", batch.label.size())\n",
    "print(\"Second in batch\", batch.label[2])\n",
    "print(\"Converted back to string: \", LABEL.vocab.itos[batch.label.data[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.variable.Variable"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the Vocab object can be used to map pretrained word vectors to the indices in the vocabulary. This will be very useful for part 3 and 4 of the problem.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/wiki.simple.vec:   1%|          | 1.91M/293M [00:01<04:47, 1.01MB/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-a7c0c215047d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build the vocabulary with word embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.simple.vec'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wiki.simple.vec'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, cache, url, unk_init)\u001b[0m\n\u001b[1;32m    221\u001b[0m          \"\"\"\n\u001b[1;32m    222\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                         \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporthook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting vectors into {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \"\"\"\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Build the vocabulary with word embeddings\n",
    "url = 'https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.simple.vec'\n",
    "TEXT.vocab.load_vectors(vectors=Vectors('wiki.simple.vec', url=url))\n",
    "\n",
    "print(TEXT.vocab.vectors)\n",
    "print(\"Word embeddings size \", TEXT.vocab.vectors.size())\n",
    "print(\"Word embedding of 'follows', first 10 dim \", TEXT.vocab.vectors[TEXT.vocab.stoi['follows']][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "class MultinomialNB:\n",
    "    def __init__(self):\n",
    "        self.n_positive = 0\n",
    "        self.n_negative = 0\n",
    "        self.p = torch.zeros(len(TEXT.vocab))\n",
    "        self.q = torch.zeros(len(TEXT.vocab))\n",
    "        self.r = 0\n",
    "        \n",
    "    def get_features(self, case):\n",
    "        f = np.zeros(len(TEXT.vocab))\n",
    "        for i in case.data:\n",
    "            f[i] += 1\n",
    "        return torch.Tensor(f)\n",
    "    \n",
    "    def train(self, train_iter):\n",
    "        for i in range(len(train_iter)):\n",
    "            batch = next(iter(train_iter))\n",
    "            if i % 100 == 0:\n",
    "                print(i)\n",
    "            for i in range(batch.text.size()[1]):\n",
    "                fi = self.get_features(batch.text[:,i])\n",
    "                if LABEL.vocab.itos[batch.label.data[i]] == \"negative\":\n",
    "                    self.n_negative += 1\n",
    "                    self.p += fi\n",
    "                elif LABEL.vocab.itos[batch.label.data[i]] == \"positive\":\n",
    "                    self.n_positive += 1\n",
    "                    self.q += fi\n",
    "        self.r = torch.log((self.p / self.p.sum()) / (self.q / self.q.sum()))\n",
    "        \n",
    "    def predict(self, batch_text):\n",
    "        for k in range(batch_text.size()[1]):\n",
    "            fk = self.get_features(batch.text[:,k])\n",
    "            y = self.r * fk + np.log(self.n_positive / self.n_negative)\n",
    "mnb = MultinomialNB()\n",
    "train_iter = torchtext.data.BucketIterator(train, batch_size=10, device=-1)\n",
    "mnb.train(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    nan\n",
      "-0.1369\n",
      "-0.0024\n",
      "   ⋮   \n",
      "    inf\n",
      "    inf\n",
      "    inf\n",
      "[torch.FloatTensor of size 16284]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mnb.r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "Now it is your turn to build the models described at the top of the assignment. \n",
    "\n",
    "Using the data given by this iterator, you should construct 4 different torch models that take in batch.text and produce a distribution over labels. \n",
    "\n",
    "When a model is trained, use the following test function to produce predictions, and then upload to the kaggle competition:  https://www.kaggle.com/c/harvard-cs281-hw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    \"All models should be able to be run with following command.\"\n",
    "    upload = []\n",
    "    # Update: for kaggle the bucket iterator needs to have batch_size 10\n",
    "    test_iter = torchtext.data.BucketIterator(test, train=False, batch_size=10)\n",
    "    for batch in test_iter:\n",
    "        # Your prediction data here (don't cheat!)\n",
    "        probs = model(b.text)\n",
    "        _, argmax = probs.max(1)\n",
    "        upload += list(argmax.data)\n",
    "\n",
    "    with open(\"predictions.txt\", \"w\") as f:\n",
    "        for u in upload:\n",
    "            f.write(str(u) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, you should put up a (short) write-up following the template provided in the repository:  https://github.com/harvard-ml-courses/cs287-s18/blob/master/template/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression; following Torch tutorial\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, TEXT, LABEL):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        # TODO: figure out what the <unk> are!!\n",
    "        self.linear = nn.Linear(len(TEXT.vocab), len(LABEL.vocab))\n",
    "    \n",
    "    # Here bow is [N, num-features]\n",
    "    def forward(self, bow):\n",
    "        return F.log_softmax(self.linear(bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextTrainer(object):\n",
    "    def __init__(self, TEXT, LABEL):\n",
    "        # NLLLoss works with labels, not 1-hot encoding\n",
    "        self._loss_fn = nn.NLLLoss()\n",
    "        self._optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "        self._TEXT = TEXT\n",
    "        self._LABEL = LABEL\n",
    "        self._text_vocab_len = len(self._TEXT.vocab)\n",
    "        # For review and assessment\n",
    "        self._training_losses = []\n",
    "        self._predictions = []\n",
    "        \n",
    "    def get_feature(self, batch):\n",
    "        # Get bag of words one-hot feature matrix \n",
    "        size_batch = batch.text.size()[1]\n",
    "        features = torch.zeros(size_batch, self._text_vocab_len)\n",
    "        # TODO: find a better way to do this!\n",
    "        for i in range(size_batch):\n",
    "            for j in batch.text[:, i]:\n",
    "                features[i, j.data[0]] += 1\n",
    "        return features\n",
    "    \n",
    "    def get_label(self, batch):\n",
    "        return batch.label.data\n",
    "    \n",
    "    def make_loss(self, batch):\n",
    "        bow = autograd.Variable(self.get_feature(batch))\n",
    "        label = autograd.Variable(self.get_label(batch))\n",
    "        loss = self._loss_fn(model(bow), label)\n",
    "        return loss\n",
    "    \n",
    "    def train(self, train_iter, model, plot=True):\n",
    "        for i,batch in enumerate(train_iter):\n",
    "            model.zero_grad()\n",
    "            loss = self.make_loss(batch)\n",
    "            \n",
    "            # Get numerical value of loss, and save it\n",
    "            loss_val = loss.data.numpy()[0] \n",
    "            self._training_losses.append(loss_val)\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print('Iteration %d, loss: %f' % (i, loss_val))\n",
    "                \n",
    "            # Gradient descent\n",
    "            loss.backward()\n",
    "            self._optimizer.step()\n",
    "        if plot:\n",
    "            plt.plot(np.arange(len(self._training_losses)), self._training_losses)\n",
    "            plt.title(\"Training loss over time\")\n",
    "            plt.show()\n",
    "            \n",
    "    def predict(self, test_iter, model, predictions_file=\"predictions.txt\",score=False):\n",
    "        for i,batch in enumerate(test_iter):            \n",
    "            # Generate feature vector and label\n",
    "            bow = autograd.Variable(self.get_feature(batch))\n",
    "            label = autograd.Variable(self.get_label(batch))\n",
    "            \n",
    "            # Get predictions\n",
    "            probs = model(bow)\n",
    "            _, argmax = probs.max(1)\n",
    "            if i % 100 == 0:\n",
    "                print('Iteration %d, predictions:' % (i), list(argmax.data))\n",
    "            self._predictions += list(argmax.data)\n",
    "            \n",
    "            if predictions_file:\n",
    "                with open(predictions_file, \"w\") as f:\n",
    "                    f.write(\"Id,Cat\\n\")\n",
    "                    for index,p in enumerate(self._predictions[:1821]):\n",
    "                        f.write(str(index) + \",\" + str(p) + \"\\n\")\n",
    "        if score:\n",
    "            # Open answers file and store correct values in a list\n",
    "            with open(\"answers.txt\") as f:\n",
    "                content = f.readlines()\n",
    "            # Ignore column names\n",
    "            content = content[1:]\n",
    "            answers = list(map(lambda x: int(x.split(',')[1]), content))\n",
    "            print(self._predictions[:10], answers[:10])\n",
    "            \n",
    "            n = len(answers)\n",
    "            correct = 0\n",
    "            for pred,ans in zip(self._predictions[:n], answers):\n",
    "                if ans == pred:\n",
    "                    correct += 1\n",
    "            print(\"Accuracy:\", correct/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss: 1.104772\n",
      "Iteration 100, loss: 0.715023\n",
      "Iteration 200, loss: 0.693258\n",
      "Iteration 300, loss: 0.596950\n",
      "Iteration 400, loss: 0.707371\n",
      "Iteration 500, loss: 0.619095\n",
      "Iteration 600, loss: 0.677274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:33: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11dc62828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, predictions: [1, 2, 1, 1, 2, 1, 1, 2, 2, 2]\n",
      "Iteration 100, predictions: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(TEXT, LABEL)\n",
    "trainer = TextTrainer(TEXT, LABEL)\n",
    "trainer.train(train_iter, model)\n",
    "trainer.predict(test_iter, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss: 1.103211\n",
      "Iteration 1, loss: 0.937787\n",
      "Iteration 2, loss: 0.897667\n",
      "Iteration 3, loss: 0.988685\n",
      "Iteration 4, loss: 0.959458\n",
      "Iteration 5, loss: 0.816659\n",
      "Iteration 6, loss: 0.889626\n",
      "Iteration 7, loss: 0.855682\n",
      "Iteration 8, loss: 0.961055\n",
      "Iteration 9, loss: 0.769439\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(TEXT, LABEL)\n",
    "trainer = TextTrainer(TEXT, LABEL)\n",
    "trainer.train(train_iter, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.0_4'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
