{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable as V\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from models import *\n",
    "from helpers import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# New stuff.\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions.kl import kl_divergence\n",
    "DO_VAE=True\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "train_dataset = datasets.MNIST(root='./data/',\n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "test_dataset = datasets.MNIST(root='./data/',\n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "torch.manual_seed(3435)\n",
    "if DO_VAE:\n",
    "    train_img = torch.stack([torch.bernoulli(d[0]) for d in train_dataset])\n",
    "    test_img = torch.stack([torch.bernoulli(d[0]) for d in test_dataset])\n",
    "else:\n",
    "    train_img = torch.stack([d[0] for d in train_dataset])\n",
    "    test_img = torch.stack([d[1] for d in test_dataset])\n",
    "train_img = torch.squeeze(train_img)\n",
    "test_img = torch.squeeze(test_img)\n",
    "train_label = torch.LongTensor([d[1] for d in train_dataset])\n",
    "test_label = torch.LongTensor([d[1] for d in test_dataset])\n",
    "\n",
    "val_img = train_img[-10000:].clone()\n",
    "val_label = train_label[-10000:].clone()\n",
    "train_img = train_img[:-10000]\n",
    "train_label = train_label[:-10000]\n",
    "\n",
    "train = torch.utils.data.TensorDataset(train_img, train_label)\n",
    "val = torch.utils.data.TensorDataset(val_img, val_label)\n",
    "test = torch.utils.data.TensorDataset(test_img, test_label)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is unavailable...\n",
      "100 10\n",
      "CUDA is unavailable...\n",
      "100 10\n",
      "Epoch 0, loss: 225.738550, KL: 7.342832, lrn_rate: 0.005000\n",
      "Validation set: loss: 19806.042852, KL: 558.977668\n",
      "Epoch 1, loss: 195.058810, KL: 6.045110, lrn_rate: 0.005000\n",
      "Validation set: loss: 18860.284219, KL: 614.327557\n",
      "Epoch 2, loss: 186.226257, KL: 7.040453, lrn_rate: 0.005000\n",
      "Validation set: loss: 17818.897695, KL: 809.571504\n",
      "Epoch 3, loss: 168.978265, KL: 9.704606, lrn_rate: 0.005000\n",
      "Validation set: loss: 15494.017871, KL: 1160.747133\n",
      "Epoch 4, loss: 151.297802, KL: 11.682958, lrn_rate: 0.005000\n",
      "Validation set: loss: 14452.116279, KL: 1212.032679\n",
      "Epoch 5, loss: 142.455038, KL: 12.439976, lrn_rate: 0.005000\n",
      "Validation set: loss: 13940.191318, KL: 1204.167098\n",
      "Epoch 6, loss: 135.523660, KL: 13.142223, lrn_rate: 0.005000\n",
      "Validation set: loss: 13099.704658, KL: 1328.734067\n",
      "Epoch 7, loss: 129.001058, KL: 14.080128, lrn_rate: 0.005000\n",
      "Validation set: loss: 12566.649082, KL: 1379.403317\n",
      "Epoch 8, loss: 123.765371, KL: 14.647790, lrn_rate: 0.005000\n",
      "Validation set: loss: 12060.979951, KL: 1508.257371\n",
      "Epoch 9, loss: 119.924970, KL: 14.979105, lrn_rate: 0.005000\n",
      "Validation set: loss: 11824.451943, KL: 1494.042793\n"
     ]
    }
   ],
   "source": [
    "encoder_mlp = MLPEncoder(hidden_dim=200, latent_dim=10)\n",
    "decoder_mlp = MLPDecoder(hidden_dim=200, latent_dim=10)\n",
    "vae = NormalVAE(encoder_mlp, decoder_mlp)\n",
    "model_list = [encoder_mlp, decoder_mlp, vae]\n",
    "lm_evaluator = LatentModelEvaluator(model_list, batch_sz=BATCH_SIZE, mode='vae')\n",
    "lm_trainer = LatentModelTrainer(model_list, lrn_rate=0.005, optimizer = optim.SGD,\n",
    "                                batch_sz=BATCH_SIZE, mode='vae')\n",
    "lm_trainer.train(train_loader, le=lm_evaluator, val_loader=val_loader,\n",
    "                num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(list(encoder_mlp.parameters())))\n",
    "print(len(list(decoder_mlp.parameters())))\n",
    "print(len(list(vae.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 2\n"
     ]
    }
   ],
   "source": [
    "def f(a=1, b=2):\n",
    "    print(a, b)\n",
    "d = {'a' : 32}\n",
    "f(**d, b=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "for i,batch in enumerate(train_loader):\n",
    "    img = batch[0].data.numpy()\n",
    "    label = batch[1].data.numpy()\n",
    "    plt.clf()\n",
    "    plt.imshow(1 - img[0], cmap='gray')\n",
    "    print(label[0])\n",
    "    plt.savefig('mnist-ex.png')\n",
    "    # print(i)\n",
    "    # print(batch[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
