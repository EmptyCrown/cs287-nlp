{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text text processing library\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "from models import *\n",
    "from helpers import *\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our input $x$\n",
    "TEXT = torchtext.data.Field()\n",
    "\n",
    "# Data distributed with the assignment\n",
    "train, val, test = torchtext.datasets.LanguageModelingDataset.splits(\n",
    "    path=\".\", \n",
    "    train=\"train.txt\", validation=\"valid.txt\", test=\"valid.txt\", text_field=TEXT)\n",
    "\n",
    "TEXT.build_vocab(train)\n",
    "if debug:\n",
    "    TEXT.build_vocab(train, max_size=1000)\n",
    "\n",
    "train_iter, val_iter, test_iter = torchtext.data.BPTTIterator.splits(\n",
    "    (train, val, test), batch_size=10, device=-1, bptt_len=32, repeat=False)\n",
    "\n",
    "# Build the vocabulary with word embeddings\n",
    "url = 'https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.simple.vec'\n",
    "TEXT.vocab.load_vectors(vectors=Vectors('wiki.simple.vec', url=url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter <eos> pierre <unk> N years old will join\n",
      "in part because of buy programs generated by stock-index arbitrage a form of program trading involving futures contracts <eos> but interest <unk> as the day wore on and investors looked ahead to\n",
      "recorders and personal computers and then sell them at a huge <unk> <eos> the going rate for a small personal computer that costs about $ N in the west is anywhere from\n",
      "comes across as a <unk> executive mr. phillips has a <unk> <unk> <eos> during time off mr. roman tends to his garden mr. phillips <unk> to a <unk> for among other things\n",
      "with notes they 're <unk> distinct <eos> dean witter reynolds inc. lost its second recent arbitration case involving a former <unk> executive <eos> a new york stock exchange arbitration panel ordered dean\n",
      "EOB\n",
      "32\n",
      "the board as a nonexecutive director nov. N <eos> mr. <unk> is chairman of <unk> n.v. the dutch publishing group <eos> rudolph <unk> N years old and former chairman of consolidated gold\n",
      "the release later this week of two important economic reports <eos> the first is wednesday 's survey of purchasing managers considered a good indicator of how the nation 's manufacturing sector fared\n",
      "N to N rubles <eos> even a pack of N western cigarettes can fetch N rubles or more <eos> with more than N billion rubles in savings accounts and little to spend\n",
      "fast cars and planes <eos> industry executives say that although the two executives used to clash more frequently the wpp takeover brought them closer together <eos> i 'm the guy who made\n",
      "witter to pay $ N in back bonuses to william kelly the company 's former head of high-yield high-risk junk-bond trading and sales <eos> it also awarded $ N in back bonuses\n",
      "EOB\n"
     ]
    }
   ],
   "source": [
    "train_iter, val_iter, test_iter = torchtext.data.BPTTIterator.splits(\n",
    "    (train, val, test), batch_size=5, device=-1, bptt_len=32, repeat=False, shuffle=True)\n",
    "def inspect_batch(batch):\n",
    "    for i in range(batch.text.data.size(1)):\n",
    "        print(' '.join([TEXT.vocab.itos[i] for i in batch.text[:,i].data]))\n",
    "        # print(' '.join([TEXT.vocab.itos[i] for i in batch.text[:,5].data]))\n",
    "it = iter(train_iter)\n",
    "for i in range(2):\n",
    "    batch = next(it)\n",
    "    print(batch.text.data.size(0))\n",
    "    inspect_batch(batch)\n",
    "    print(\"EOB\")\n",
    "# print(batch.text[:,3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity goals:\n",
    "count: 120-200\n",
    "feedforward: 100-150\n",
    "recurrent: below 100 (between 80-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    }
   ],
   "source": [
    "train_iter, _, _  = torchtext.data.BPTTIterator.splits(\n",
    "    (train, val, test), batch_size=1, device=-1, bptt_len=10000, repeat=False)\n",
    "tgram = Trigram(TEXT)\n",
    "tgram.train_counts(train_iter)\n",
    "tgram.set_alpha(0.25, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "0.3 0.5 191.339042201\n"
     ]
    }
   ],
   "source": [
    "_, val_iter, _  = torchtext.data.BPTTIterator.splits(\n",
    "    (train, val, test), batch_size=1, device=-1, bptt_len=10000, repeat=False)\n",
    "for (a1, a2) in [(0.3, 0.5)]: #it.product(np.arange(0.1, 1, 0.1), repeat=2):\n",
    "    if a1 + a2 >= 1:\n",
    "        continue\n",
    "    tgram.set_alpha(a1, a2)\n",
    "    le = LangEvaluator(tgram, TEXT, evalmetric='perplexity')\n",
    "    print(a1, a2, le.evaluate(val_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([10001, 300]), torch.Size([60, 1, 6, 300]), torch.Size([60]), torch.Size([10001, 1, 6, 300]), torch.Size([10001]), torch.Size([10001, 60]), torch.Size([10001])]\n"
     ]
    }
   ],
   "source": [
    "params_train = list(filter(lambda p : p.requires_grad, model_nnlm.parameters()))\n",
    "print([p.size() for p in params_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss: 9.210577, norm: 0.000000\n",
      "Iteration 10, loss: 9.138780, norm: 0.000000\n",
      "Iteration 20, loss: 9.048756, norm: 0.000000\n",
      "Iteration 30, loss: 8.949280, norm: 0.000000\n",
      "Iteration 40, loss: 8.841352, norm: 0.000000\n",
      "Iteration 50, loss: 8.572618, norm: 0.000000\n",
      "Iteration 60, loss: 8.503356, norm: 0.000000\n",
      "Iteration 70, loss: 8.215203, norm: 0.000000\n",
      "Iteration 80, loss: 7.986099, norm: 0.000000\n",
      "Iteration 90, loss: 7.916728, norm: 0.000000\n"
     ]
    }
   ],
   "source": [
    "train_iter, _, _  = torchtext.data.BPTTIterator.splits(\n",
    "    (train, val, test), batch_size=10, device=-1, bptt_len=32, repeat=False)\n",
    "model_nnlm = NNLM(TEXT)\n",
    "trainer = LangTrainer(TEXT, model_nnlm)\n",
    "trainer.train(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA for evaluation...\n",
      "Epoch 0, loss: 162.435089, norm: 6.820673, elapsed: 52.066823, lrn_rate: 1.000000\n",
      "Epoch 1, loss: 155.884277, norm: 3.801386, elapsed: 105.139259, lrn_rate: 1.000000\n",
      "Epoch 2, loss: 150.217239, norm: 4.420662, elapsed: 158.387465, lrn_rate: 1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter, _, _  = torchtext.data.BPTTIterator.splits(\n",
    "    (train, val, test), batch_size=128, device=-1, bptt_len=36, repeat=False)\n",
    "model_lstm = LSTMLM2(TEXT)\n",
    "trainer = LangTrainer(TEXT, model_lstm, use_hidden=True, lrn_rate=1.0)\n",
    "trainer.train(train_iter, num_iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA for evaluation...\n",
      "Validation time: 20.806038 seconds\n",
      "2411.5569330249964\n",
      "Validation time: 4.735303 seconds\n",
      "2414.4938698270835\n"
     ]
    }
   ],
   "source": [
    "le = LangEvaluator(model_lstm, TEXT, use_hidden=True)\n",
    "print(le.evaluate(train_iter))\n",
    "print(le.evaluate(test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07247233390808105\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "parameters = model_lstm.parameters()\n",
    "parameters = list(filter(lambda p: p.grad is not None, parameters))\n",
    "total_norm = max(p.grad.data.abs().max() for p in parameters)\n",
    "print(total_norm)\n",
    "print(trainer.training_norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IGNORE STUFF BELOW HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # NOT USED!\n",
    "    # Here arr is a 1-D numpy array; this returns \n",
    "    # groups of n consecutive words (with overlapping)\n",
    "    def get_ngrams(self, arr, n=3):\n",
    "        len_ngrams = arr.shape[0] - n + 1\n",
    "        ngram_inds = np.tile(np.reshape(np.arange(len_ngrams), [len_ngrams, 1]), [1, n]) + \\\n",
    "                    np.tile(np.reshape(np.arange(n), [1, n]), [len_ngrams, 1])\n",
    "        return np.take(arr, ngram_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 8]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [2 * x + i for i,x in enumerate(a)]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10001, 300])\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.vectors.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad_token = TEXT.vocab.stoi['<pad>']\n",
    "it = iter(train_iter)\n",
    "cnt = 0\n",
    "for batch in it:\n",
    "    cnt += 1\n",
    "    if (len(np.where(batch.text.data.numpy() == pad_token)[0])):\n",
    "        print(batch.text.data, cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    print(x)\n",
    "\n",
    "a = [1]\n",
    "f(*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
